import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
import torchvision.ops as ops
import argparse
import os
import re
import xml.etree.ElementTree as ET
import numpy as np
from PIL import Image
from tqdm import tqdm
import copy
import time
import tarfile
from torchvision.models import resnet50
import urllib.request
import shutil
# from channel_selector import *
# from auxiliary_network import *
# from check_point import *
# from context_roi_align import *
# from gIoU_loss import *
# from lcp_channel_selector import *
# from os2d_resnet import *

VOC_CLASSES = [
    'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat',
    'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person',
    'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'
]

class VOCDataset(torch.utils.data.Dataset):
    def __init__(self, data_path, split='train', transform=None, download=True):
        # å¦‚æœéœ€è¦ä¸‹è¼‰ä¸”è·¯å¾‘ä¸å­˜åœ¨æœ‰æ•ˆæ•¸æ“šé›†ï¼Œå‰‡ä¸‹è¼‰
        if download:
            self.data_path = self._download_voc(data_path)
        else:
            self.data_path = self._resolve_data_root(data_path)
            
        self.split = split
        self.transform = transform
        self.samples = []
        self.cache = {}

        # è·¯å¾‘çµæ§‹èˆ‡åˆ†å‰²æª”æ¡ˆæª¢æŸ¥
        self._fix_nested_path_structure()
        if not self._validate_dataset_structure():
            if download:
                print(f"âš ï¸ æ‰¾ä¸åˆ°æœ‰æ•ˆçš„VOCè³‡æ–™é›†ï¼Œå˜—è©¦ä¸‹è¼‰...")
                self.data_path = self._download_voc(data_path)
            else:
                raise FileNotFoundError(f"ç„¡æ•ˆçš„VOCè³‡æ–™é›†çµæ§‹æ–¼ {self.data_path}ï¼Œè«‹è¨­ç½® download=True è‡ªå‹•ä¸‹è¼‰")
        
        self._verify_split_files()
        self._precache_metadata()
        print(f"ğŸ“¦ è¼‰å…¥ VOC2007 {split}é›†: {len(self.samples)} å€‹æ¨£æœ¬ (å¿«å–ç‰ˆ)")

    def _download_voc(self, path):
        """ä¸‹è¼‰ä¸¦è§£å£“ Pascal VOC æ•¸æ“šé›†"""
        import tarfile
        import urllib.request
        import os
        
        # å‰µå»ºç›®æ¨™ç›®éŒ„
        os.makedirs(path, exist_ok=True)
        
        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ VOC2007 è³‡æ–™å¤¾
        voc_path = os.path.join(path, 'VOC2007')
        if os.path.exists(voc_path) and os.path.exists(os.path.join(voc_path, 'JPEGImages')):
            print(f"âœ… æ‰¾åˆ°å·²å­˜åœ¨çš„ VOC2007 è³‡æ–™é›†: {voc_path}")
            return voc_path
            
        voc_devkit_path = os.path.join(path, 'VOCdevkit', 'VOC2007')
        if os.path.exists(voc_devkit_path) and os.path.exists(os.path.join(voc_devkit_path, 'JPEGImages')):
            print(f"âœ… æ‰¾åˆ°å·²å­˜åœ¨çš„ VOC2007 è³‡æ–™é›†: {voc_devkit_path}")
            return voc_devkit_path
            
        # VOC ä¸‹è¼‰ URL
        DOWNLOAD_URLS = [
            ('http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar',
             '34ed68851bce2a36e2a223fa52c661d592c66b3c'),
            ('http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar',
             '41a8d6e12baa5ab18ee7f8f8029b9e11805b4ef1')
        ]
        
        for url, checksum in DOWNLOAD_URLS:
            filename = os.path.join(path, url.split('/')[-1])
            # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç¶“å­˜åœ¨
            if not os.path.exists(filename):
                print(f"ğŸ“¥ ä¸‹è¼‰ {url}")
                try:
                    urllib.request.urlretrieve(url, filename)
                    print(f"âœ… ä¸‹è¼‰å®Œæˆ: {filename}")
                except Exception as e:
                    print(f"âŒ ä¸‹è¼‰å¤±æ•—: {e}")
                    continue
                    
            # è§£å£“æ–‡ä»¶
            print(f"ğŸ“¦ è§£å£“ {filename}")
            try:
                with tarfile.open(filename) as tar:
                    tar.extractall(path=path)
                print(f"âœ… è§£å£“å®Œæˆ")
            except Exception as e:
                print(f"âŒ è§£å£“å¤±æ•—: {e}")
                continue
                
        # æª¢æŸ¥æœ€çµ‚è·¯å¾‘
        if os.path.exists(voc_devkit_path):
            print(f"ğŸ“‚ VOC2007 è³‡æ–™é›†ä½ç½®: {voc_devkit_path}")
            return voc_devkit_path
        else:
            print(f"âŒ ä¸‹è¼‰å¾Œæ‰¾ä¸åˆ° VOC2007 è³‡æ–™é›†!")
            raise FileNotFoundError(f"ä¸‹è¼‰å¾Œæ‰¾ä¸åˆ° VOC2007 è³‡æ–™é›†!")

    def _resolve_data_root(self, data_root):
        """è‡ªå‹•ä¿®æ­£ VOCdevkit è·¯å¾‘"""
        potential_paths = [
            data_root,
            os.path.join(data_root, 'VOCdevkit/VOC2007'),
            os.path.join(data_root, 'VOC2007'),
            os.path.join(data_root, 'VOCdevkit/VOCdevkit/VOC2007')
        ]
        for path in potential_paths:
            if os.path.exists(os.path.join(path, 'Annotations')):
                print(f"ğŸ” åµæ¸¬åˆ°æœ‰æ•ˆè³‡æ–™é›†è·¯å¾‘: {path}")
                return path
        return data_root

    def _fix_nested_path_structure(self):
        if 'VOCdevkit/VOCdevkit' in self.data_path:
            corrected = self.data_path.replace('VOCdevkit/VOCdevkit', 'VOCdevkit')
            if os.path.exists(corrected):
                print(f"ğŸ› ï¸ è‡ªå‹•ä¿®æ­£åµŒå¥—è·¯å¾‘: {self.data_path} â†’ {corrected}")
                self.data_path = corrected

    def _validate_dataset_structure(self):
        required_dirs = ['Annotations', 'JPEGImages', 'ImageSets/Main']
        return all(os.path.isdir(os.path.join(self.data_path, d)) for d in required_dirs)

    def _verify_split_files(self):
        # æ”¯æŒçš„åˆ†å‰²æ–‡ä»¶
        valid_splits = ['train', 'val', 'test', 'trainval']
        if self.split not in valid_splits:
            raise ValueError(f"ç„¡æ•ˆçš„åˆ†å‰²é¡å‹: {self.split}ï¼Œæ”¯æŒçš„é¡å‹: {valid_splits}")
            
        split_file = os.path.join(self.data_path, 'ImageSets/Main', f'{self.split}.txt')
        if not os.path.isfile(split_file):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°åˆ†å‰²æª”æ¡ˆ: {split_file}")

    def _precache_metadata(self):
        """ä¸¦è¡Œé è¼‰æ‰€æœ‰æ¨™è¨»è³‡æ–™åˆ°è¨˜æ†¶é«”"""
        from concurrent.futures import ThreadPoolExecutor, as_completed

        split_file = os.path.join(self.data_path, 'ImageSets/Main', f'{self.split}.txt')
        with open(split_file, 'r') as f:
            ids = [line.strip() for line in f if line.strip()]

        self.samples = []
        with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:
            futures = {executor.submit(self._safe_parse_annotation, img_id): img_id for img_id in ids}
            for future in tqdm(as_completed(futures), total=len(ids), desc="ğŸš€ é è¼‰æ¨™è¨»è³‡æ–™"):
                img_id = futures[future]
                try:
                    result = future.result()
                    if result:
                        self.samples.append(img_id)
                        self.cache[img_id] = result
                except Exception as e:
                    print(f"âš ï¸ è·³éç„¡æ•ˆæ¨£æœ¬ {img_id}: {str(e)}")

    def _safe_parse_annotation(self, img_id):
        img_path = os.path.join(self.data_path, 'JPEGImages', f'{img_id}.jpg')
        annot_path = os.path.join(self.data_path, 'Annotations', f'{img_id}.xml')
        if not os.path.isfile(img_path):
            raise FileNotFoundError(f"åœ–ç‰‡æª”æ¡ˆä¸å­˜åœ¨: {img_path}")
        if not os.path.isfile(annot_path):
            raise FileNotFoundError(f"æ¨™è¨»æª”æ¡ˆä¸å­˜åœ¨: {annot_path}")

        tree = ET.parse(annot_path)
        root = tree.getroot()
        boxes = []
        labels = []
        for obj in root.findall('object'):
            name = obj.find('name').text
            if name not in VOC_CLASSES:
                continue
            bbox = obj.find('bndbox')
            box = [
                float(bbox.find('xmin').text),
                float(bbox.find('ymin').text),
                float(bbox.find('xmax').text),
                float(bbox.find('ymax').text)
            ]
            boxes.append(box)
            labels.append(VOC_CLASSES.index(name))
        return (img_path, boxes, labels)

    def __getitem__(self, idx):
        img_id = self.samples[idx]
        img_path, boxes, labels = self.cache[img_id]
        img = Image.open(img_path).convert('RGB')
        img = np.asarray(img).copy()
        img = torch.from_numpy(img).float().permute(2, 0, 1) / 255.0
        if self.transform:
            img = self.transform(img)
        return img, torch.tensor(boxes), torch.tensor(labels), img_id

    def __len__(self):
        return len(self.samples)
