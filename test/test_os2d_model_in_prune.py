import os
import torch
import torchvision
import pytest
import traceback
from src.lcp_channel_selector import OS2DChannelSelector
from src.contextual_roi_align import ContextualRoIAlign
from src.os2d_model_in_prune import Os2dModelInPrune
from src.auxiliary_network import AuxiliaryNetwork
import logging

def test_os2d_model_in_prune_initialization():
    """æ¸¬è©¦ Os2dModelInPrune åˆå§‹åŒ–"""
    # è¨­ç½® logger
    logger = logging.getLogger("OS2D.test")
    
    # åˆå§‹åŒ–æ¨¡å‹
    os2d_path = "./os2d_v2-train.pth"
    if not os.path.exists(os2d_path):
        pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
    
    # åˆå§‹åŒ–æ¨¡å‹
    model = Os2dModelInPrune(logger=logger, pretrained_path=os2d_path)
    
    # é©—è­‰æ¨¡å‹çµæ§‹
    assert hasattr(model, 'net_feature_maps'), "æ¨¡å‹æ‡‰è©²æœ‰ net_feature_maps å±¬æ€§"
    assert hasattr(model, 'net_label_features'), "æ¨¡å‹æ‡‰è©²æœ‰ net_label_features å±¬æ€§"
    assert hasattr(model, 'os2d_head_creator'), "æ¨¡å‹æ‡‰è©²æœ‰ os2d_head_creator å±¬æ€§"
    
    # é©—è­‰åƒæ•¸æ•¸é‡
    param_count = sum(p.numel() for p in model.parameters())
    print(f"æ¨¡å‹åƒæ•¸ç¸½æ•¸: {param_count}")
    assert param_count > 0, "æ¨¡å‹åƒæ•¸æ•¸é‡æ‡‰è©²å¤§æ–¼ 0"
    
    print("âœ… Os2dModelInPrune åˆå§‹åŒ–æ¸¬è©¦é€šé")
    return True

def test_os2d_model_in_prune_forward():
    """æ¸¬è©¦ Os2dModelInPrune å‰å‘å‚³æ’­"""
    # è¨­ç½® logger
    logger = logging.getLogger("OS2D.test")
    
    # åˆå§‹åŒ–æ¨¡å‹
    os2d_path = "./os2d_v2-train.pth"
    if not os.path.exists(os2d_path):
        pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = Os2dModelInPrune(logger=logger, pretrained_path=os2d_path, is_cuda=(device.type == 'cuda'))
    model = model.to(device)
    
    # å‰µå»ºæ¸¬è©¦è¼¸å…¥
    batch_size = 2
    images = torch.randn(batch_size, 3, 224, 224).to(device)
    class_images = [torch.randn(3, 224, 224).to(device) for _ in range(2)]
    
    # åŸ·è¡Œå‰å‘å‚³æ’­
    with torch.no_grad():
        loc_scores, class_scores, class_scores_transform_detached, fm_size, transform_corners = model(images, class_images)
    
    # é©—è­‰è¼¸å‡º
    assert loc_scores is not None, "loc_scores ä¸æ‡‰ç‚º None"
    assert class_scores is not None, "class_scores ä¸æ‡‰ç‚º None"
    assert class_scores_transform_detached is not None, "class_scores_transform_detached ä¸æ‡‰ç‚º None"
    assert fm_size is not None, "fm_size ä¸æ‡‰ç‚º None"
    
    print("âœ… Os2dModelInPrune å‰å‘å‚³æ’­æ¸¬è©¦é€šé")
    return True

def test_os2d_model_in_prune_channel():
    """æ¸¬è©¦ Os2dModelInPrune é€šé“å‰ªæåŠŸèƒ½"""
    # è¨­ç½® logger
    logger = logging.getLogger("OS2D.test")
    
    # åˆå§‹åŒ–æ¨¡å‹
    os2d_path = "./os2d_v2-train.pth"
    if not os.path.exists(os2d_path):
        pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = Os2dModelInPrune(logger=logger, pretrained_path=os2d_path, is_cuda=(device.type == 'cuda'))
    model = model.to(device)
    
    # åˆå§‹åŒ–è¼”åŠ©ç¶²è·¯
    aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
    
    # é¸æ“‡è¦å‰ªæçš„å±¤
    layer_name = "layer2.0.conv1"
    
    # ç²å–åŸå§‹é€šé“æ•¸
    target_layer = None
    for name, module in model.backbone.named_modules():
        if name == layer_name:
            target_layer = module
            break
    
    assert target_layer is not None, f"æ‰¾ä¸åˆ°å±¤: {layer_name}"
    orig_channels = target_layer.out_channels
    print(f"åŸå§‹é€šé“æ•¸: {orig_channels}")
    
    # è¨­ç½®å‰ªææ¯”ä¾‹
    prune_ratio = 0.3
    expected_channels = int(orig_channels * (1 - prune_ratio))
    
    # å‰µå»ºæ¸¬è©¦è¼¸å…¥
    batch_size = 2
    images = torch.randn(batch_size, 3, 224, 224).to(device)
    boxes = [torch.tensor([[10, 10, 50, 50], [20, 20, 60, 60]], dtype=torch.float32).to(device) for _ in range(batch_size)]
    labels = [torch.tensor([0, 1], dtype=torch.long).to(device) for _ in range(batch_size)]
    
    # åŸ·è¡Œå‰ªæ
    print(f"å‰ªæå±¤ {layer_name}ï¼Œå‰ªææ¯”ä¾‹: {prune_ratio}")
    success = model.prune_channel(layer_name, prune_ratio=prune_ratio, images=images, boxes=boxes, labels=labels, auxiliary_net=aux_net)
    
    # é©—è­‰å‰ªæçµæœ
    assert success, "å‰ªææ“ä½œå¤±æ•—"
    
    # ç²å–å‰ªæå¾Œçš„é€šé“æ•¸
    pruned_layer = None
    for name, module in model.backbone.named_modules():
        if name == layer_name:
            pruned_layer = module
            break
    
    assert pruned_layer is not None, f"å‰ªæå¾Œæ‰¾ä¸åˆ°å±¤: {layer_name}"
    pruned_channels = pruned_layer.out_channels
    print(f"å‰ªæå¾Œé€šé“æ•¸: {pruned_channels}")
    
    # é©—è­‰é€šé“æ•¸æ˜¯å¦æ­£ç¢ºæ¸›å°‘
    assert pruned_channels == expected_channels, f"é€šé“æ•¸ä¸åŒ¹é…: é æœŸ {expected_channels}, å¯¦éš› {pruned_channels}"
    
    # æ¸¬è©¦å‰å‘å‚³æ’­
    with torch.no_grad():
        loc_scores, class_scores, class_scores_transform_detached, fm_size, transform_corners = model(images, class_images)
    
    print("âœ… Os2dModelInPrune é€šé“å‰ªææ¸¬è©¦é€šé")
    return True

def test_forward_pass_with_class_images():
    """Test forward pass with class_images parameter"""
    try:
        # Setup device
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # Initialize model
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D pretrained model not found: {os2d_path}")
            
        model = Os2dModelInPrune(pretrained_path=os2d_path)
        model = model.to(device)
        
        # Create test inputs
        batch_size = 1
        x = torch.randn(batch_size, 3, 224, 224).to(device)
        class_images = [torch.randn(1, 3, 224, 224).to(device)]

        # Test forward pass
        print("\nTesting forward pass with class_images...")
        try:
            with torch.no_grad():
                output = model(x, class_images)
            print("âœ… Forward pass with class_images successful")
            return True
        except Exception as e:
            print(f"âŒ Forward pass failed: {e}")
            assert False, f"Forward pass failed: {e}"
            
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        traceback.print_exc()
        return False

def test_set_layer_out_channels():
    """æ¸¬è©¦ set_layer_out_channels æ–¹æ³•"""
    try:
        # è¨­ç½®è¨­å‚™
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        model = Os2dModelInPrune(pretrained_path=os2d_path)
        model = model.to(device)
        
        # é¸æ“‡è¦æ¸¬è©¦çš„å±¤
        layer_name = "layer2.0.conv1"
        param_count = sum(p.numel() for p in model.parameters())
        print(f"æ¨¡å‹åƒæ•¸ç¸½æ•¸: {param_count}")
        # ç²å–åŸå§‹å±¤èˆ‡ä¸‹æ¸¸å±¤
        parts = layer_name.split('.')
        layer_str, block_idx, conv_name = parts[0], int(parts[1]), parts[2]
        block = getattr(model.backbone, layer_str)[block_idx]
        
        # ç²å–åŸå§‹é€šé“æ•¸
        conv_layer = getattr(block, conv_name)
        orig_out_channels = conv_layer.out_channels
        
        # ç²å–ä¸‹æ¸¸å±¤çš„åŸå§‹é€šé“æ•¸
        next_conv_name = f"conv{int(conv_name[-1])+1}"
        next_conv_layer = getattr(block, next_conv_name)
        orig_next_in_channels = next_conv_layer.in_channels
        
        # ç²å–å°æ‡‰ BatchNorm å±¤çš„åŸå§‹é€šé“æ•¸
        bn_name = conv_name.replace('conv', 'bn')
        bn_layer = getattr(block, bn_name)
        orig_bn_channels = bn_layer.num_features
        
        print(f"åŸå§‹å±¤çµæ§‹:")
        print(f"{layer_name}: out_channels={orig_out_channels}")
        print(f"{layer_str}.{block_idx}.{next_conv_name}: in_channels={orig_next_in_channels}")
        print(f"{layer_str}.{block_idx}.{bn_name}: num_features={orig_bn_channels}")
        
        # è¨­ç½®æ–°çš„é€šé“æ•¸
        new_out_channels = orig_out_channels // 2
        print(f"\nå°‡ {layer_name} çš„ out_channels è¨­ç‚º {new_out_channels}")
        
        # åŸ·è¡Œæ¸¬è©¦æ–¹æ³•
        success = model.set_layer_out_channels(layer_name, new_out_channels)
        assert success, "set_layer_out_channels æ–¹æ³•æ‡‰è©²è¿”å› True"
        
        # é‡æ–°ç²å–å±¤
        block = getattr(model.backbone, layer_str)[block_idx]
        conv_layer = getattr(block, conv_name)
        next_conv_layer = getattr(block, next_conv_name)
        bn_layer = getattr(block, bn_name)
        
        # é©—è­‰é€šé“æ•¸æ˜¯å¦æ­£ç¢ºæ›´æ–°
        print(f"\næ›´æ–°å¾Œçš„å±¤çµæ§‹:")
        print(f"{layer_name}: out_channels={conv_layer.out_channels}")
        print(f"{layer_str}.{block_idx}.{next_conv_name}: in_channels={next_conv_layer.in_channels}")
        print(f"{layer_str}.{block_idx}.{bn_name}: num_features={bn_layer.num_features}")
        param_count = sum(p.numel() for p in model.parameters())
        print(f"æ¨¡å‹åƒæ•¸ç¸½æ•¸: {param_count}")
        assert conv_layer.out_channels == new_out_channels, f"{layer_name} çš„ out_channels æ‡‰ç‚º {new_out_channels}"
        assert next_conv_layer.in_channels == new_out_channels, f"{layer_str}.{block_idx}.{next_conv_name} çš„ in_channels æ‡‰ç‚º {new_out_channels}"
        # Add test for forward pass with class_images
        print("\nTesting forward pass...") 
        x = torch.randn(1, 3, 224, 224).to(device)
        class_images = [torch.randn(3, 224, 224).to(device)]
        try:
            with torch.no_grad():
                output = model(x, class_images)  # Added class_images parameter
            print("âœ… Forward pass successful")
        except Exception as e:
            print(f"âŒ Forward pass failed: {e}")
            assert False, f"Forward pass failed: {e}"
        # æª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§
        print("\næª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§...")
        _test_all_layer_channel_consistency(model)
        
        print("\nâœ… set_layer_out_channels æ¸¬è©¦é€šé")
        return True
    except Exception as e:
        print(f"âŒ set_layer_out_channels æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

def _test_all_layer_channel_consistency(model):
    """æª¢æŸ¥ backbone æ‰€æœ‰ conv/bn å±¤çš„ in/out channel æ˜¯å¦ä¸€è‡´"""
    backbone = model.backbone
    all_pass = True
    for layer_name in ['layer1', 'layer2', 'layer3', 'layer4']:
        if not hasattr(backbone, layer_name):
            continue
        layer = getattr(backbone, layer_name)
        for block_idx, block in enumerate(layer):
            prefix = f"{layer_name}.{block_idx}"
            # æª¢æŸ¥ conv1
            conv1 = getattr(block, 'conv1', None)
            bn1 = getattr(block, 'bn1', None)
            if conv1 is not None and bn1 is not None:
                if bn1.num_features != conv1.out_channels:
                    print(f"âŒ {prefix}.bn1.num_features({bn1.num_features}) != conv1.out_channels({conv1.out_channels})")
                    all_pass = False
                else:
                    print(f"âœ“ {prefix}.bn1.num_features({bn1.num_features}) == conv1.out_channels({conv1.out_channels})")
            
            # æª¢æŸ¥ conv2
            conv2 = getattr(block, 'conv2', None)
            bn2 = getattr(block, 'bn2', None)
            if conv2 is not None:
                # æª¢æŸ¥ conv2 in_channels == conv1 out_channels
                if conv1 is not None and conv2.in_channels != conv1.out_channels:
                    print(f"âŒ {prefix}.conv2.in_channels({conv2.in_channels}) != conv1.out_channels({conv1.out_channels})")
                    all_pass = False
                else:
                    print(f"âœ“ {prefix}.conv2.in_channels({conv2.in_channels}) == conv1.out_channels({conv1.out_channels})")
                
                if bn2 is not None:
                    if bn2.num_features != conv2.out_channels:
                        print(f"âŒ {prefix}.bn2.num_features({bn2.num_features}) != conv2.out_channels({conv2.out_channels})")
                        all_pass = False
                    else:
                        print(f"âœ“ {prefix}.bn2.num_features({bn2.num_features}) == conv2.out_channels({conv2.out_channels})")
            
            # æª¢æŸ¥ conv3
            conv3 = getattr(block, 'conv3', None)
            bn3 = getattr(block, 'bn3', None)
            if conv3 is not None:
                # æª¢æŸ¥ conv3 in_channels == conv2 out_channels
                if conv2 is not None and conv3.in_channels != conv2.out_channels:
                    print(f"âŒ {prefix}.conv3.in_channels({conv3.in_channels}) != conv2.out_channels({conv2.out_channels})")
                    all_pass = False
                else:
                    print(f"âœ“ {prefix}.conv3.in_channels({conv3.in_channels}) == conv2.out_channels({conv2.out_channels})")
                
                if bn3 is not None:
                    if bn3.num_features != conv3.out_channels:
                        print(f"âŒ {prefix}.bn3.num_features({bn3.num_features}) != conv3.out_channels({conv3.out_channels})")
                        all_pass = False
                    else:
                        print(f"âœ“ {prefix}.bn3.num_features({bn3.num_features}) == conv3.out_channels({conv3.out_channels})")
    
    if all_pass:
        print("âœ… æ‰€æœ‰å±¤çš„ channel å°æ‡‰æª¢æŸ¥é€šé")
    else:
        print("âŒ æœ‰å±¤çš„ channel å°æ‡‰éŒ¯èª¤ï¼Œè«‹æª¢æŸ¥ä¸Šæ–¹è¼¸å‡º")

def test_cross_block_residual_connection():
    """æ¸¬è©¦è·¨å¡Šæ®˜å·®é€£æ¥ä¿è­·æ©Ÿåˆ¶"""
    try:
        # è¨­ç½®è¨­å‚™
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
        
        # åˆå§‹åŒ–è¼”åŠ©ç¶²è·¯
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
        
        # åˆå§‹åŒ–æ¨¡å‹
        model = Os2dModelInPrune(pretrained_path=os2d_path)
        model = model.to(device)
        
        # é¸æ“‡ä¸€å€‹è·¨å¡Šé€£æ¥çš„å±¤é€²è¡Œå‰ªæ
        layer_name = "layer2.3.conv3"  # æ­¤å±¤å¯èƒ½é€£æ¥åˆ°ä¸‹ä¸€å€‹å¡Šçš„ conv1
        
        # ç²å–åŸå§‹é€šé“æ•¸
        target_layer = None
        for name, module in model.backbone.named_modules():
            if name == layer_name:
                target_layer = module
                break
        
        if target_layer is None:
            pytest.skip(f"æ‰¾ä¸åˆ°å±¤: {layer_name}ï¼Œå¯èƒ½æ˜¯å› ç‚ºæ¨¡å‹çµæ§‹ä¸åŒ")
        
        orig_channels = target_layer.out_channels
        print(f"åŸå§‹é€šé“æ•¸: {orig_channels}")
        
        # å‰µå»ºæ¸¬è©¦è¼¸å…¥
        batch_size = 2
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        boxes = [torch.tensor([[10, 10, 50, 50], [20, 20, 60, 60]], dtype=torch.float32).to(device) for _ in range(batch_size)]
        labels = [torch.tensor([0, 1], dtype=torch.long).to(device) for _ in range(batch_size)]
        
        # è¨­ç½®å‰ªææ¯”ä¾‹
        prune_ratio = 0.3
        expected_channels = int(orig_channels * (1 - prune_ratio))
        
        # åŸ·è¡Œå‰ªæ
        print(f"å‰ªæå±¤ {layer_name}ï¼Œå‰ªææ¯”ä¾‹: {prune_ratio}")
        success = model.prune_channel(layer_name, prune_ratio=prune_ratio, images=images, boxes=boxes, labels=labels, auxiliary_net=aux_net)
        
        # é©—è­‰å‰ªæçµæœ
        if success == "SKIPPED":
            print(f"âœ… æ­£ç¢ºè·³éäº† {layer_name} çš„å‰ªæ")
            # å¦‚æœè·³éäº†å‰ªæï¼Œå‰‡æœŸæœ›é€šé“æ•¸ä¸è®Š
            expected_channels = orig_channels
        else:
            assert success, "å‰ªææ“ä½œå¤±æ•—"
        
        # ç²å–å‰ªæå¾Œçš„é€šé“æ•¸
        pruned_layer = None
        for name, module in model.backbone.named_modules():
            if name == layer_name:
                pruned_layer = module
                break
        
        assert pruned_layer is not None, f"å‰ªæå¾Œæ‰¾ä¸åˆ°å±¤: {layer_name}"
        pruned_channels = pruned_layer.out_channels
        print(f"å‰ªæå¾Œé€šé“æ•¸: {pruned_channels}")
        
        # é©—è­‰é€šé“æ•¸æ˜¯å¦æ­£ç¢ºæ¸›å°‘
        assert pruned_channels == expected_channels, f"é€šé“æ•¸ä¸åŒ¹é…: é æœŸ {expected_channels}, å¯¦éš› {pruned_channels}"
        
        # æª¢æŸ¥ä¸‹ä¸€å€‹å¡Šçš„ç¬¬ä¸€å±¤æ˜¯å¦å·²æ›´æ–°
        next_layer_name = "layer3.0.conv1"
        next_layer = None
        for name, module in model.backbone.named_modules():
            if name == next_layer_name:
                next_layer = module
                break
        
        if next_layer is not None:
            assert next_layer.in_channels == pruned_channels, f"ä¸‹ä¸€å€‹å¡Šçš„è¼¸å…¥é€šé“æ•¸ä¸åŒ¹é…: é æœŸ {pruned_channels}, å¯¦éš› {next_layer.in_channels}"
            print(f"âœ“ ä¸‹ä¸€å€‹å¡Šçš„è¼¸å…¥é€šé“æ•¸å·²æ­£ç¢ºæ›´æ–°: {next_layer.in_channels}")
        
        # æ¸¬è©¦å‰å‘å‚³æ’­
        class_images = [torch.randn(3, 224, 224).to(device) for _ in range(batch_size)]
        with torch.no_grad():
            output = model(images, class_images)
            
        # æª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§
        print("\næª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§...")
        _test_all_layer_channel_consistency(model)
        
        print("âœ… è·¨å¡Šæ®˜å·®é€£æ¥ä¿è­·æ¸¬è©¦é€šé")
        return True
    except Exception as e:
        print(f"âŒ è·¨å¡Šæ®˜å·®é€£æ¥ä¿è­·æ¸¬è©¦å¤±æ•—: {e}")
        traceback.print_exc()
        return False

def test_load_os2d_weights():
    """æ¸¬è©¦ OS2D æ¨¡å‹è¼‰å…¥æ¬Šé‡"""
    try:
        # è¨­ç½®è¨­å‚™
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # åˆå§‹åŒ–æ¨¡å‹
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
        
        # è¼‰å…¥æ¨¡å‹
        print(f"ğŸ“¥ è¼‰å…¥ OS2D checkpoint: {os2d_path}")
        model = Os2dModelInPrune(pretrained_path=os2d_path)
        
        # é©—è­‰æ¨¡å‹è¼‰å…¥æˆåŠŸ
        print("âœ… OS2D æ¬Šé‡è¼‰å…¥æˆåŠŸ")
        
        # é©—è­‰åƒæ•¸ç¸½å’Œ (ç°¡å–®çš„å®Œæ•´æ€§æª¢æŸ¥)
        param_sum = sum(p.sum().item() for p in model.parameters())
        print(f"âœ… æ¨¡å‹åƒæ•¸ç¸½å’Œ: {param_sum}")
        
        return True
    except Exception as e:
        print(f"âŒ OS2D æ¨¡å‹æ¸¬è©¦å¤±æ•—: {e}")
        traceback.print_exc()
        return False
    
def test_get_feature_map():
    """æ¸¬è©¦ OS2D ç‰¹å¾µåœ–æå–åŠŸèƒ½"""
    try:
        # è¨­ç½®è¨­å‚™
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # åˆå§‹åŒ–æ¨¡å‹
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
        
        # è¼‰å…¥æ¨¡å‹
        print(f"ğŸ“¥ è¼‰å…¥ OS2D checkpoint: {os2d_path}")
        model = Os2dModelInPrune(pretrained_path=os2d_path)
        model = model.to(device)
        
        # å‰µå»ºæ¸¬è©¦è¼¸å…¥
        batch_size = 2
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        
        # æå–ç‰¹å¾µåœ–
        with torch.no_grad():
            features = model.get_feature_map(images)
        
        # é©—è­‰ç‰¹å¾µåœ–å½¢ç‹€
        print(f"âœ… ç‰¹å¾µåœ–å½¢ç‹€: {features.shape}")
        assert features.shape[0] == batch_size, f"æ‰¹æ¬¡å¤§å°ä¸åŒ¹é…: {features.shape[0]} != {batch_size}"
        
        # æª¢æŸ¥ç‰¹å¾µåœ–ç¶­åº¦
        assert len(features.shape) == 4, f"ç‰¹å¾µåœ–æ‡‰ç‚º4ç¶­å¼µé‡ï¼Œå¯¦éš›ç‚º{len(features.shape)}ç¶­"
        
        # é©—è­‰ç‰¹å¾µåœ–æœ‰å€¼
        assert torch.isfinite(features).all(), "ç‰¹å¾µåœ–åŒ…å«ç„¡é™å€¼"
        assert not torch.isnan(features).any(), "ç‰¹å¾µåœ–åŒ…å« NaN"
        
        # æª¢æŸ¥ç‰¹å¾µåœ–æ•¸å€¼ç¯„åœ
        print(f"ç‰¹å¾µåœ–æ•¸å€¼ç¯„åœ: [{features.min().item():.3f}, {features.max().item():.3f}]")
        
        print("âœ… OS2D ç‰¹å¾µåœ–æ¸¬è©¦é€šé")
        return True
    except Exception as e:
        print(f"âŒ OS2D ç‰¹å¾µåœ–æ¸¬è©¦å¤±æ•—: {e}")
        traceback.print.exc()
        return False

def test_prune_block_with_downsample():
    """æ¸¬è©¦å‰ªæå¸¶æœ‰ downsample çš„å¡Š"""
    try:
        # è¨­ç½®è¨­å‚™
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è¨­å‚™: {device}")

        # åˆå§‹åŒ–æ¨¡å‹
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")

        # åˆå§‹åŒ–æ¨¡å‹å’Œè¼”åŠ©ç¶²è·¯ 
        model = Os2dModelInPrune(pretrained_path=os2d_path)
        model = model.to(device)
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)

        # é¸æ“‡ä¸€å€‹å¸¶æœ‰ downsample çš„å¡Š
        block_name = "layer2.0"
        
        # å‰µå»ºæ¸¬è©¦è¼¸å…¥
        batch_size = 2
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        boxes = [torch.tensor([[10, 10, 50, 50], [20, 20, 60, 60]], dtype=torch.float32).to(device) for _ in range(batch_size)]
        labels = [torch.tensor([0, 1], dtype=torch.long).to(device) for _ in range(batch_size)]

        # ç²å–åŸå§‹é€šé“æ•¸
        block = getattr(model.backbone, block_name.split('.')[0])[int(block_name.split('.')[1])]
        orig_channels = block.conv3.out_channels
        orig_downsample_channels = block.downsample[0].out_channels
        print(f"åŸå§‹ conv3 é€šé“æ•¸: {orig_channels}")
        print(f"åŸå§‹ downsample é€šé“æ•¸: {orig_downsample_channels}")

        # åŸ·è¡Œå‰ªæ
        prune_ratio = 0.3
        print(f"\nå‰ªæå¡Š {block_name}ï¼Œå‰ªææ¯”ä¾‹: {prune_ratio}...")
        success = model.prune_channel(f"{block_name}.conv3", prune_ratio=prune_ratio, 
                                    images=images, boxes=boxes, labels=labels, auxiliary_net=aux_net)

        # é©—è­‰å‰ªæçµæœ
        if success == "SKIPPED":
            print(f"âš ï¸ è·³éå‰ªæ {block_name}")
            return True

        # ç²å–å‰ªæå¾Œçš„é€šé“æ•¸
        block = getattr(model.backbone, block_name.split('.')[0])[int(block_name.split('.')[1])]
        pruned_channels = block.conv3.out_channels
        pruned_downsample_channels = block.downsample[0].out_channels
        
        print(f"å‰ªæå¾Œ conv3 é€šé“æ•¸: {pruned_channels}")
        print(f"å‰ªæå¾Œ downsample é€šé“æ•¸: {pruned_downsample_channels}")

        # é©—è­‰é€šé“æ•¸æ˜¯å¦ç¬¦åˆé æœŸ
        expected_channels = int(orig_channels * (1 - prune_ratio))
        assert pruned_channels == expected_channels, \
            f"conv3 é€šé“æ•¸ä¸åŒ¹é…: é æœŸ {expected_channels}, å¯¦éš› {pruned_channels}"
        assert pruned_downsample_channels == expected_channels, \
            f"downsample é€šé“æ•¸ä¸åŒ¹é…: é æœŸ {expected_channels}, å¯¦éš› {pruned_downsample_channels}"

        # æ¸¬è©¦å‰å‘å‚³æ’­
        class_images = [torch.randn(3, 224, 224).to(device)]
        with torch.no_grad():
            output = model(images, class_images)

        # æª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§
        print("\næª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§...")
        _test_all_layer_channel_consistency(model)

        print("\nâœ… å« downsample å¡Šå‰ªææ¸¬è©¦é€šé")
        return True

    except Exception as e:
        print(f"âŒ å« downsample å¡Šå‰ªææ¸¬è©¦å¤±æ•—: {e}")
        traceback.print_exc()
        return False

def test_prune_channel():
    """æ¸¬è©¦ OS2D å–®å±¤é€šé“å‰ªæåŠŸèƒ½"""
    try:
        # è¨­ç½®è¨­å‚™
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
        
        # è¼‰å…¥æ¨¡å‹
        print(f"ğŸ“¥ è¼‰å…¥ OS2D checkpoint: {os2d_path}")
        model = Os2dModelInPrune(pretrained_path=os2d_path)
        model = model.to(device)
        
        # åˆå§‹åŒ–è¼”åŠ©ç¶²è·¯
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
        
        # é¸æ“‡è¦å‰ªæçš„å±¤
        layer_name = "layer2.0.conv1"
        
        # ç²å–åŸå§‹é€šé“æ•¸
        target_layer = None
        for name, module in model.backbone.named_modules():
            if name == layer_name:
                target_layer = module
                break
        
        assert target_layer is not None, f"æ‰¾ä¸åˆ°å±¤: {layer_name}"
        orig_channels = target_layer.out_channels
        print(f"åŸå§‹é€šé“æ•¸: {orig_channels}")
        
        # è¨­ç½®å‰ªææ¯”ä¾‹
        prune_ratio = 0.3
        expected_channels = int(orig_channels * (1 - prune_ratio))
        
        # å‰µå»ºæ¸¬è©¦è¼¸å…¥
        batch_size = 2
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        boxes = [torch.tensor([[10, 10, 50, 50], [20, 20, 60, 60]], dtype=torch.float32).to(device) for _ in range(batch_size)]
        labels = [torch.tensor([0, 1], dtype=torch.long).to(device) for _ in range(batch_size)]
        
        # åŸ·è¡Œå‰ªæ
        print(f"å‰ªæå±¤ {layer_name}ï¼Œå‰ªææ¯”ä¾‹: {prune_ratio}")
        success = model.prune_channel(layer_name, prune_ratio=prune_ratio, images=images, boxes=boxes, labels=labels, auxiliary_net=aux_net)
        
        # é©—è­‰å‰ªæçµæœ
        assert success, "å‰ªææ“ä½œå¤±æ•—"
        
        # ç²å–å‰ªæå¾Œçš„é€šé“æ•¸
        pruned_layer = None
        for name, module in model.backbone.named_modules():
            if name == layer_name:
                pruned_layer = module
                break
        
        assert pruned_layer is not None, f"å‰ªæå¾Œæ‰¾ä¸åˆ°å±¤: {layer_name}"
        pruned_channels = pruned_layer.out_channels
        print(f"å‰ªæå¾Œé€šé“æ•¸: {pruned_channels}")
        
        # é©—è­‰é€šé“æ•¸æ˜¯å¦æ­£ç¢ºæ¸›å°‘
        assert pruned_channels == expected_channels, f"é€šé“æ•¸ä¸åŒ¹é…: é æœŸ {expected_channels}, å¯¦éš› {pruned_channels}"
        
        return True
    except Exception as e:
        print(f"âŒ OS2D prune channel æ¸¬è©¦å¤±æ•—: {e}")
        # traceback.print.exc()
        return False
        
def test_residual_connection_protection():
    """æ¸¬è©¦æ®˜å·®é€£æ¥ä¿è­·æ©Ÿåˆ¶"""
    try:
        # è¨­ç½®è¨­å‚™
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
        
        # åˆå§‹åŒ–è¼”åŠ©ç¶²è·¯
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
        
        # åˆå§‹åŒ–æ¨¡å‹
        model = Os2dModelInPrune(pretrained_path=os2d_path)
        model = model.to(device)
        
        # é¸æ“‡ä¸€å€‹æœ‰æ®˜å·®é€£æ¥çš„å±¤é€²è¡Œå‰ªæ
        layer_name = "layer2.0.conv3"  # æ­¤å±¤æœ‰æ®˜å·®é€£æ¥
        
        # ç²å–åŸå§‹é€šé“æ•¸
        target_layer = None
        for name, module in model.backbone.named_modules():
            if name == layer_name:
                target_layer = module
                break
        
        assert target_layer is not None, f"æ‰¾ä¸åˆ°å±¤: {layer_name}"
        orig_channels = target_layer.out_channels
        print(f"åŸå§‹é€šé“æ•¸: {orig_channels}")
        
        # ç²å–æ®˜å·®é€£æ¥å±¤
        downsample_layer = None
        for name, module in model.backbone.named_modules():
            if name == "layer2.0.downsample.0":
                downsample_layer = module
                break
        
        assert downsample_layer is not None, "æ‰¾ä¸åˆ°æ®˜å·®é€£æ¥å±¤"
        assert downsample_layer.out_channels == orig_channels, "æ®˜å·®é€£æ¥å±¤é€šé“æ•¸èˆ‡ç›®æ¨™å±¤ä¸ä¸€è‡´"
        
        # å‰µå»ºæ¸¬è©¦è¼¸å…¥
        batch_size = 2
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        boxes = [torch.tensor([[10, 10, 50, 50], [20, 20, 60, 60]], dtype=torch.float32).to(device) for _ in range(batch_size)]
        labels = [torch.tensor([0, 1], dtype=torch.long).to(device) for _ in range(batch_size)]
        
        # è¨­ç½®å‰ªææ¯”ä¾‹
        prune_ratio = 0.3
        expected_channels = int(orig_channels * (1 - prune_ratio))
        
        # åŸ·è¡Œå‰ªæ
        print(f"å‰ªæå±¤ {layer_name}ï¼Œå‰ªææ¯”ä¾‹: {prune_ratio}")
        success = model.prune_channel(layer_name, prune_ratio=prune_ratio, images=images, boxes=boxes, labels=labels, auxiliary_net=aux_net)
        
        # é©—è­‰å‰ªæçµæœ
        if success == "SKIPPED":
            print(f"âœ… æ­£ç¢ºè·³éäº† {layer_name} çš„å‰ªæ")
            # å¦‚æœè·³éäº†å‰ªæï¼Œå‰‡æœŸæœ›é€šé“æ•¸ä¸è®Š
            expected_channels = orig_channels
        else:
            assert success, "å‰ªææ“ä½œå¤±æ•—"
        
        # ç²å–å‰ªæå¾Œçš„é€šé“æ•¸
        pruned_layer = None
        for name, module in model.backbone.named_modules():
            if name == layer_name:
                pruned_layer = module
                break
        
        assert pruned_layer is not None, f"å‰ªæå¾Œæ‰¾ä¸åˆ°å±¤: {layer_name}"
        pruned_channels = pruned_layer.out_channels
        print(f"å‰ªæå¾Œé€šé“æ•¸: {pruned_channels}")
        
        # é©—è­‰é€šé“æ•¸æ˜¯å¦ç¬¦åˆé æœŸ
        assert pruned_channels == expected_channels, f"é€šé“æ•¸ä¸åŒ¹é…: é æœŸ {expected_channels}, å¯¦éš› {pruned_channels}"
        
        # é©—è­‰æ®˜å·®é€£æ¥å±¤æ˜¯å¦åŒæ­¥æ›´æ–°
        downsample_layer = None
        for name, module in model.backbone.named_modules():
            if name == "layer2.0.downsample.0":
                downsample_layer = module
                break
        
        assert downsample_layer is not None, "å‰ªæå¾Œæ‰¾ä¸åˆ°æ®˜å·®é€£æ¥å±¤"
        assert downsample_layer.out_channels == pruned_channels, f"æ®˜å·®é€£æ¥å±¤é€šé“æ•¸ä¸åŒ¹é…: é æœŸ {pruned_channels}, å¯¦éš› {downsample_layer.out_channels}"
        
        # æ¸¬è©¦å‰å‘å‚³æ’­
        class_images = [torch.randn(3, 224, 224).to(device)]
        with torch.no_grad():
            output = model(images, class_images)
            
        # æª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§ 
        print("\næª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§...")
        _test_all_layer_channel_consistency(model)
        
        print("âœ… æ®˜å·®é€£æ¥ä¿è­·æ¸¬è©¦é€šé")
        return True
    except Exception as e:
        print(f"âŒ æ®˜å·®é€£æ¥ä¿è­·æ¸¬è©¦å¤±æ•—: {e}")
        traceback.print_exc()
        return False

def test_residual_connection_pre_post_pruning():
    """æ¸¬è©¦æ®˜å·®é€£æ¥å‰ªæå‰å¾Œçš„å±¤é–“é—œä¿‚"""
    try:
        # è¨­ç½®è¨­å‚™
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
        
        # åˆå§‹åŒ–è¼”åŠ©ç¶²è·¯
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
        
        # åˆå§‹åŒ–æ¨¡å‹
        model = Os2dModelInPrune(pretrained_path=os2d_path)
        model = model.to(device)
        
        # é¸æ“‡è¦å‰ªæçš„å±¤
        layer_name = "layer2.0.conv3"  # æœ‰æ®˜å·®é€£æ¥çš„å±¤
        
        # è¨˜éŒ„å‰ªæå‰çš„å±¤é–“é—œä¿‚
        def get_layer_channels(model, layer_name):
            layer = None
            for name, module in model.backbone.named_modules():
                if name == layer_name:
                    layer = module
                    break
            return layer.out_channels if layer else None
        
        # ç²å–å‰ªæå‰çš„é€šé“æ•¸
        pre_prune_channels = get_layer_channels(model, layer_name)
        pre_prune_downsample = get_layer_channels(model, "layer2.0.downsample.0")
        
        print(f"å‰ªæå‰ {layer_name} é€šé“æ•¸: {pre_prune_channels}")
        print(f"å‰ªæå‰ downsample é€šé“æ•¸: {pre_prune_downsample}")
        
        # å‰µå»ºæ¸¬è©¦è¼¸å…¥
        batch_size = 2
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        boxes = [torch.tensor([[10, 10, 50, 50], [20, 20, 60, 60]], dtype=torch.float32).to(device) for _ in range(batch_size)]
        labels = [torch.tensor([0, 1], dtype=torch.long).to(device) for _ in range(batch_size)]
        
        # è¨­ç½®å‰ªææ¯”ä¾‹ä¸¦åŸ·è¡Œå‰ªæ
        prune_ratio = 0.3
        success = model.prune_channel(layer_name, prune_ratio=prune_ratio, images=images, boxes=boxes, labels=labels, auxiliary_net=aux_net)
        
        if success == "SKIPPED":
            print(f"âœ… æ­£ç¢ºè·³éäº† {layer_name} çš„å‰ªæ")
            return True
            
        # é©—è­‰å‰ªæçµæœ
        post_prune_channels = get_layer_channels(model, layer_name)
        post_prune_downsample = get_layer_channels(model, "layer2.0.downsample.0")
        
        print(f"å‰ªæå¾Œ {layer_name} é€šé“æ•¸: {post_prune_channels}")
        print(f"å‰ªæå¾Œ downsample é€šé“æ•¸: {post_prune_downsample}")
        
        # é©—è­‰æ®˜å·®é€£æ¥çš„ä¸€è‡´æ€§
        assert post_prune_channels == post_prune_downsample, \
            f"å‰ªæå¾Œé€šé“æ•¸ä¸ä¸€è‡´: {layer_name}={post_prune_channels}, downsample={post_prune_downsample}"
        
        # æ¸¬è©¦å‰å‘å‚³æ’­
        class_images = [torch.randn(3, 224, 224).to(device)]
        with torch.no_grad():
            output = model(images, class_images)
            
        # æª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§
        print("\næª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§...")
        _test_all_layer_channel_consistency(model)
        
        print("âœ… æ®˜å·®é€£æ¥å‰ªæå‰å¾Œé—œä¿‚æ¸¬è©¦é€šé")
        return True
    except Exception as e:
        print(f"âŒ æ®˜å·®é€£æ¥å‰ªæå‰å¾Œé—œä¿‚æ¸¬è©¦å¤±æ•—: {e}")
        traceback.print_exc()
        return False

def test_continuous_blocks_pruning():
    """æ¸¬è©¦é€£çºŒå¤šå€‹å¡Šçš„å‰ªæ"""
    try:
        # è¨­ç½®è¨­å‚™ 
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
        
        # åˆå§‹åŒ–è¼”åŠ©ç¶²è·¯
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
        
        # è¼‰å…¥æ¨¡å‹
        model = Os2dModelInPrune(pretrained_path=os2d_path) 
        model = model.to(device)
        
        # é¸æ“‡è¦å‰ªæçš„å¤šå€‹å¡Š
        blocks_to_prune = [
            "layer2.0.conv1",
            "layer2.0.conv2",
            "layer2.1.conv1", 
            "layer2.1.conv2"
        ]
        
        # å‰µå»ºæ¸¬è©¦è¼¸å…¥
        batch_size = 2
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        boxes = [torch.tensor([[10, 10, 50, 50], [20, 20, 60, 60]], dtype=torch.float32).to(device) for _ in range(batch_size)]
        labels = [torch.tensor([0, 1], dtype=torch.long).to(device) for _ in range(batch_size)]
        
        # è¨˜éŒ„åŸå§‹åƒæ•¸é‡
        orig_params = sum(p.numel() for p in model.parameters())
        print(f"åŸå§‹åƒæ•¸é‡: {orig_params:,}")
        
        # ä¾æ¬¡å°æ¯å€‹å¡Šé€²è¡Œå‰ªæ
        prune_ratio = 0.3
        for layer_name in blocks_to_prune:
            print(f"\nå‰ªæå±¤ {layer_name}...")
            success = model.prune_channel(layer_name, prune_ratio=prune_ratio, images=images, boxes=boxes, labels=labels, auxiliary_net=aux_net)
            if success == "SKIPPED":
                print(f"âš ï¸ è·³éå‰ªæ {layer_name}")
                continue
            assert success, f"å‰ªæ {layer_name} å¤±æ•—"
        
        # è¨ˆç®—æœ€çµ‚åƒæ•¸é‡
        final_params = sum(p.numel() for p in model.parameters())
        reduction = (orig_params - final_params) / orig_params * 100
        print(f"\nåƒæ•¸é‡æ¸›å°‘: {orig_params:,} -> {final_params:,} ({reduction:.2f}%)")
        
        # æ¸¬è©¦å‰å‘å‚³æ’­
        class_images = [torch.randn(3, 224, 224).to(device)]
        with torch.no_grad():
            output = model(images, class_images)
            
        # æª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§
        print("\næª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§...")
        _test_all_layer_channel_consistency(model)
        
        print("\nâœ… é€£çºŒå¡Šå‰ªææ¸¬è©¦é€šé")
        return True
        
    except Exception as e:
        print(f"âŒ é€£çºŒå¡Šå‰ªææ¸¬è©¦å¤±æ•—: {e}")
        traceback.print.exc()  
        return False

def test_prune_conv1_only():
    """æ¸¬è©¦åªå‰ªæ conv1 å±¤"""
    try:
        # è¨­ç½®è¨­å‚™
        device = 'cpu'
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
        # è¼‰å…¥æ¨¡å‹èˆ‡è¼”åŠ©ç¶²è·¯
        model = Os2dModelInPrune(pretrained_path=os2d_path).to(device)
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
        
        # é¸æ“‡è¦å‰ªæçš„ conv1 å±¤
        target_layers = [
            "layer1.0.conv1",
            "layer2.0.conv1", 
            "layer3.0.conv1",
            "layer4.0.conv1"
        ]
        
        # å‰µå»ºæ¸¬è©¦è¼¸å…¥
        batch_size = 1  # æ¸›å°‘æ‰¹æ¬¡å¤§å°
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        boxes = [torch.tensor([[10, 10, 50, 50]], dtype=torch.float32).to(device)]
        labels = [torch.tensor([0], dtype=torch.long).to(device)]
        
        # è¨˜éŒ„åŸå§‹åƒæ•¸é‡
        orig_params = sum(p.numel() for p in model.parameters())
        print(f"åŸå§‹åƒæ•¸é‡: {orig_params:,}")
        
        # å°æ¯å€‹ conv1 å±¤é€²è¡Œå‰ªæ
        prune_ratio = 0.3
        for layer_name in target_layers:
            print(f"\nå‰ªæå±¤ {layer_name}...")
            
            # ç²å–åŸå§‹é€šé“æ•¸
            orig_channels = None
            for name, module in model.backbone.named_modules():
                if name == layer_name:
                    orig_channels = module.out_channels
                    break
            
            if orig_channels is None:
                print(f"âš ï¸ æ‰¾ä¸åˆ°å±¤ {layer_name}")
                continue
                
            print(f"åŸå§‹é€šé“æ•¸: {orig_channels}")
            expected_channels = int(orig_channels * (1 - prune_ratio))
            print( f"é æœŸé€šé“æ•¸: {expected_channels}")
            # åŸ·è¡Œå‰ªæ
            success = model.prune_channel(
                layer_name=layer_name,
                prune_ratio=prune_ratio,
                images=images,
                boxes=boxes,
                labels=labels,
                auxiliary_net=aux_net
            )
            
            if success == "SKIPPED":
                print(f"âš ï¸ è·³éå‰ªæ {layer_name}")
                continue
                
            assert success, f"å‰ªæ {layer_name} å¤±æ•—"
            
            # é©—è­‰å‰ªæå¾Œçš„é€šé“æ•¸
            pruned_channels = None
            for name, module in model.backbone.named_modules():
                if name == layer_name:
                    pruned_channels = module.out_channels
                    break
            
            assert pruned_channels == expected_channels, \
                f"é€šé“æ•¸ä¸åŒ¹é…: é æœŸ {expected_channels}, å¯¦éš› {pruned_channels}"
                
        # è¨ˆç®—æœ€çµ‚åƒæ•¸é‡
        final_params = sum(p.numel() for p in model.parameters())
        reduction = (orig_params - final_params) / orig_params * 100
        print(f"\nåƒæ•¸é‡æ¸›å°‘: {orig_params:,} -> {final_params:,} ({reduction:.2f}%)")
        
        # model._print_model_summary()
        # æ¸¬è©¦å‰å‘å‚³æ’­
        class_images = [torch.randn(3, 224, 224).to(device)]
        with torch.no_grad():
            output = model(images, class_images)
            
        # æª¢æŸ¥channelä¸€è‡´æ€§
        print("\næª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§...")
        _test_all_layer_channel_consistency(model)
        
        print("\nâœ… Conv1 å‰ªææ¸¬è©¦é€šé")
        return True
        
    except Exception as e:
        print(f"âŒ Conv1 å‰ªææ¸¬è©¦å¤±æ•—: {e}")
        traceback.print.exc()
        return False

def test_prune_conv2_only():
    """æ¸¬è©¦åªå‰ªæ conv2 å±¤"""
    try:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
            
        # è¼‰å…¥æ¨¡å‹èˆ‡è¼”åŠ©ç¶²è·¯    
        model = Os2dModelInPrune(pretrained_path=os2d_path, is_cuda=(device.type == 'cuda')).to(device)
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
        
        # é¸æ“‡è¦å‰ªæçš„ conv2 å±¤
        target_layers = [
            "layer1.0.conv2",
            "layer2.0.conv2",
            "layer3.0.conv2"
            "layer4.0.conv2"
        ]
        
        # æ¸¬è©¦è¼¸å…¥
        batch_size = 1
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        boxes = [torch.tensor([[10, 10, 50, 50]], dtype=torch.float32).to(device)]
        labels = [torch.tensor([0], dtype=torch.long).to(device)]
        
        orig_params = sum(p.numel() for p in model.parameters())
        print(f"åŸå§‹åƒæ•¸é‡: {orig_params:,}")
        
        # å°æ¯å€‹ conv2 å±¤é€²è¡Œå‰ªæ
        prune_ratio = 0.3
        for layer_name in target_layers:
            print(f"\nå‰ªæå±¤ {layer_name}...")
            
            # ç²å–åŸå§‹é€šé“æ•¸
            orig_channels = None 
            for name, module in model.backbone.named_modules():
                if name == layer_name:
                    orig_channels = module.out_channels
                    break
                    
            if orig_channels is None:
                print(f"âš ï¸ æ‰¾ä¸åˆ°å±¤ {layer_name}")
                continue
                
            print(f"åŸå§‹é€šé“æ•¸: {orig_channels}")
            expected_channels = int(orig_channels * (1 - prune_ratio))
            
            # åŸ·è¡Œå‰ªæ
            success = model.prune_channel(
                layer_name=layer_name,
                prune_ratio=prune_ratio, 
                images=images,
                boxes=boxes,
                labels=labels,
                auxiliary_net=aux_net
            )
            
            if success == "SKIPPED":
                print(f"âš ï¸ è·³éå‰ªæ {layer_name}")
                continue
                
            assert success, f"å‰ªæ {layer_name} å¤±æ•—"
            
            # é©—è­‰å‰ªæçµæœ
            pruned_channels = None
            for name, module in model.backbone.named_modules():
                if name == layer_name:
                    pruned_channels = module.out_channels
                    break
                    
            assert pruned_channels == expected_channels, \
                f"é€šé“æ•¸ä¸åŒ¹é…: é æœŸ {expected_channels}, å¯¦éš› {pruned_channels}"
                
        # è¨ˆç®—åƒæ•¸é‡è®ŠåŒ–
        final_params = sum(p.numel() for p in model.parameters())
        reduction = (orig_params - final_params) / orig_params * 100
        print(f"\nåƒæ•¸é‡æ¸›å°‘: {orig_params:,} -> {final_params:,} ({reduction:.2f}%)")
        model._print_model_summary()
        # æ¸¬è©¦å‰å‘å‚³æ’­
        class_images = [torch.randn(3, 224, 224).to(device)]
        with torch.no_grad():
            output = model(images, class_images)
            
        # æª¢æŸ¥channelä¸€è‡´æ€§  
        print("\næª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§...")
        _test_all_layer_channel_consistency(model)
        
        print("\nâœ… Conv2 å‰ªææ¸¬è©¦é€šé")
        return True
        
    except Exception as e:
        print(f"âŒ Conv2 å‰ªææ¸¬è©¦å¤±æ•—: {e}")
        traceback.print.exc()
        return False

def test_prune_conv3_only():
    """æ¸¬è©¦åªå‰ªæ conv3 å±¤(åŒ…å«æ®˜å·®é€£æ¥)"""
    try:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
            
        # è¼‰å…¥æ¨¡å‹èˆ‡è¼”åŠ©ç¶²è·¯
        model = Os2dModelInPrune(pretrained_path=os2d_path).to(device)
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
        
        # é¸æ“‡è¦å‰ªæçš„ conv3 å±¤
        target_layers = [
            "layer1.0.conv3",
            "layer2.0.conv3",
            "layer3.0.conv3",
            "layer4.0.conv3"
        ]
        
        # æ¸¬è©¦è¼¸å…¥
        batch_size = 1
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        boxes = [torch.tensor([[10, 10, 50, 50]], dtype=torch.float32).to(device)]
        labels = [torch.tensor([0], dtype=torch.long).to(device)]
        
        orig_params = sum(p.numel() for p in model.parameters())
        print(f"åŸå§‹åƒæ•¸é‡: {orig_params:,}")
        
        # å°æ¯å€‹ conv3 å±¤é€²è¡Œå‰ªæ
        prune_ratio = 0.3
        for layer_name in target_layers:
            print(f"\nå‰ªæå±¤ {layer_name}...")
            
            # ç²å–åŸå§‹é€šé“æ•¸
            orig_channels = None
            for name, module in model.backbone.named_modules():
                if name == layer_name:
                    orig_channels = module.out_channels
                    break
                    
            if orig_channels is None:
                print(f"âš ï¸ æ‰¾ä¸åˆ°å±¤ {layer_name}")
                continue
                
            # ç²å–å°æ‡‰çš„æ®˜å·®å±¤
            block_name = ".".join(layer_name.split(".")[:2])
            downsample_name = f"{block_name}.downsample.0"
            
            print(f"åŸå§‹é€šé“æ•¸: {orig_channels}")
            expected_channels = int(orig_channels * (1 - prune_ratio))
            
            # åŸ·è¡Œå‰ªæ
            success = model.prune_channel(
                layer_name=layer_name,
                prune_ratio=prune_ratio,
                images=images, 
                boxes=boxes,
                labels=labels,
                auxiliary_net=aux_net
            )
            
            if success == "SKIPPED":
                print(f"âš ï¸ è·³éå‰ªæ {layer_name}")
                continue
                
            assert success, f"å‰ªæ {layer_name} å¤±æ•—"
            
            # é©—è­‰å‰ªæçµæœ
            pruned_channels = None
            downsample_channels = None
            for name, module in model.backbone.named_modules():
                if name == layer_name:
                    pruned_channels = module.out_channels
                elif name == downsample_name:
                    downsample_channels = module.out_channels
                    
            assert pruned_channels == expected_channels, \
                f"é€šé“æ•¸ä¸åŒ¹é…: é æœŸ {expected_channels}, å¯¦éš› {pruned_channels}"
                
            # é©—è­‰æ®˜å·®å±¤åŒæ­¥æ›´æ–°
            assert downsample_channels == pruned_channels, \
                f"æ®˜å·®å±¤é€šé“æ•¸ä¸åŒ¹é…: conv3={pruned_channels}, downsample={downsample_channels}"
                
        # è¨ˆç®—åƒæ•¸é‡è®ŠåŒ–
        final_params = sum(p.numel() for p in model.parameters())
        reduction = (orig_params - final_params) / orig_params * 100
        print(f"\nåƒæ•¸é‡æ¸›å°‘: {orig_params:,} -> {final_params:,} ({reduction:.2f}%)")
        
        # æ¸¬è©¦å‰å‘å‚³æ’­
        class_images = [torch.randn(3, 224, 224).to(device)]
        with torch.no_grad():
            output = model(images, class_images)
            
        # æª¢æŸ¥channelä¸€è‡´æ€§
        print("\næª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§...")
        _test_all_layer_channel_consistency(model)
        
        print("\nâœ… Conv3 å‰ªææ¸¬è©¦é€šé")
        return True
        
    except Exception as e:
        print(f"âŒ Conv3 å‰ªææ¸¬è©¦å¤±æ•—: {e}")
        traceback.print.exc()
        return False

def test_continuous_block_pruning():
    """æ¸¬è©¦é€£çºŒå‰ªææ•´å€‹æ®˜å·®å¡Š"""
    try:
        device = torch.device('cpu' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
            
        # è¼‰å…¥æ¨¡å‹èˆ‡è¼”åŠ©ç¶²è·¯
        model = Os2dModelInPrune(pretrained_path=os2d_path).to(device)
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
        
        # é¸æ“‡è¦é€£çºŒå‰ªæçš„å¡Š
        target_blocks = [
            ["layer2.0.conv1", "layer2.0.conv2", "layer2.0.conv3"],
            ["layer2.1.conv1", "layer2.1.conv2", "layer2.1.conv3"],
            ["layer3.0.conv1", "layer3.0.conv2", "layer3.0.conv3"]
        ]
        
        # æ¸¬è©¦è¼¸å…¥
        batch_size = 1
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        boxes = [torch.tensor([[10, 10, 50, 50]], dtype=torch.float32).to(device)]
        labels = [torch.tensor([0], dtype=torch.long).to(device)]
        
        orig_params = sum(p.numel() for p in model.parameters())
        print(f"åŸå§‹åƒæ•¸é‡: {orig_params:,}")
        
        # å°æ¯å€‹å¡Šé€²è¡Œé€£çºŒå‰ªæ
        prune_ratio = 0.3
        for block in target_blocks:
            print(f"\né–‹å§‹å‰ªæå¡Š {block[0].split('.')[0:2]}...")
            
            for layer_name in block:
                print(f"\nå‰ªæå±¤ {layer_name}...")
                
                # ç²å–åŸå§‹é€šé“æ•¸
                orig_channels = None
                for name, module in model.backbone.named_modules():
                    if name == layer_name:
                        orig_channels = module.out_channels
                        break
                        
                if orig_channels is None:
                    print(f"âš ï¸ æ‰¾ä¸åˆ°å±¤ {layer_name}")
                    continue
                    
                print(f"åŸå§‹é€šé“æ•¸: {orig_channels}")
                expected_channels = int(orig_channels * (1 - prune_ratio))
                
                # åŸ·è¡Œå‰ªæ
                success = model.prune_channel(
                    layer_name=layer_name,
                    prune_ratio=prune_ratio,
                    images=images,
                    boxes=boxes,
                    labels=labels,
                    auxiliary_net=aux_net
                )
                
                if success == "SKIPPED":
                    print(f"âš ï¸ è·³éå‰ªæ {layer_name}")
                    continue
                    
                assert success, f"å‰ªæ {layer_name} å¤±æ•—"
                
                # é©—è­‰å‰ªæçµæœ
                pruned_channels = None
                for name, module in model.backbone.named_modules():
                    if name == layer_name:
                        pruned_channels = module.out_channels
                        break
                        
                assert pruned_channels == expected_channels, \
                    f"é€šé“æ•¸ä¸åŒ¹é…: é æœŸ {expected_channels}, å¯¦éš› {pruned_channels}"
                    
            # æ¯å€‹å¡Šå‰ªæå®Œæˆå¾Œæ¸¬è©¦å‰å‘å‚³æ’­
            class_images = [torch.randn(3, 224, 224).to(device)]
            with torch.no_grad():
                output = model(images, class_images)
                
            # æª¢æŸ¥channelä¸€è‡´æ€§
            print("\næª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§...")
            _test_all_layer_channel_consistency(model)
                
        # è¨ˆç®—æœ€çµ‚åƒæ•¸é‡
        final_params = sum(p.numel() for p in model.parameters())
        reduction = (orig_params - final_params) / orig_params * 100
        print(f"\nåƒæ•¸é‡æ¸›å°‘: {orig_params:,} -> {final_params:,} ({reduction:.2f}%)")
        
        print("\nâœ… é€£çºŒå¡Šå‰ªææ¸¬è©¦é€šé")
        return True
        
    except Exception as e:
        print(f"âŒ é€£çºŒå¡Šå‰ªææ¸¬è©¦å¤±æ•—: {e}")
        traceback.print.exc()  
        return False

def test_prune_multiple_blocks():
    """æ¸¬è©¦é€£çºŒå‰ªå¤šå€‹ block"""
    try:
        device = torch.device('cpu' if torch.cuda.is_available() else 'cpu')
        print(f"\n===== æ¸¬è©¦é€£çºŒå‰ªå¤šå€‹ block =====")
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
            
        model = Os2dModelInPrune(pretrained_path=os2d_path).to(device)
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
        
        # å®šç¾©è¦å‰ªæçš„å¤šå€‹ block
        blocks_to_prune = [
            ["layer2.0.conv1", "layer2.0.conv2"],  # ç¬¬ä¸€å€‹ block
            ["layer2.1.conv1", "layer2.1.conv2"],  # ç¬¬äºŒå€‹ block
            ["layer3.0.conv1", "layer3.0.conv2"]   # ç¬¬ä¸‰å€‹ block
        ]
        
        # æ¸¬è©¦è¼¸å…¥
        batch_size = 1
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        boxes = [torch.tensor([[10, 10, 50, 50]], dtype=torch.float32).to(device)]
        labels = [torch.tensor([0], dtype=torch.long).to(device)]
        
        # è¨˜éŒ„åŸå§‹åƒæ•¸é‡
        orig_params = sum(p.numel() for p in model.parameters())
        print(f"åŸå§‹åƒæ•¸é‡: {orig_params:,}")
        
        # å°æ¯å€‹ block é€²è¡Œå‰ªæ
        prune_ratio = 0.3
        for block in blocks_to_prune:
            print(f"\nå‰ªæ block: {block}")
            for layer_name in block:
                print(f"\nå‰ªæå±¤ {layer_name}...")
                success = model.prune_channel(
                    layer_name=layer_name,
                    prune_ratio=prune_ratio,
                    images=images,
                    boxes=boxes,
                    labels=labels,
                    auxiliary_net=aux_net
                )
                
                if success == "SKIPPED":
                    print(f"âš ï¸ è·³éå‰ªæ {layer_name}")
                    continue
                    
                assert success, f"å‰ªæ {layer_name} å¤±æ•—"
                
            # æ¯å€‹ block å‰ªæå¾Œæ¸¬è©¦å‰å‘å‚³æ’­
            class_images = [torch.randn(3, 224, 224).to(device)]
            with torch.no_grad():
                output = model(images, class_images)
                
            # æª¢æŸ¥ channel ä¸€è‡´æ€§
            _test_all_layer_channel_consistency(model)
            
        # è¨ˆç®—åƒæ•¸é‡æ¸›å°‘
        final_params = sum(p.numel() for p in model.parameters())
        reduction = (orig_params - final_params) / orig_params * 100
        print(f"\nåƒæ•¸é‡æ¸›å°‘: {orig_params:,} -> {final_params:,} ({reduction:.2f}%)")
        
        print("\nâœ… é€£çºŒå‰ªå¤šå€‹ block æ¸¬è©¦é€šé")
        return True
        
    except Exception as e:
        print(f"âŒ é€£çºŒå‰ªå¤šå€‹ block æ¸¬è©¦å¤±æ•—: {e}")
        traceback.print_exc()
        return False

def test_cross_stage_prune():
    """æ¸¬è©¦è·¨ stage å‰ªæ"""
    try:
        device = torch.device('cpu' if torch.cuda.is_available() else 'cpu')
        print(f"\n===== æ¸¬è©¦è·¨ stage å‰ªæ =====")
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
            
        model = Os2dModelInPrune(pretrained_path=os2d_path).to(device)
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
        
        # å®šç¾©è·¨ stage çš„å‰ªæå±¤
        cross_stage_layers = [
            "layer2.3.conv2",  # layer2 æœ€å¾Œä¸€å€‹ block
            "layer3.0.conv1",  # layer3 ç¬¬ä¸€å€‹ block
        ]
        
        # æ¸¬è©¦è¼¸å…¥
        batch_size = 1
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        boxes = [torch.tensor([[10, 10, 50, 50]], dtype=torch.float32).to(device)]
        labels = [torch.tensor([0], dtype=torch.long).to(device)]
        
        orig_params = sum(p.numel() for p in model.parameters())
        print(f"åŸå§‹åƒæ•¸é‡: {orig_params:,}")
        
        # åŸ·è¡Œè·¨ stage å‰ªæ
        prune_ratio = 0.3
        for layer_name in cross_stage_layers:
            print(f"\nå‰ªæå±¤ {layer_name}...")
            success = model.prune_channel(
                layer_name=layer_name,
                prune_ratio=prune_ratio,
                images=images,
                boxes=boxes,
                labels=labels,
                auxiliary_net=aux_net
            )
            
            if success == "SKIPPED":
                print(f"âš ï¸ è·³éå‰ªæ {layer_name}")
                continue
                
            assert success, f"å‰ªæ {layer_name} å¤±æ•—"
            
            # æ¸¬è©¦å‰å‘å‚³æ’­
            class_images = [torch.randn(3, 224, 224).to(device)]
            with torch.no_grad():
                output = model(images, class_images)
                
            # æª¢æŸ¥ channel ä¸€è‡´æ€§
            _test_all_layer_channel_consistency(model)
            
        final_params = sum(p.numel() for p in model.parameters())
        reduction = (orig_params - final_params) / orig_params * 100
        print(f"\nåƒæ•¸é‡æ¸›å°‘: {orig_params:,} -> {final_params:,} ({reduction:.2f}%)")
        
        print("\nâœ… è·¨ stage å‰ªææ¸¬è©¦é€šé")
        return True
        
    except Exception as e:
        print(f"âŒ è·¨ stage å‰ªææ¸¬è©¦å¤±æ•—: {e}")
        traceback.print_exc()
        return False

def test_resnet18_basicblock_prune():
    """æ¸¬è©¦ ResNet18/34 BasicBlock å‰ªæ"""
    try:
        device = torch.device('cpu' if torch.cuda.is_available() else 'cpu')
        print(f"\n===== æ¸¬è©¦ ResNet18 BasicBlock å‰ªæ =====")
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # è¼‰å…¥ ResNet18 æ¨¡å‹
        model = torchvision.models.resnet18(weights=None).to(device)
        
        # å®šç¾©è¦å‰ªæçš„ BasicBlock å±¤
        basic_block_layers = [
            "layer1.0.conv1",
            "layer1.0.conv2",
            "layer2.0.conv1",
            "layer2.0.conv2"
        ]
        
        # æ¸¬è©¦è¼¸å…¥
        batch_size = 1
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        
        orig_params = sum(p.numel() for p in model.parameters())
        print(f"åŸå§‹åƒæ•¸é‡: {orig_params:,}")
        
        # åŸ·è¡Œ BasicBlock å‰ªæ
        prune_ratio = 0.3
        for layer_name in basic_block_layers:
            print(f"\nå‰ªæå±¤ {layer_name}...")
            
            # ç²å–åŸå§‹é€šé“æ•¸
            layer = None
            for name, module in model.named_modules():
                if name == layer_name:
                    layer = module
                    break
                    
            if layer is None:
                print(f"âš ï¸ æ‰¾ä¸åˆ°å±¤ {layer_name}")
                continue
                
            orig_channels = layer.out_channels
            expected_channels = int(orig_channels * (1 - prune_ratio))
            
            # åŸ·è¡Œå‰ªæ
            # é€™è£¡éœ€è¦å¯¦ç¾ BasicBlock çš„å‰ªæé‚è¼¯
            
            # æ¸¬è©¦å‰å‘å‚³æ’­
            with torch.no_grad():
                output = model(images)
                
        final_params = sum(p.numel() for p in model.parameters())
        reduction = (orig_params - final_params) / orig_params * 100
        print(f"\nåƒæ•¸é‡æ¸›å°‘: {orig_params:,} -> {final_params:,} ({reduction:.2f}%)")
        
        print("\nâœ… ResNet18 BasicBlock å‰ªææ¸¬è©¦é€šé")
        return True
        
    except Exception as e:
        print(f"âŒ ResNet18 BasicBlock å‰ªææ¸¬è©¦å¤±æ•—: {e}")
        traceback.print.exc()
        return False

def test_pruning_ratios(layer_name, model_fn=None):
    """æ¸¬è©¦ä¸åŒå‰ªæç‡å°æŒ‡å®šå±¤çš„å½±éŸ¿"""
    try:
        device = torch.device('cpu' if torch.cuda.is_available() else 'cpu')
        print(f"\n===== æ¸¬è©¦å‰ªæç‡ sweep {layer_name} =====")
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # å®šç¾©è¦æ¸¬è©¦çš„å‰ªæç‡
        pruning_ratios = [0.1, 0.2, 0.3, 0.4, 0.5]
        
        results = []
        for ratio in pruning_ratios:
            print(f"\næ¸¬è©¦å‰ªæç‡: {ratio}")
            
            # åˆå§‹åŒ–æ–°çš„æ¨¡å‹å¯¦ä¾‹
            if model_fn:
                model = model_fn().to(device)
            else:
                os2d_path = "./os2d_v2-train.pth"
                if not os.path.exists(os2d_path):
                    pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
                model = Os2dModelInPrune(pretrained_path=os2d_path).to(device)
                
            aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
            
            # æ¸¬è©¦è¼¸å…¥
            batch_size = 1
            images = torch.randn(batch_size, 3, 224, 224).to(device)
            boxes = [torch.tensor([[10, 10, 50, 50]], dtype=torch.float32).to(device)]
            labels = [torch.tensor([0], dtype=torch.long).to(device)]
            
            # è¨˜éŒ„åŸå§‹åƒæ•¸é‡
            orig_params = sum(p.numel() for p in model.parameters())
            
            # åŸ·è¡Œå‰ªæ
            success = model.prune_channel(
                layer_name=layer_name,
                prune_ratio=ratio,
                images=images,
                boxes=boxes,
                labels=labels,
                auxiliary_net=aux_net
            )
            
            if success == "SKIPPED":
                print(f"âš ï¸ è·³éå‰ªæ ratio={ratio}")
                continue
                
            assert success, f"å‰ªæå¤±æ•— ratio={ratio}"
            
            # è¨ˆç®—åƒæ•¸é‡æ¸›å°‘
            final_params = sum(p.numel() for p in model.parameters())
            reduction = (orig_params - final_params) / orig_params * 100
            
            # æ¸¬è©¦å‰å‘å‚³æ’­
            class_images = [torch.randn(3, 224, 224).to(device)]
            with torch.no_grad():
                output = model(images, class_images)
                
            # è¨˜éŒ„çµæœ
            results.append({
                'ratio': ratio,
                'param_reduction': reduction,
                'orig_params': orig_params,
                'final_params': final_params
            })
            
        # è¼¸å‡ºçµæœæ‘˜è¦
        print("\nå‰ªæç‡ sweep çµæœ:")
        for result in results:
            print(f"å‰ªæç‡ {result['ratio']:.1f}: åƒæ•¸æ¸›å°‘ {result['param_reduction']:.2f}% ({result['orig_params']:,} -> {result['final_params']:,})")
            
        print(f"\nâœ… å‰ªæç‡ sweep æ¸¬è©¦é€šé: {layer_name}")
        return True
        
    except Exception as e:
        print(f"âŒ å‰ªæç‡ sweep æ¸¬è©¦å¤±æ•—: {e}")
        return False

def test_lcp_channel_selector():
    """æ¸¬è©¦ LCP é€šé“é¸æ“‡å™¨åŸºæœ¬åŠŸèƒ½"""
    try:
        print("\n===== LCP é€šé“é¸æ“‡å™¨æ¸¬è©¦ =====")
        
        # è¨­ç½®è¨­å‚™
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # åˆå§‹åŒ–æ¨¡å‹èˆ‡è·¯å¾‘
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
        
        # è¼‰å…¥æ¨¡å‹èˆ‡è¼”åŠ©ç¶²è·¯    
        model = Os2dModelInPrune(pretrained_path=os2d_path).to(device)
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
        
        # åˆå§‹åŒ–é¸æ“‡å™¨
        selector = OS2DChannelSelector(
            model=model,
            auxiliary_net=aux_net,
            device=device,
            alpha=0.6,
            beta=0.3,
            gamma=0.1
        )
        
        # åŸºæœ¬å±¬æ€§é©—è­‰
        assert hasattr(selector, 'compute_importance'), "é¸æ“‡å™¨æ‡‰è©²æœ‰ compute_importance æ–¹æ³•"
        assert hasattr(selector, 'select_channels'), "é¸æ“‡å™¨æ‡‰è©²æœ‰ select_channels æ–¹æ³•"
        assert selector.model is model, "æ¨¡å‹åƒè€ƒéŒ¯èª¤"
        assert selector.auxiliary_net is aux_net, "è¼”åŠ©ç¶²è·¯åƒè€ƒéŒ¯èª¤"
        assert selector.device == device, "è¨­å‚™è¨­ç½®éŒ¯èª¤"
        
        print("âœ… LCP é€šé“é¸æ“‡å™¨åˆå§‹åŒ–æ¸¬è©¦é€šé")
        return True
        
    except Exception as e:
        print(f"âŒ LCP é€šé“é¸æ“‡å™¨æ¸¬è©¦å¤±æ•—: {e}")
        traceback.print_exc()
        return False

def test_channel_importance_computation():
    """æ¸¬è©¦é€šé“é‡è¦æ€§è¨ˆç®—åŠŸèƒ½"""
    try:
        print("\n===== é€šé“é‡è¦æ€§è¨ˆç®—æ¸¬è©¦ =====")
        
        # è¨­ç½®è¨­å‚™
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # åˆå§‹åŒ–æ¨¡å‹èˆ‡è·¯å¾‘
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
            
        # è¼‰å…¥æ¨¡å‹èˆ‡è¼”åŠ©ç¶²è·¯
        model = Os2dModelInPrune(pretrained_path=os2d_path).to(device)
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
        
        # åˆå§‹åŒ–é¸æ“‡å™¨
        selector = OS2DChannelSelector(
            model=model,
            auxiliary_net=aux_net,
            device=device
        )
        
        # æº–å‚™æ¸¬è©¦æ•¸æ“š
        batch_size = 2
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        
        # ç”Ÿæˆ class images (ä½¿ç”¨åŒä¸€æ‰¹æ¬¡ä¸­çš„ç¬¬ä¸€å¼µåœ–åƒ)
        class_images = [images[0].clone()]  # ä½¿ç”¨ç¬¬ä¸€å¼µåœ–ä½œç‚ºé¡åˆ¥åœ–åƒ
        
        # ç”Ÿæˆé‚Šç•Œæ¡†å’Œæ¨™ç±¤
        boxes = [torch.tensor([[10, 10, 50, 50]], dtype=torch.float32).to(device) for _ in range(batch_size)]
        labels = [torch.tensor([0], dtype=torch.long).to(device) for _ in range(batch_size)]
        
        # ä¿®æ”¹ forward pass
        def modified_forward():
            return model(images, class_images=class_images)
            
        # æ¸¬è©¦ä¸åŒå±¤çš„é€šé“é‡è¦æ€§è¨ˆç®—
        test_layers = [
            {"name": "layer2.0.conv1", "expected_channels": 128},
            {"name": "layer2.0.conv2", "expected_channels": 128},
            {"name": "layer3.0.conv1", "expected_channels": 256}
        ]
        
        for layer_info in test_layers:
            layer_name = layer_info["name"]
            expected_channels = layer_info["expected_channels"]
            print(f"\næ¸¬è©¦å±¤ {layer_name}...")
            
            # è¨ˆç®—é€šé“é‡è¦æ€§
            importance_scores = selector.compute_importance(
                layer_name=layer_name,
                images=images,
                boxes=boxes,
                gt_boxes=boxes,
                labels=labels
            )
            
            # é©—è­‰é‡è¦æ€§åˆ†æ•¸
            assert importance_scores is not None, f"{layer_name} importance_scores ä¸æ‡‰ç‚º None"
            assert len(importance_scores) == expected_channels, \
                f"{layer_name} importance_scores é•·åº¦ä¸ç¬¦: é æœŸ {expected_channels}, å¯¦éš› {len(importance_scores)}"
            print(f"âœ“ {layer_name} é‡è¦æ€§åˆ†æ•¸è¨ˆç®—æˆåŠŸ")
        
        print("\nâœ… é€šé“é‡è¦æ€§è¨ˆç®—æ¸¬è©¦é€šé")
        return True
        
    except Exception as e:
        print(f"âŒ é€šé“é‡è¦æ€§è¨ˆç®—æ¸¬è©¦å¤±æ•—: {e}")
        # traceback.print_exc()
        return False
def test_lcp_finetune_pipeline():
    """æ¸¬è©¦ LCP å¾®èª¿å‰ªæ pipeline"""
    try:
        print("\n===== æ¸¬è©¦ LCP å¾®èª¿å‰ªæ Pipeline =====")
        
        # è¨­ç½®è¨­å‚™
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # åˆå§‹åŒ–æ¨¡å‹å’Œè·¯å¾‘
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
        
        # è¼‰å…¥æ¨¡å‹èˆ‡è¼”åŠ©ç¶²è·¯
        model = Os2dModelInPrune(pretrained_path=os2d_path).to(device)
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
        
        # è¨­ç½® VOC2007 æ•¸æ“šé›†
        from src.dataset_downloader import VOCDataset
        
        # è¨“ç·´é›†
        train_loader = VOCDataset(
            data_path="./data/VOCdevkit/VOC2007",
            split="train",
            download=True
        )
        
        # é©—è­‰é›†
        val_loader = VOCDataset(
            data_path="./data/VOCdevkit/VOC2007",
            split="val",
            download=True
        )
        
        # å®šç¾©è¦å‰ªæçš„å±¤å’Œæ¯”ä¾‹
        pruning_config = [
            {"layer": "layer2.0.conv1", "ratio": 0.3},
            {"layer": "layer2.0.conv2", "ratio": 0.3},
            {"layer": "layer3.0.conv1", "ratio": 0.3}
        ]
        
        # è¨˜éŒ„åŸå§‹åƒæ•¸é‡
        orig_params = sum(p.numel() for p in model.parameters())
        print(f"åŸå§‹åƒæ•¸é‡: {orig_params:,}")
        
        # å®šç¾©è¨“ç·´åƒæ•¸
        num_epochs = 2
        learning_rate = 0.001
        
        # åŸ·è¡Œ fine-tuning å’Œå‰ªæ
        for epoch in range(num_epochs):
            print(f"\nEpoch {epoch+1}/{num_epochs}")
            
            # Training phase
            model.train()
            train_loss = 0.0
            for batch_idx, batch_data in enumerate(train_loader):
                if batch_idx >= 5:  # é™åˆ¶æ‰¹æ¬¡æ•¸ç”¨æ–¼æ¸¬è©¦
                    break
                # è§£ææ•¸æ“š
                if isinstance(batch_data, (tuple, list)):
                    if len(batch_data) == 4:
                        images, boxes, labels, _ = batch_data  # å¦‚æœæœ‰é¡å¤–çš„æ•¸æ“š
                    else:
                        images, boxes, labels = batch_data
                else:
                    # å‡è¨­ batch_data æ˜¯å­—å…¸æ ¼å¼
                    images = batch_data['images']
                    boxes = batch_data['boxes']
                    labels = batch_data['labels']

                # print(f"images type: {type(images)}")
                # if isinstance(images, list):
                #     print(f"images[0] shape: {images[0].shape}")
                # elif isinstance(images, torch.Tensor):
                #     print(f"images shape: {images.shape}")

                # è™•ç† images
                if isinstance(images, list):
                    images = torch.stack(images).to(device)  # [B, 3, H, W]
                elif isinstance(images, torch.Tensor):
                    if images.dim() == 3:
                        images = images.unsqueeze(0).to(device)  # [1, 3, H, W]
                    else:
                        images = images.to(device)
                else:
                    raise ValueError(f"images æ ¼å¼ä¸æ”¯æ´: {type(images)}")

                # print(f"images shape after stack: {images.shape}")

                # å– class_images
                images = torch.stack([img for img in images]).to(device)
                boxes = [b.to(device) for b in boxes]
                labels = [l.to(device) for l in labels]
                class_images = [images[0].clone()]
                assert class_images[0].shape[0] == 3, f"class_images shape éŒ¯èª¤: {class_images[0].shape}"
                
                # å‰å‘å‚³æ’­å’Œè¨ˆç®—æå¤±
                outputs = model(images, class_images=class_images)
                # é€™è£¡éœ€è¦å¯¦ç¾æå¤±è¨ˆç®—
                loss = outputs[0].mean()  # ç¤ºä¾‹æå¤±
                
                # åå‘å‚³æ’­å’Œå„ªåŒ–
                loss.backward()
                train_loss += loss.item()
                
                if batch_idx % 2 == 0:
                    print(f"Batch {batch_idx}, Loss: {loss.item():.4f}")
            
            # åŸ·è¡Œå‰ªæ
            for config in pruning_config:
                layer_name = config["layer"]
                prune_ratio = config["ratio"]
                print(f"\nå‰ªæå±¤ {layer_name}, æ¯”ä¾‹ {prune_ratio}")
                device = "cpu"
                success = model.prune_channel(
                    layer_name=layer_name,
                    prune_ratio=prune_ratio,
                    images=images,
                    boxes=boxes,
                    labels=labels,
                    auxiliary_net=aux_net
                )
                device = "cuda" if torch.cuda.is_available() else "cpu"
                for batch_idx, batch_data in enumerate(val_loader):
                    if batch_idx >= 3:  # é™åˆ¶æ‰¹æ¬¡æ•¸ç”¨æ–¼æ¸¬è©¦
                        break
                        
                    # è§£ææ•¸æ“š
                    if isinstance(batch_data, (tuple, list)):
                        if len(batch_data) == 4:
                            images, boxes, labels, _ = batch_data  # å¦‚æœæœ‰é¡å¤–çš„æ•¸æ“š
                        else:
                            images, boxes, labels = batch_data
                    else:
                        # å‡è¨­ batch_data æ˜¯å­—å…¸æ ¼å¼
                        images = batch_data['images']
                        boxes = batch_data['boxes']
                        labels = batch_data['labels']
                    
                    # ç§»å‹•æ•¸æ“šåˆ°è¨­å‚™
                    images = images.to(device)
                    boxes = [b.to(device) for b in boxes]
                    labels = [l.to(device) for l in labels]
            # Validation phase
            model.eval()
            val_loss = 0.0
            device = "cpu"
            with torch.no_grad():
                for batch_idx, batch_data in enumerate(val_loader):
                    if batch_idx >= 3:  # é™åˆ¶æ‰¹æ¬¡æ•¸ç”¨æ–¼æ¸¬è©¦
                        break
                        
                    # è§£ææ•¸æ“š
                    if isinstance(batch_data, (tuple, list)):
                        if len(batch_data) == 4:
                            images, boxes, labels, _ = batch_data  # å¦‚æœæœ‰é¡å¤–çš„æ•¸æ“š
                        else:
                            images, boxes, labels = batch_data
                    else:
                        # å‡è¨­ batch_data æ˜¯å­—å…¸æ ¼å¼
                        images = batch_data['images']
                        boxes = batch_data['boxes']
                        labels = batch_data['labels']
                        
                    # ç§»å‹•æ•¸æ“šåˆ°è¨­å‚™
                    images = images.to(device)
                    boxes = [b.to(device) for b in boxes]
                    labels = [l.to(device) for l in labels]
                    
                    if isinstance(images, list):
                        images = torch.stack(images).to(device)  # [B, 3, H, W]
                    elif isinstance(images, torch.Tensor):
                        if images.dim() == 3:
                            images = images.unsqueeze(0).to(device)  # [1, 3, H, W]
                        else:
                            images = images.to(device)
                    else:
                        raise ValueError(f"images æ ¼å¼ä¸æ”¯æ´: {type(images)}")

                    # print(f"images shape after stack: {images.shape}")

                    # å– class_images
                    images = torch.stack([img for img in images]).to(device)
                    boxes = [b.to(device) for b in boxes]
                    labels = [l.to(device) for l in labels]
                    class_images = [images[0].clone()]
                    assert class_images[0].shape[0] == 3, f"class_images shape éŒ¯èª¤: {class_images[0].shape}"
                
                    # å‰å‘å‚³æ’­
                    outputs = model(images, class_images=class_images)
                    # é€™è£¡éœ€è¦å¯¦ç¾é©—è­‰æå¤±è¨ˆç®—
                    loss = outputs[0].mean()  # ç¤ºä¾‹æå¤±
                    val_loss += loss.item()
            
            print(f"Epoch {epoch+1} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}")
            
            # æª¢æŸ¥ channel ä¸€è‡´æ€§
            _test_all_layer_channel_consistency(model)
        
        # è¨ˆç®—æœ€çµ‚åƒæ•¸é‡
        final_params = sum(p.numel() for p in model.parameters())
        reduction = (orig_params - final_params) / orig_params * 100
        print(f"\nåƒæ•¸é‡æ¸›å°‘: {orig_params:,} -> {final_params:,} ({reduction:.2f}%)")
        
        print("\nâœ… LCP å¾®èª¿å‰ªæ Pipeline æ¸¬è©¦é€šé")
        return True
        
    except Exception as e:
        print(f"âŒ LCP å¾®èª¿å‰ªæ Pipeline æ¸¬è©¦å¤±æ•—: {e}")
        traceback.print_exc()
        return False
def test_feature_map_extraction():
    """æ¸¬è©¦ LCP Channel Selector çš„ç‰¹å¾µåœ–æå–åŠŸèƒ½"""
    try:
        print("\n===== æ¸¬è©¦ç‰¹å¾µåœ–æå–åŠŸèƒ½ =====")
        
        # è¨­ç½®è¨­å‚™
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # åˆå§‹åŒ–æ¨¡å‹å’Œè·¯å¾‘
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
        
        # è¼‰å…¥æ¨¡å‹èˆ‡è¼”åŠ©ç¶²è·¯
        model = Os2dModelInPrune(pretrained_path=os2d_path).to(device)
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
        
        # å‰µå»ºé€šé“é¸æ“‡å™¨
        selector = OS2DChannelSelector(
            model=model,
            auxiliary_net=aux_net,
            device=device
        )
        
        # æº–å‚™æ¸¬è©¦æ•¸æ“š
        batch_size = 1
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        
        # æ¸¬è©¦ä¸åŒå±¤çš„ç‰¹å¾µåœ–æå–
        test_layers = [
            "layer1.0.conv1",
            "layer2.0.conv1",
            "layer3.0.conv1",
        ]
        
        # 1. é¦–å…ˆæ‰“å°æ‰€æœ‰å¯ç”¨å±¤åç¨±ä»¥ä¾›åƒè€ƒ
        print("\nç²å–æ‰€æœ‰å¯ç”¨å±¤åç¨±:")
        all_layers = {}
        for name, module in model.named_modules():
            if isinstance(module, torch.nn.Conv2d):
                all_layers[name] = module
        print(f"ç¸½å…±æ‰¾åˆ° {len(all_layers)} å€‹å·ç©å±¤")
        print("å‰10å€‹å·ç©å±¤åç¨±:")
        for idx, (name, _) in enumerate(all_layers.items()):
            if idx < 10:
                print(f"  - {name}")
        
        # 2. æ¸¬è©¦ä¸åŒæ–¹æ³•ç²å–ç‰¹å¾µåœ–
        success_count = 0
        for layer_name in test_layers:
            print(f"\næ¸¬è©¦å±¤ {layer_name} çš„ç‰¹å¾µåœ–æå–:")
            
            # æ‰‹å‹•æ·»åŠ  hook æå–ç‰¹å¾µåœ–
            feature_maps = {}
            
            def hook_fn(name):
                def inner_hook(module, input, output):
                    feature_maps[name] = output.detach()
                return inner_hook
            
            # å˜—è©¦ä¸åŒå¯èƒ½çš„å±¤è·¯å¾‘
            possible_layer_names = [
                f"net_feature_maps.{layer_name}",
                f"backbone.{layer_name}",
                layer_name
            ]
            
            hooks = []
            found_layer = False
            
            # è¨»å†Š hook
            for full_name in possible_layer_names:
                for name, module in model.named_modules():
                    if name == full_name and isinstance(module, torch.nn.Conv2d):
                        print(f"æ‰¾åˆ°å±¤: {name}")
                        hook = module.register_forward_hook(hook_fn(name))
                        hooks.append(hook)
                        found_layer = True
            
            if not found_layer:
                print(f"âŒ ç„¡æ³•æ‰¾åˆ°å±¤ {layer_name}")
                continue
                
            # å‰å‘å‚³æ’­
            with torch.no_grad():
                # å˜—è©¦ä¸åŒçš„å‰å‘å‚³æ’­æ–¹æ³•
                try:
                    # æº–å‚™ class_images
                    class_images = [images[0].clone()]
                    outputs = model(images, class_images=class_images)
                except TypeError:
                    print("æ¨¡å‹ä¸æ¥å— class_images åƒæ•¸ï¼Œä½¿ç”¨åŸºæœ¬æ¨¡å¼")
                    outputs = model(images)
            
            # æª¢æŸ¥æ˜¯å¦ç²å–åˆ°ç‰¹å¾µåœ–
            if feature_maps:
                success = True
                print(f"âœ“ é€šé hook æˆåŠŸç²å–ç‰¹å¾µåœ–:")
                for name, feature in feature_maps.items():
                    print(f"  - {name}: {feature.shape}")
                success_count += 1
            else:
                print(f"âŒ é€šé hook ç„¡æ³•ç²å–ç‰¹å¾µåœ–")
                success = False
            
            # ç§»é™¤ hooks
            for hook in hooks:
                hook.remove()
            
            # 3. æ¸¬è©¦ Channel Selector ä¸­çš„ _get_feature_maps æ–¹æ³•
            print("\nä½¿ç”¨ Channel Selector çš„ _get_feature_maps æ–¹æ³•:")
            feature_map, orig_feature_map = selector._get_feature_maps(layer_name, images)
            
            if feature_map is not None and orig_feature_map is not None:
                print(f"âœ“ æˆåŠŸç²å–ç‰¹å¾µåœ–: feature_map {feature_map.shape}, orig_feature_map {orig_feature_map.shape}")
                success_count += 1
            else:
                print("âŒ ä½¿ç”¨ _get_feature_maps æ–¹æ³•ç„¡æ³•ç²å–ç‰¹å¾µåœ–")
        
        # æ¸¬è©¦çµè«–
        if success_count > 0:
            print(f"\nâœ… ç‰¹å¾µåœ–æå–æ¸¬è©¦é€šé: {success_count} æ¬¡æˆåŠŸ")
        else:
            print("\nâŒ ç‰¹å¾µåœ–æå–æ¸¬è©¦å¤±æ•—: ç„¡æ³•ç²å–ä»»ä½•ç‰¹å¾µåœ–")
            
        # 4. æ¸¬è©¦ä¿®å¾©æ–¹æ¡ˆ - æ·»åŠ ç²å–ç‰¹å¾µåœ–çš„å‚™é¸æ–¹æ³•
        if success_count == 0:
            print("\nå˜—è©¦å¯¦ç¾ç‰¹å¾µåœ–æå–å‚™é¸æ–¹æ³•:")
            
            # æ·»åŠ  get_feature_map_backup æ–¹æ³•
            def get_feature_map_backup(model, layer_name, images):
                feature_maps = {}
                
                def hook_fn(name):
                    def inner_hook(module, input, output):
                        feature_maps[name] = output.detach()
                    return inner_hook
                
                # éæ­·æ‰€æœ‰å·ç©å±¤ä¸¦æŸ¥æ‰¾åŒ¹é…çš„
                hooks = []
                for name, module in model.named_modules():
                    if isinstance(module, torch.nn.Conv2d) and layer_name in name:
                        print(f"å˜—è©¦åŒ¹é…å±¤: {name}")
                        hook = module.register_forward_hook(hook_fn(name))
                        hooks.append(hook)
                
                try:
                    # å‰å‘å‚³æ’­
                    with torch.no_grad():
                        try:
                            # æº–å‚™ class_images
                            class_images = [images[0].clone()]
                            _ = model(images, class_images=class_images)
                        except TypeError:
                            _ = model(images)
                    
                    # æª¢æŸ¥æ˜¯å¦ç²å–åˆ°ç‰¹å¾µåœ–
                    if feature_maps:
                        key = next(iter(feature_maps.keys()))
                        return feature_maps[key]
                    return None
                
                finally:
                    # ç§»é™¤ hooks
                    for hook in hooks:
                        hook.remove()
            
            # æ¸¬è©¦å‚™é¸æ–¹æ³•
            for layer_name in test_layers:
                print(f"\næ¸¬è©¦å±¤ {layer_name} çš„å‚™é¸ç‰¹å¾µåœ–ç²å–æ–¹æ³•:")
                feature_map = get_feature_map_backup(model, layer_name, images)
                if feature_map is not None:
                    print(f"âœ“ å‚™é¸æ–¹æ³•æˆåŠŸç²å–ç‰¹å¾µåœ–: {feature_map.shape}")
                else:
                    print("âŒ å‚™é¸æ–¹æ³•ç„¡æ³•ç²å–ç‰¹å¾µåœ–")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç‰¹å¾µåœ–æå–æ¸¬è©¦ç™¼ç”ŸéŒ¯èª¤: {e}")
        traceback.print_exc()
        return False
if __name__ == "__main__":
    test_os2d_model_in_prune_initialization()
    test_os2d_model_in_prune_forward()
    test_forward_pass_with_class_images()
    test_set_layer_out_channels() 
    test_os2d_model_in_prune_channel()
    test_continuous_blocks_pruning()
    test_prune_conv1_only()
    test_prune_conv2_only()
    test_prune_conv3_only()
    test_continuous_block_pruning()
    test_prune_multiple_blocks()
    test_cross_stage_prune()
    test_resnet18_basicblock_prune()
    test_pruning_ratios("layer2.0.conv1")
    test_lcp_channel_selector()
    test_channel_importance_computation()
