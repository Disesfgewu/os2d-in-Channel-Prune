import os
import torch
import torchvision
import pytest
# import # traceback
import numpy as np
import unittest
from torch.utils.data import DataLoader
from unittest.mock import MagicMock, patch
from src.lcp_channel_selector import OS2DChannelSelector
from src.contextual_roi_align import ContextualRoIAlign
from src.auxiliary_network import AuxiliaryNetwork
from src.os2d_model_in_prune import Os2dModelInPrune
from src.dataset_downloader import VOCDataset , VOC_CLASSES

import logging


def test_grozi_dataset():
    """
    æ¸¬è©¦ OS2D å®˜æ–¹ Grozi-3.2k dataset/dataloader åŠŸèƒ½èˆ‡è³‡æ–™çµæ§‹
    """
    import os
    import pytest
    import torch
    import numpy as np
    import pandas as pd
    from os2d.data.dataset import build_grozi_dataset
    from os2d.data.dataloader import DataloaderOneShotDetection
    from os2d.modeling.box_coder import Os2dBoxCoder, BoxGridGenerator
    from os2d.structures.feature_map import FeatureMapSize

    data_path = "./data"
    grozi_csv = os.path.join(data_path, "grozi", "classes", "grozi.csv")
    if not os.path.exists(grozi_csv):
        print("\nâŒ Grozi-3.2k dataset not found. è«‹ä¾å®˜æ–¹èªªæ˜æ‰‹å‹•ä¸‹è¼‰ä¸¦è§£å£“è‡³ ./data/grozi/")
        pytest.skip("Grozi-3.2k dataset missing, test skipped.")
        return False

    # å»ºç«‹ datasetï¼ˆmini subset åŠ é€Ÿæ¸¬è©¦ï¼‰
    dataset = build_grozi_dataset(
        data_path=data_path,
        name="grozi-train-mini",  # åªå–2å¼µåœ–2é¡åˆ¥ï¼Œé©åˆå–®å…ƒæ¸¬è©¦
        eval_scale=224,
        cache_images=False
    )

    # é©—è­‰ dataset çµæ§‹
    assert hasattr(dataset, "gtboxframe")
    assert hasattr(dataset, "image_ids")
    assert hasattr(dataset, "image_file_names")
    assert hasattr(dataset, "get_name")
    assert hasattr(dataset, "get_eval_scale")
    assert hasattr(dataset, "get_class_ids")
    assert hasattr(dataset, "get_image_annotation_for_imageid")
    assert isinstance(dataset.image_ids, list) and len(dataset.image_ids) > 0
    assert isinstance(dataset.image_file_names, list) and len(dataset.image_file_names) > 0
    assert isinstance(dataset.gtboxframe, pd.DataFrame)
    print(f"âœ… Dataset çµæ§‹æ¸¬è©¦é€šé ({dataset.get_name()})ï¼Œå…± {len(dataset.image_ids)} å¼µåœ–ï¼Œ{len(dataset.get_class_ids())} é¡åˆ¥")

    # æ¸¬è©¦ get_class_ids, get_image_annotation_for_imageid
    class_ids = dataset.get_class_ids()
    assert isinstance(class_ids, (list, np.ndarray))
    image_id = dataset.image_ids[0]
    boxes = dataset.get_image_annotation_for_imageid(image_id)
    assert hasattr(boxes, "bbox_xyxy")
    assert hasattr(boxes, "get_field")
    print(f"âœ… å–®åœ–æ¨™è¨»æ¸¬è©¦é€šéï¼Œimage_id={image_id}ï¼Œboxesæ•¸={len(boxes)}")

    # å»ºç«‹ box_coder
    box_coder = Os2dBoxCoder(
        positive_iou_threshold=0.5,
        negative_iou_threshold=0.4,
        remap_classification_targets_iou_pos=0.5,
        remap_classification_targets_iou_neg=0.4,
        output_box_grid_generator=BoxGridGenerator(
            box_size=FeatureMapSize(w=16, h=16),
            box_stride=FeatureMapSize(w=16, h=16)
        ),
        function_get_feature_map_size=lambda img_size: FeatureMapSize(w=img_size.w // 16, h=img_size.h // 16),
        do_nms_across_classes=False
    )

    dataloader = DataloaderOneShotDetection(
        dataset=dataset,
        box_coder=box_coder,
        batch_size=1,
        img_normalization={"mean": [0.485, 0.456, 0.406], "std": [0.229, 0.224, 0.225]},
        gt_image_size=64,
        random_flip_batches=False,
        random_crop_size=None,
        random_color_distortion=False,
        pyramid_scales_eval=[1.0],
        do_augmentation=False
    )

    # æ¸¬è©¦ dataloader çš„ batch çµæ§‹
    batch = dataloader.get_batch(0)
    assert isinstance(batch, tuple) and len(batch) >= 9
    images, class_images, loc_targets, class_targets, batch_class_ids, class_image_sizes, box_inverse_transform, batch_boxes, batch_img_size = batch
    assert isinstance(images, torch.Tensor)
    assert isinstance(class_images, list)
    assert isinstance(loc_targets, torch.Tensor)
    assert isinstance(class_targets, torch.Tensor)
    print(f"âœ… Dataloader batch çµæ§‹æ¸¬è©¦é€šéï¼Œimages.shape={images.shape}, class_images={len(class_images)}")

    # æ¸¬è©¦ get_all_class_images
    batch_class_images, class_image_sizes, class_ids = dataloader.get_all_class_images()
    assert isinstance(batch_class_images, list)
    assert len(batch_class_images) == len(class_ids)
    print(f"âœ… get_all_class_images æ¸¬è©¦é€šéï¼Œclass_images={len(batch_class_images)}")

    print("ğŸ‰ test_grozi_dataset: OS2D Grozi dataset/dataloader åŠŸèƒ½æ¸¬è©¦å…¨éƒ¨é€šéï¼")
    return True


def test_os2d_dataset():
    """
    æ¸¬è©¦ OS2D å®˜æ–¹ build_dataset_by_name æ”¯æ´çš„æ‰€æœ‰è³‡æ–™é›†èƒ½æ­£ç¢ºåˆå§‹åŒ–
    """
    import os
    import pytest
    from os2d.data.dataset import build_dataset_by_name

    data_path = "./data"
    dataset_names = [
        "grozi-train-mini",
        "grozi-val-old-cl",
        "grozi-val-new-cl",
        "grozi-val-all"
        # ä½ å¯ä»¥æ ¹æ“šå®‰è£æƒ…æ³åŠ å…¥ "instre-all", "dairy", "paste-v", "paste-f" ç­‰
    ]
    for name in dataset_names:
        try:
            dataset = build_dataset_by_name(
                data_path=data_path,
                name=name,
                eval_scale=224,
                cache_images=False
            )
            assert hasattr(dataset, "get_name")
            assert dataset.get_name() == name
            print(f"âœ… Dataset {name} åˆå§‹åŒ–æˆåŠŸï¼Œimages={len(dataset.image_ids)}, classes={len(dataset.get_class_ids())}")
        except Exception as e:
            print(f"âš ï¸ Dataset {name} åˆå§‹åŒ–å¤±æ•—: {e}")
    print("ğŸ‰ test_os2d_dataset: build_dataset_by_name æ”¯æ´çš„è³‡æ–™é›†æ¸¬è©¦å®Œæˆ")
    return True


def test_os2d_dataloader():
    """
    æ¸¬è©¦ OS2D å®˜æ–¹ DataloaderOneShotDetection çš„ batch çµæ§‹èˆ‡ API
    """
    import os
    import pytest
    import torch
    from os2d.data.dataset import build_grozi_dataset
    from os2d.data.dataloader import DataloaderOneShotDetection
    from os2d.modeling.box_coder import Os2dBoxCoder, BoxGridGenerator
    from os2d.structures.feature_map import FeatureMapSize

    data_path = "./data"
    dataset = build_grozi_dataset(
        data_path=data_path,
        name="grozi-train-mini",
        eval_scale=224,
        cache_images=False
    )
    box_coder = Os2dBoxCoder(
        positive_iou_threshold=0.5,
        negative_iou_threshold=0.4,
        remap_classification_targets_iou_pos=0.5,
        remap_classification_targets_iou_neg=0.4,
        output_box_grid_generator=BoxGridGenerator(
            box_size=FeatureMapSize(w=16, h=16),
            box_stride=FeatureMapSize(w=16, h=16)
        ),
        function_get_feature_map_size=lambda img_size: FeatureMapSize(w=img_size.w // 16, h=img_size.h // 16),
        do_nms_across_classes=False
    )
    dataloader = DataloaderOneShotDetection(
        dataset=dataset,
        box_coder=box_coder,
        batch_size=1,
        img_normalization={"mean": [0.485, 0.456, 0.406], "std": [0.229, 0.224, 0.225]},
        gt_image_size=64,
        random_flip_batches=False,
        random_crop_size=None,
        random_color_distortion=False,
        pyramid_scales_eval=[1.0],
        do_augmentation=False
    )
    # æ¸¬è©¦ __len__ èˆ‡ get_batch
    assert len(dataloader) > 0
    batch = dataloader.get_batch(0)
    assert isinstance(batch, tuple) and len(batch) >= 9
    images, class_images, loc_targets, class_targets, batch_class_ids, class_image_sizes, box_inverse_transform, batch_boxes, batch_img_size = batch
    assert isinstance(images, torch.Tensor)
    assert isinstance(class_images, list)
    assert isinstance(loc_targets, torch.Tensor)
    assert isinstance(class_targets, torch.Tensor)
    print(f"âœ… Dataloader batch çµæ§‹æ¸¬è©¦é€šéï¼Œimages.shape={images.shape}, class_images={len(class_images)}")
    # æ¸¬è©¦ get_name, get_eval_scale
    assert hasattr(dataloader, "get_name")
    assert hasattr(dataloader, "get_eval_scale")
    print(f"âœ… Dataloader get_name={dataloader.get_name()}, eval_scale={dataloader.get_eval_scale()}")
    print("ğŸ‰ test_os2d_dataloader: OS2D DataloaderOneShotDetection åŠŸèƒ½æ¸¬è©¦å…¨éƒ¨é€šéï¼")
    return True

def test_os2d_model_in_prune_initialization():
    """æ¸¬è©¦ Os2dModelInPrune åˆå§‹åŒ–ï¼Œä¸¦å€åˆ†å­¸ç”Ÿæ¨¡å‹èˆ‡æ•™å¸«æ¨¡å‹åƒæ•¸é‡"""
    # è¨­ç½® logger
    logger = logging.getLogger("OS2D.test")
    
    # åˆå§‹åŒ–æ¨¡å‹
    os2d_path = "./os2d_v2-train.pth"
    if not os.path.exists(os2d_path):
        pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
    
    # åˆå§‹åŒ–æ¨¡å‹
    model = Os2dModelInPrune(logger=logger, pretrained_path=os2d_path)
    
    # é©—è­‰æ¨¡å‹çµæ§‹
    assert hasattr(model, 'net_feature_maps'), "æ¨¡å‹æ‡‰è©²æœ‰ net_feature_maps å±¬æ€§"
    assert hasattr(model, 'net_label_features'), "æ¨¡å‹æ‡‰è©²æœ‰ net_label_features å±¬æ€§"
    assert hasattr(model, 'os2d_head_creator'), "æ¨¡å‹æ‡‰è©²æœ‰ os2d_head_creator å±¬æ€§"
    
    # åˆ†é–‹è¨ˆç®—å­¸ç”Ÿæ¨¡å‹å’Œæ•™å¸«æ¨¡å‹çš„åƒæ•¸æ•¸é‡
    student_params = 0
    teacher_params = 0
    
    for name, param in model.named_parameters():
        if name.startswith('teacher_model'):
            teacher_params += param.numel()
        else:
            student_params += param.numel()
    
    total_params = student_params + teacher_params
    
    # è¼¸å‡ºå„éƒ¨åˆ†åƒæ•¸é‡
    print(f"æ¨¡å‹ç¸½åƒæ•¸é‡: {total_params:,}")
    print(f"  - å­¸ç”Ÿæ¨¡å‹åƒæ•¸é‡: {student_params:,}")
    print(f"  - æ•™å¸«æ¨¡å‹åƒæ•¸é‡: {teacher_params:,}")
    
    # å¦‚æœå­˜åœ¨æ•™å¸«æ¨¡å‹ï¼Œå‰‡é©—è­‰å­¸ç”Ÿå’Œæ•™å¸«æ¨¡å‹çš„åƒæ•¸é‡æ˜¯å¦æ¥è¿‘
    if teacher_params > 0:
        param_diff_ratio = abs(student_params - teacher_params) / max(student_params, teacher_params)
        print(f"  - å­¸ç”Ÿ/æ•™å¸«æ¨¡å‹åƒæ•¸é‡å·®ç•°æ¯”ä¾‹: {param_diff_ratio:.4f}")
        assert param_diff_ratio < 0.05, "å­¸ç”Ÿæ¨¡å‹èˆ‡æ•™å¸«æ¨¡å‹åƒæ•¸é‡å·®ç•°éå¤§ï¼Œæ‡‰è©²éå¸¸æ¥è¿‘"
    
    # ç¢ºä¿ç¸½åƒæ•¸é‡å¤§æ–¼0
    assert total_params > 0, "æ¨¡å‹åƒæ•¸æ•¸é‡æ‡‰è©²å¤§æ–¼ 0"
    
    # å¦‚æœåªéœ€è¦æŸ¥çœ‹å­¸ç”Ÿæ¨¡å‹åƒæ•¸é‡ï¼Œå¯ä»¥å–æ¶ˆä¸‹é¢çš„è¨»é‡‹
    # print(f"ç´”å­¸ç”Ÿæ¨¡å‹åƒæ•¸é‡: {student_params:,}")
    
    print("âœ… Os2dModelInPrune åˆå§‹åŒ–æ¸¬è©¦é€šé")
    return True

def test_os2d_model_in_prune_forward():
    """æ¸¬è©¦ Os2dModelInPrune å‰å‘å‚³æ’­"""
    # è¨­ç½® logger
    logger = logging.getLogger("OS2D.test")
    
    # åˆå§‹åŒ–æ¨¡å‹
    os2d_path = "./os2d_v2-train.pth"
    if not os.path.exists(os2d_path):
        pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cuda')
    model = Os2dModelInPrune(logger=logger, pretrained_path=os2d_path, is_cuda=(device.type == 'cuda'))
    model = model.to(device)
    
    # å‰µå»ºæ¸¬è©¦è¼¸å…¥
    batch_size = 2
    images = torch.randn(batch_size, 3, 224, 224).to(device)
    class_images = [torch.randn(3, 224, 224).to(device) for _ in range(2)]
    
    # åŸ·è¡Œå‰å‘å‚³æ’­
    with torch.no_grad():
        loc_scores, class_scores, class_scores_transform_detached, fm_size, transform_corners = model(images, class_images)
    
    # é©—è­‰è¼¸å‡º
    assert loc_scores is not None, "loc_scores ä¸æ‡‰ç‚º None"
    assert class_scores is not None, "class_scores ä¸æ‡‰ç‚º None"
    assert class_scores_transform_detached is not None, "class_scores_transform_detached ä¸æ‡‰ç‚º None"
    assert fm_size is not None, "fm_size ä¸æ‡‰ç‚º None"
    
    print("âœ… Os2dModelInPrune å‰å‘å‚³æ’­æ¸¬è©¦é€šé")
    return True

def test_os2d_model_in_prune_channel():
    """æ¸¬è©¦ Os2dModelInPrune é€šé“å‰ªæåŠŸèƒ½"""
    # è¨­ç½® logger
    logger = logging.getLogger("OS2D.test")
    
    # åˆå§‹åŒ–æ¨¡å‹
    os2d_path = "./os2d_v2-train.pth"
    if not os.path.exists(os2d_path):
        pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cuda')
    model = Os2dModelInPrune(logger=logger, pretrained_path=os2d_path, is_cuda=(device.type == 'cuda'))
    model = model.to(device)
    
    # åˆå§‹åŒ–è¼”åŠ©ç¶²è·¯
    aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
    
    # é¸æ“‡è¦å‰ªæçš„å±¤
    layer_name = "layer2.0.conv1"
    
    # ç²å–åŸå§‹é€šé“æ•¸
    target_layer = None
    for name, module in model.backbone.named_modules():
        if name == layer_name:
            target_layer = module
            break
    
    assert target_layer is not None, f"æ‰¾ä¸åˆ°å±¤: {layer_name}"
    orig_channels = target_layer.out_channels
    print(f"åŸå§‹é€šé“æ•¸: {orig_channels}")
    
    # è¨­ç½®å‰ªææ¯”ä¾‹
    prune_ratio = 0.3
    expected_channels = int(orig_channels * (1 - prune_ratio))
    
    # å‰µå»ºæ¸¬è©¦è¼¸å…¥
    batch_size = 2
    images = torch.randn(batch_size, 3, 224, 224).to(device)
    boxes = [torch.tensor([[10, 10, 50, 50], [20, 20, 60, 60]], dtype=torch.float32).to(device) for _ in range(batch_size)]
    labels = [torch.tensor([0, 1], dtype=torch.long).to(device) for _ in range(batch_size)]
    
    # åŸ·è¡Œå‰ªæ
    print(f"å‰ªæå±¤ {layer_name}ï¼Œå‰ªææ¯”ä¾‹: {prune_ratio}")
    success = model.prune_channel(layer_name, prune_ratio=prune_ratio, images=images, boxes=boxes, labels=labels, auxiliary_net=aux_net)
    
    # é©—è­‰å‰ªæçµæœ
    assert success, "å‰ªææ“ä½œå¤±æ•—"
    
    # ç²å–å‰ªæå¾Œçš„é€šé“æ•¸
    pruned_layer = None
    for name, module in model.backbone.named_modules():
        if name == layer_name:
            pruned_layer = module
            break
    
    assert pruned_layer is not None, f"å‰ªæå¾Œæ‰¾ä¸åˆ°å±¤: {layer_name}"
    pruned_channels = pruned_layer.out_channels
    print(f"å‰ªæå¾Œé€šé“æ•¸: {pruned_channels}")
    
    # é©—è­‰é€šé“æ•¸æ˜¯å¦æ­£ç¢ºæ¸›å°‘
    assert pruned_channels == expected_channels, f"é€šé“æ•¸ä¸åŒ¹é…: é æœŸ {expected_channels}, å¯¦éš› {pruned_channels}"
    
    # æ¸¬è©¦å‰å‘å‚³æ’­
    with torch.no_grad():
        loc_scores, class_scores, class_scores_transform_detached, fm_size, transform_corners = model(images, class_images)
    
    print("âœ… Os2dModelInPrune é€šé“å‰ªææ¸¬è©¦é€šé")
    return True

def test_forward_pass_with_class_images():
    """Test forward pass with class_images parameter"""
    try:
        # Setup device
        device = torch.device('cuda' if torch.cuda.is_available() else 'cuda')
        
        # Initialize model
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D pretrained model not found: {os2d_path}")
            
        model = Os2dModelInPrune(pretrained_path=os2d_path)
        model = model.to(device)
        
        # Create test inputs
        batch_size = 1
        x = torch.randn(batch_size, 3, 224, 224).to(device)
        class_images = [torch.randn(1, 3, 224, 224).to(device)]

        # Test forward pass
        print("\nTesting forward pass with class_images...")
        try:
            with torch.no_grad():
                output = model(x, class_images)
            print("âœ… Forward pass with class_images successful")
            return True
        except Exception as e:
            print(f"âŒ Forward pass failed: {e}")
            assert False, f"Forward pass failed: {e}"
            
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        # traceback.print_exc()
        return False

def test_set_layer_out_channels():
    """æ¸¬è©¦ set_layer_out_channels æ–¹æ³•"""
    try:
        # è¨­ç½®è¨­å‚™
        device = torch.device('cuda' if torch.cuda.is_available() else 'cuda')
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        model = Os2dModelInPrune(pretrained_path=os2d_path)
        model = model.to(device)
        
        # é¸æ“‡è¦æ¸¬è©¦çš„å±¤
        layer_name = "layer2.0.conv1"
        param_count = sum(p.numel() for p in model.parameters())
        print(f"æ¨¡å‹åƒæ•¸ç¸½æ•¸: {param_count}")
        # ç²å–åŸå§‹å±¤èˆ‡ä¸‹æ¸¸å±¤
        parts = layer_name.split('.')
        layer_str, block_idx, conv_name = parts[0], int(parts[1]), parts[2]
        block = getattr(model.backbone, layer_str)[block_idx]
        
        # ç²å–åŸå§‹é€šé“æ•¸
        conv_layer = getattr(block, conv_name)
        orig_out_channels = conv_layer.out_channels
        
        # ç²å–ä¸‹æ¸¸å±¤çš„åŸå§‹é€šé“æ•¸
        next_conv_name = f"conv{int(conv_name[-1])+1}"
        next_conv_layer = getattr(block, next_conv_name)
        orig_next_in_channels = next_conv_layer.in_channels
        
        # ç²å–å°æ‡‰ BatchNorm å±¤çš„åŸå§‹é€šé“æ•¸
        bn_name = conv_name.replace('conv', 'bn')
        bn_layer = getattr(block, bn_name)
        orig_bn_channels = bn_layer.num_features
        
        print(f"åŸå§‹å±¤çµæ§‹:")
        print(f"{layer_name}: out_channels={orig_out_channels}")
        print(f"{layer_str}.{block_idx}.{next_conv_name}: in_channels={orig_next_in_channels}")
        print(f"{layer_str}.{block_idx}.{bn_name}: num_features={orig_bn_channels}")
        
        # è¨­ç½®æ–°çš„é€šé“æ•¸
        new_out_channels = orig_out_channels // 2
        print(f"\nå°‡ {layer_name} çš„ out_channels è¨­ç‚º {new_out_channels}")
        
        # åŸ·è¡Œæ¸¬è©¦æ–¹æ³•
        success = model.set_layer_out_channels(layer_name, new_out_channels)
        assert success, "set_layer_out_channels æ–¹æ³•æ‡‰è©²è¿”å› True"
        
        # é‡æ–°ç²å–å±¤
        block = getattr(model.backbone, layer_str)[block_idx]
        conv_layer = getattr(block, conv_name)
        next_conv_layer = getattr(block, next_conv_name)
        bn_layer = getattr(block, bn_name)
        
        # é©—è­‰é€šé“æ•¸æ˜¯å¦æ­£ç¢ºæ›´æ–°
        print(f"\næ›´æ–°å¾Œçš„å±¤çµæ§‹:")
        print(f"{layer_name}: out_channels={conv_layer.out_channels}")
        print(f"{layer_str}.{block_idx}.{next_conv_name}: in_channels={next_conv_layer.in_channels}")
        print(f"{layer_str}.{block_idx}.{bn_name}: num_features={bn_layer.num_features}")
        param_count = sum(p.numel() for p in model.parameters())
        print(f"æ¨¡å‹åƒæ•¸ç¸½æ•¸: {param_count}")
        assert conv_layer.out_channels == new_out_channels, f"{layer_name} çš„ out_channels æ‡‰ç‚º {new_out_channels}"
        assert next_conv_layer.in_channels == new_out_channels, f"{layer_str}.{block_idx}.{next_conv_name} çš„ in_channels æ‡‰ç‚º {new_out_channels}"
        # Add test for forward pass with class_images
        print("\nTesting forward pass...") 
        x = torch.randn(1, 3, 224, 224).to(device)
        class_images = [torch.randn(3, 224, 224).to(device)]
        try:
            with torch.no_grad():
                output = model(x, class_images)  # Added class_images parameter
            print("âœ… Forward pass successful")
        except Exception as e:
            print(f"âŒ Forward pass failed: {e}")
            assert False, f"Forward pass failed: {e}"
        # æª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§
        print("\næª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§...")
        _test_all_layer_channel_consistency(model)
        
        print("\nâœ… set_layer_out_channels æ¸¬è©¦é€šé")
        return True
    except Exception as e:
        print(f"âŒ set_layer_out_channels æ¸¬è©¦å¤±æ•—: {e}")
        # import # traceback
        # traceback.print_exc()
        return False

def _test_all_layer_channel_consistency(model):
    """æª¢æŸ¥ backbone æ‰€æœ‰ conv/bn å±¤çš„ in/out channel æ˜¯å¦ä¸€è‡´"""
    backbone = model.backbone
    all_pass = True
    for layer_name in ['layer1', 'layer2', 'layer3', 'layer4']:
        if not hasattr(backbone, layer_name):
            continue
        layer = getattr(backbone, layer_name)
        for block_idx, block in enumerate(layer):
            prefix = f"{layer_name}.{block_idx}"
            # æª¢æŸ¥ conv1
            conv1 = getattr(block, 'conv1', None)
            bn1 = getattr(block, 'bn1', None)
            if conv1 is not None and bn1 is not None:
                if bn1.num_features != conv1.out_channels:
                    print(f"âŒ {prefix}.bn1.num_features({bn1.num_features}) != conv1.out_channels({conv1.out_channels})")
                    all_pass = False
                else:
                    print(f"âœ“ {prefix}.bn1.num_features({bn1.num_features}) == conv1.out_channels({conv1.out_channels})")
            
            # æª¢æŸ¥ conv2
            conv2 = getattr(block, 'conv2', None)
            bn2 = getattr(block, 'bn2', None)
            if conv2 is not None:
                # æª¢æŸ¥ conv2 in_channels == conv1 out_channels
                if conv1 is not None and conv2.in_channels != conv1.out_channels:
                    print(f"âŒ {prefix}.conv2.in_channels({conv2.in_channels}) != conv1.out_channels({conv1.out_channels})")
                    all_pass = False
                else:
                    print(f"âœ“ {prefix}.conv2.in_channels({conv2.in_channels}) == conv1.out_channels({conv1.out_channels})")
                
                if bn2 is not None:
                    if bn2.num_features != conv2.out_channels:
                        print(f"âŒ {prefix}.bn2.num_features({bn2.num_features}) != conv2.out_channels({conv2.out_channels})")
                        all_pass = False
                    else:
                        print(f"âœ“ {prefix}.bn2.num_features({bn2.num_features}) == conv2.out_channels({conv2.out_channels})")
            
            # æª¢æŸ¥ conv3
            conv3 = getattr(block, 'conv3', None)
            bn3 = getattr(block, 'bn3', None)
            if conv3 is not None:
                # æª¢æŸ¥ conv3 in_channels == conv2 out_channels
                if conv2 is not None and conv3.in_channels != conv2.out_channels:
                    print(f"âŒ {prefix}.conv3.in_channels({conv3.in_channels}) != conv2.out_channels({conv2.out_channels})")
                    all_pass = False
                else:
                    print(f"âœ“ {prefix}.conv3.in_channels({conv3.in_channels}) == conv2.out_channels({conv2.out_channels})")
                
                if bn3 is not None:
                    if bn3.num_features != conv3.out_channels:
                        print(f"âŒ {prefix}.bn3.num_features({bn3.num_features}) != conv3.out_channels({conv3.out_channels})")
                        all_pass = False
                    else:
                        print(f"âœ“ {prefix}.bn3.num_features({bn3.num_features}) == conv3.out_channels({conv3.out_channels})")
    
    if all_pass:
        print("âœ… æ‰€æœ‰å±¤çš„ channel å°æ‡‰æª¢æŸ¥é€šé")
    else:
        print("âŒ æœ‰å±¤çš„ channel å°æ‡‰éŒ¯èª¤ï¼Œè«‹æª¢æŸ¥ä¸Šæ–¹è¼¸å‡º")

def test_cross_block_residual_connection():
    """æ¸¬è©¦è·¨å¡Šæ®˜å·®é€£æ¥ä¿è­·æ©Ÿåˆ¶"""
    try:
        # è¨­ç½®è¨­å‚™
        device = torch.device('cuda' if torch.cuda.is_available() else 'cuda')
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
        
        # åˆå§‹åŒ–è¼”åŠ©ç¶²è·¯
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
        
        # åˆå§‹åŒ–æ¨¡å‹
        model = Os2dModelInPrune(pretrained_path=os2d_path)
        model = model.to(device)
        
        # é¸æ“‡ä¸€å€‹è·¨å¡Šé€£æ¥çš„å±¤é€²è¡Œå‰ªæ
        layer_name = "layer2.3.conv3"  # æ­¤å±¤å¯èƒ½é€£æ¥åˆ°ä¸‹ä¸€å€‹å¡Šçš„ conv1
        
        # ç²å–åŸå§‹é€šé“æ•¸
        target_layer = None
        for name, module in model.backbone.named_modules():
            if name == layer_name:
                target_layer = module
                break
        
        if target_layer is None:
            pytest.skip(f"æ‰¾ä¸åˆ°å±¤: {layer_name}ï¼Œå¯èƒ½æ˜¯å› ç‚ºæ¨¡å‹çµæ§‹ä¸åŒ")
        
        orig_channels = target_layer.out_channels
        print(f"åŸå§‹é€šé“æ•¸: {orig_channels}")
        
        # å‰µå»ºæ¸¬è©¦è¼¸å…¥
        batch_size = 2
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        boxes = [torch.tensor([[10, 10, 50, 50], [20, 20, 60, 60]], dtype=torch.float32).to(device) for _ in range(batch_size)]
        labels = [torch.tensor([0, 1], dtype=torch.long).to(device) for _ in range(batch_size)]
        
        # è¨­ç½®å‰ªææ¯”ä¾‹
        prune_ratio = 0.3
        expected_channels = int(orig_channels * (1 - prune_ratio))
        
        # åŸ·è¡Œå‰ªæ
        print(f"å‰ªæå±¤ {layer_name}ï¼Œå‰ªææ¯”ä¾‹: {prune_ratio}")
        success = model.prune_channel(layer_name, prune_ratio=prune_ratio, images=images, boxes=boxes, labels=labels, auxiliary_net=aux_net)
        
        # é©—è­‰å‰ªæçµæœ
        if success == "SKIPPED":
            print(f"âœ… æ­£ç¢ºè·³éäº† {layer_name} çš„å‰ªæ")
            # å¦‚æœè·³éäº†å‰ªæï¼Œå‰‡æœŸæœ›é€šé“æ•¸ä¸è®Š
            expected_channels = orig_channels
        else:
            assert success, "å‰ªææ“ä½œå¤±æ•—"
        
        # ç²å–å‰ªæå¾Œçš„é€šé“æ•¸
        pruned_layer = None
        for name, module in model.backbone.named_modules():
            if name == layer_name:
                pruned_layer = module
                break
        
        assert pruned_layer is not None, f"å‰ªæå¾Œæ‰¾ä¸åˆ°å±¤: {layer_name}"
        pruned_channels = pruned_layer.out_channels
        print(f"å‰ªæå¾Œé€šé“æ•¸: {pruned_channels}")
        
        # é©—è­‰é€šé“æ•¸æ˜¯å¦æ­£ç¢ºæ¸›å°‘
        assert pruned_channels == expected_channels, f"é€šé“æ•¸ä¸åŒ¹é…: é æœŸ {expected_channels}, å¯¦éš› {pruned_channels}"
        
        # æª¢æŸ¥ä¸‹ä¸€å€‹å¡Šçš„ç¬¬ä¸€å±¤æ˜¯å¦å·²æ›´æ–°
        next_layer_name = "layer3.0.conv1"
        next_layer = None
        for name, module in model.backbone.named_modules():
            if name == next_layer_name:
                next_layer = module
                break
        
        if next_layer is not None:
            assert next_layer.in_channels == pruned_channels, f"ä¸‹ä¸€å€‹å¡Šçš„è¼¸å…¥é€šé“æ•¸ä¸åŒ¹é…: é æœŸ {pruned_channels}, å¯¦éš› {next_layer.in_channels}"
            print(f"âœ“ ä¸‹ä¸€å€‹å¡Šçš„è¼¸å…¥é€šé“æ•¸å·²æ­£ç¢ºæ›´æ–°: {next_layer.in_channels}")
        
        # æ¸¬è©¦å‰å‘å‚³æ’­
        class_images = [torch.randn(3, 224, 224).to(device) for _ in range(batch_size)]
        with torch.no_grad():
            output = model(images, class_images)
            
        # æª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§
        print("\næª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§...")
        _test_all_layer_channel_consistency(model)
        
        print("âœ… è·¨å¡Šæ®˜å·®é€£æ¥ä¿è­·æ¸¬è©¦é€šé")
        return True
    except Exception as e:
        print(f"âŒ è·¨å¡Šæ®˜å·®é€£æ¥ä¿è­·æ¸¬è©¦å¤±æ•—: {e}")
        # traceback.print_exc()
        return False

def test_load_os2d_weights():
    """æ¸¬è©¦ OS2D æ¨¡å‹è¼‰å…¥æ¬Šé‡"""
    try:
        # è¨­ç½®è¨­å‚™
        device = torch.device('cuda' if torch.cuda.is_available() else 'cuda')
        
        # åˆå§‹åŒ–æ¨¡å‹
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
        
        # è¼‰å…¥æ¨¡å‹
        print(f"ğŸ“¥ è¼‰å…¥ OS2D checkpoint: {os2d_path}")
        model = Os2dModelInPrune(pretrained_path=os2d_path)
        
        # é©—è­‰æ¨¡å‹è¼‰å…¥æˆåŠŸ
        print("âœ… OS2D æ¬Šé‡è¼‰å…¥æˆåŠŸ")
        
        # é©—è­‰åƒæ•¸ç¸½å’Œ (ç°¡å–®çš„å®Œæ•´æ€§æª¢æŸ¥)
        param_sum = sum(p.sum().item() for p in model.parameters())
        print(f"âœ… æ¨¡å‹åƒæ•¸ç¸½å’Œ: {param_sum}")
        
        return True
    except Exception as e:
        print(f"âŒ OS2D æ¨¡å‹æ¸¬è©¦å¤±æ•—: {e}")
        # traceback.print_exc()
        return False
    
def test_get_feature_map():
    """æ¸¬è©¦ OS2D ç‰¹å¾µåœ–æå–åŠŸèƒ½"""
    try:
        # è¨­ç½®è¨­å‚™
        device = torch.device('cuda' if torch.cuda.is_available() else 'cuda')
        
        # åˆå§‹åŒ–æ¨¡å‹
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
        
        # è¼‰å…¥æ¨¡å‹
        print(f"ğŸ“¥ è¼‰å…¥ OS2D checkpoint: {os2d_path}")
        model = Os2dModelInPrune(pretrained_path=os2d_path)
        model = model.to(device)
        
        # å‰µå»ºæ¸¬è©¦è¼¸å…¥
        batch_size = 2
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        
        # æå–ç‰¹å¾µåœ–
        with torch.no_grad():
            features = model.get_feature_map(images)
        
        # é©—è­‰ç‰¹å¾µåœ–å½¢ç‹€
        print(f"âœ… ç‰¹å¾µåœ–å½¢ç‹€: {features.shape}")
        assert features.shape[0] == batch_size, f"æ‰¹æ¬¡å¤§å°ä¸åŒ¹é…: {features.shape[0]} != {batch_size}"
        
        # æª¢æŸ¥ç‰¹å¾µåœ–ç¶­åº¦
        assert len(features.shape) == 4, f"ç‰¹å¾µåœ–æ‡‰ç‚º4ç¶­å¼µé‡ï¼Œå¯¦éš›ç‚º{len(features.shape)}ç¶­"
        
        # é©—è­‰ç‰¹å¾µåœ–æœ‰å€¼
        assert torch.isfinite(features).all(), "ç‰¹å¾µåœ–åŒ…å«ç„¡é™å€¼"
        assert not torch.isnan(features).any(), "ç‰¹å¾µåœ–åŒ…å« NaN"
        
        # æª¢æŸ¥ç‰¹å¾µåœ–æ•¸å€¼ç¯„åœ
        print(f"ç‰¹å¾µåœ–æ•¸å€¼ç¯„åœ: [{features.min().item():.3f}, {features.max().item():.3f}]")
        
        print("âœ… OS2D ç‰¹å¾µåœ–æ¸¬è©¦é€šé")
        return True
    except Exception as e:
        print(f"âŒ OS2D ç‰¹å¾µåœ–æ¸¬è©¦å¤±æ•—: {e}")
        # traceback.print.exc()
        return False

def test_prune_block_with_downsample():
    """æ¸¬è©¦å‰ªæå¸¶æœ‰ downsample çš„å¡Š"""
    try:
        # è¨­ç½®è¨­å‚™
        device = torch.device('cuda' if torch.cuda.is_available() else 'cuda')
        print(f"ä½¿ç”¨è¨­å‚™: {device}")

        # åˆå§‹åŒ–æ¨¡å‹
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")

        # åˆå§‹åŒ–æ¨¡å‹å’Œè¼”åŠ©ç¶²è·¯ 
        model = Os2dModelInPrune(pretrained_path=os2d_path)
        model = model.to(device)
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)

        # é¸æ“‡ä¸€å€‹å¸¶æœ‰ downsample çš„å¡Š
        block_name = "layer2.0"
        
        # å‰µå»ºæ¸¬è©¦è¼¸å…¥
        batch_size = 2
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        boxes = [torch.tensor([[10, 10, 50, 50], [20, 20, 60, 60]], dtype=torch.float32).to(device) for _ in range(batch_size)]
        labels = [torch.tensor([0, 1], dtype=torch.long).to(device) for _ in range(batch_size)]

        # ç²å–åŸå§‹é€šé“æ•¸
        block = getattr(model.backbone, block_name.split('.')[0])[int(block_name.split('.')[1])]
        orig_channels = block.conv3.out_channels
        orig_downsample_channels = block.downsample[0].out_channels
        print(f"åŸå§‹ conv3 é€šé“æ•¸: {orig_channels}")
        print(f"åŸå§‹ downsample é€šé“æ•¸: {orig_downsample_channels}")

        # åŸ·è¡Œå‰ªæ
        prune_ratio = 0.3
        print(f"\nå‰ªæå¡Š {block_name}ï¼Œå‰ªææ¯”ä¾‹: {prune_ratio}...")
        success = model.prune_channel(f"{block_name}.conv3", prune_ratio=prune_ratio, 
                                    images=images, boxes=boxes, labels=labels, auxiliary_net=aux_net)

        # é©—è­‰å‰ªæçµæœ
        if success == "SKIPPED":
            print(f"âš ï¸ è·³éå‰ªæ {block_name}")
            return True

        # ç²å–å‰ªæå¾Œçš„é€šé“æ•¸
        block = getattr(model.backbone, block_name.split('.')[0])[int(block_name.split('.')[1])]
        pruned_channels = block.conv3.out_channels
        pruned_downsample_channels = block.downsample[0].out_channels
        
        print(f"å‰ªæå¾Œ conv3 é€šé“æ•¸: {pruned_channels}")
        print(f"å‰ªæå¾Œ downsample é€šé“æ•¸: {pruned_downsample_channels}")

        # é©—è­‰é€šé“æ•¸æ˜¯å¦ç¬¦åˆé æœŸ
        expected_channels = int(orig_channels * (1 - prune_ratio))
        assert pruned_channels == expected_channels, \
            f"conv3 é€šé“æ•¸ä¸åŒ¹é…: é æœŸ {expected_channels}, å¯¦éš› {pruned_channels}"
        assert pruned_downsample_channels == expected_channels, \
            f"downsample é€šé“æ•¸ä¸åŒ¹é…: é æœŸ {expected_channels}, å¯¦éš› {pruned_downsample_channels}"

        # æ¸¬è©¦å‰å‘å‚³æ’­
        class_images = [torch.randn(3, 224, 224).to(device)]
        with torch.no_grad():
            output = model(images, class_images)

        # æª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§
        print("\næª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§...")
        _test_all_layer_channel_consistency(model)

        print("\nâœ… å« downsample å¡Šå‰ªææ¸¬è©¦é€šé")
        return True

    except Exception as e:
        print(f"âŒ å« downsample å¡Šå‰ªææ¸¬è©¦å¤±æ•—: {e}")
        # traceback.print_exc()
        return False

def test_prune_channel():
    """æ¸¬è©¦ OS2D å–®å±¤é€šé“å‰ªæåŠŸèƒ½"""
    try:
        # è¨­ç½®è¨­å‚™
        device = torch.device('cuda' if torch.cuda.is_available() else 'cuda')
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
        
        # è¼‰å…¥æ¨¡å‹
        print(f"ğŸ“¥ è¼‰å…¥ OS2D checkpoint: {os2d_path}")
        model = Os2dModelInPrune(pretrained_path=os2d_path)
        model = model.to(device)
        
        # åˆå§‹åŒ–è¼”åŠ©ç¶²è·¯
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
        
        # é¸æ“‡è¦å‰ªæçš„å±¤
        layer_name = "layer2.0.conv1"
        
        # ç²å–åŸå§‹é€šé“æ•¸
        target_layer = None
        for name, module in model.backbone.named_modules():
            if name == layer_name:
                target_layer = module
                break
        
        assert target_layer is not None, f"æ‰¾ä¸åˆ°å±¤: {layer_name}"
        orig_channels = target_layer.out_channels
        print(f"åŸå§‹é€šé“æ•¸: {orig_channels}")
        
        # è¨­ç½®å‰ªææ¯”ä¾‹
        prune_ratio = 0.3
        expected_channels = int(orig_channels * (1 - prune_ratio))
        
        # å‰µå»ºæ¸¬è©¦è¼¸å…¥
        batch_size = 2
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        boxes = [torch.tensor([[10, 10, 50, 50], [20, 20, 60, 60]], dtype=torch.float32).to(device) for _ in range(batch_size)]
        labels = [torch.tensor([0, 1], dtype=torch.long).to(device) for _ in range(batch_size)]
        
        # åŸ·è¡Œå‰ªæ
        print(f"å‰ªæå±¤ {layer_name}ï¼Œå‰ªææ¯”ä¾‹: {prune_ratio}")
        success = model.prune_channel(layer_name, prune_ratio=prune_ratio, images=images, boxes=boxes, labels=labels, auxiliary_net=aux_net)
        
        # é©—è­‰å‰ªæçµæœ
        assert success, "å‰ªææ“ä½œå¤±æ•—"
        
        # ç²å–å‰ªæå¾Œçš„é€šé“æ•¸
        pruned_layer = None
        for name, module in model.backbone.named_modules():
            if name == layer_name:
                pruned_layer = module
                break
        
        assert pruned_layer is not None, f"å‰ªæå¾Œæ‰¾ä¸åˆ°å±¤: {layer_name}"
        pruned_channels = pruned_layer.out_channels
        print(f"å‰ªæå¾Œé€šé“æ•¸: {pruned_channels}")
        
        # é©—è­‰é€šé“æ•¸æ˜¯å¦æ­£ç¢ºæ¸›å°‘
        assert pruned_channels == expected_channels, f"é€šé“æ•¸ä¸åŒ¹é…: é æœŸ {expected_channels}, å¯¦éš› {pruned_channels}"
        
        return True
    except Exception as e:
        print(f"âŒ OS2D prune channel æ¸¬è©¦å¤±æ•—: {e}")
        # # traceback.print.exc()
        return False
        
def test_residual_connection_protection():
    """æ¸¬è©¦æ®˜å·®é€£æ¥ä¿è­·æ©Ÿåˆ¶"""
    try:
        # è¨­ç½®è¨­å‚™
        device = torch.device('cuda' if torch.cuda.is_available() else 'cuda')
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
        
        # åˆå§‹åŒ–è¼”åŠ©ç¶²è·¯
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
        
        # åˆå§‹åŒ–æ¨¡å‹
        model = Os2dModelInPrune(pretrained_path=os2d_path)
        model = model.to(device)
        
        # é¸æ“‡ä¸€å€‹æœ‰æ®˜å·®é€£æ¥çš„å±¤é€²è¡Œå‰ªæ
        layer_name = "layer2.0.conv3"  # æ­¤å±¤æœ‰æ®˜å·®é€£æ¥
        
        # ç²å–åŸå§‹é€šé“æ•¸
        target_layer = None
        for name, module in model.backbone.named_modules():
            if name == layer_name:
                target_layer = module
                break
        
        assert target_layer is not None, f"æ‰¾ä¸åˆ°å±¤: {layer_name}"
        orig_channels = target_layer.out_channels
        print(f"åŸå§‹é€šé“æ•¸: {orig_channels}")
        
        # ç²å–æ®˜å·®é€£æ¥å±¤
        downsample_layer = None
        for name, module in model.backbone.named_modules():
            if name == "layer2.0.downsample.0":
                downsample_layer = module
                break
        
        assert downsample_layer is not None, "æ‰¾ä¸åˆ°æ®˜å·®é€£æ¥å±¤"
        assert downsample_layer.out_channels == orig_channels, "æ®˜å·®é€£æ¥å±¤é€šé“æ•¸èˆ‡ç›®æ¨™å±¤ä¸ä¸€è‡´"
        
        # å‰µå»ºæ¸¬è©¦è¼¸å…¥
        batch_size = 2
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        boxes = [torch.tensor([[10, 10, 50, 50], [20, 20, 60, 60]], dtype=torch.float32).to(device) for _ in range(batch_size)]
        labels = [torch.tensor([0, 1], dtype=torch.long).to(device) for _ in range(batch_size)]
        
        # è¨­ç½®å‰ªææ¯”ä¾‹
        prune_ratio = 0.3
        expected_channels = int(orig_channels * (1 - prune_ratio))
        
        # åŸ·è¡Œå‰ªæ
        print(f"å‰ªæå±¤ {layer_name}ï¼Œå‰ªææ¯”ä¾‹: {prune_ratio}")
        success = model.prune_channel(layer_name, prune_ratio=prune_ratio, images=images, boxes=boxes, labels=labels, auxiliary_net=aux_net)
        
        # é©—è­‰å‰ªæçµæœ
        if success == "SKIPPED":
            print(f"âœ… æ­£ç¢ºè·³éäº† {layer_name} çš„å‰ªæ")
            # å¦‚æœè·³éäº†å‰ªæï¼Œå‰‡æœŸæœ›é€šé“æ•¸ä¸è®Š
            expected_channels = orig_channels
        else:
            assert success, "å‰ªææ“ä½œå¤±æ•—"
        
        # ç²å–å‰ªæå¾Œçš„é€šé“æ•¸
        pruned_layer = None
        for name, module in model.backbone.named_modules():
            if name == layer_name:
                pruned_layer = module
                break
        
        assert pruned_layer is not None, f"å‰ªæå¾Œæ‰¾ä¸åˆ°å±¤: {layer_name}"
        pruned_channels = pruned_layer.out_channels
        print(f"å‰ªæå¾Œé€šé“æ•¸: {pruned_channels}")
        
        # é©—è­‰é€šé“æ•¸æ˜¯å¦ç¬¦åˆé æœŸ
        assert pruned_channels == expected_channels, f"é€šé“æ•¸ä¸åŒ¹é…: é æœŸ {expected_channels}, å¯¦éš› {pruned_channels}"
        
        # é©—è­‰æ®˜å·®é€£æ¥å±¤æ˜¯å¦åŒæ­¥æ›´æ–°
        downsample_layer = None
        for name, module in model.backbone.named_modules():
            if name == "layer2.0.downsample.0":
                downsample_layer = module
                break
        
        assert downsample_layer is not None, "å‰ªæå¾Œæ‰¾ä¸åˆ°æ®˜å·®é€£æ¥å±¤"
        assert downsample_layer.out_channels == pruned_channels, f"æ®˜å·®é€£æ¥å±¤é€šé“æ•¸ä¸åŒ¹é…: é æœŸ {pruned_channels}, å¯¦éš› {downsample_layer.out_channels}"
        
        # æ¸¬è©¦å‰å‘å‚³æ’­
        class_images = [torch.randn(3, 224, 224).to(device)]
        with torch.no_grad():
            output = model(images, class_images)
            
        # æª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§ 
        print("\næª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§...")
        _test_all_layer_channel_consistency(model)
        
        print("âœ… æ®˜å·®é€£æ¥ä¿è­·æ¸¬è©¦é€šé")
        return True
    except Exception as e:
        print(f"âŒ æ®˜å·®é€£æ¥ä¿è­·æ¸¬è©¦å¤±æ•—: {e}")
        # traceback.print_exc()
        return False

def test_residual_connection_pre_post_pruning():
    """æ¸¬è©¦æ®˜å·®é€£æ¥å‰ªæå‰å¾Œçš„å±¤é–“é—œä¿‚"""
    try:
        # è¨­ç½®è¨­å‚™
        device = torch.device('cuda' if torch.cuda.is_available() else 'cuda')
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
        
        # åˆå§‹åŒ–è¼”åŠ©ç¶²è·¯
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
        
        # åˆå§‹åŒ–æ¨¡å‹
        model = Os2dModelInPrune(pretrained_path=os2d_path)
        model = model.to(device)
        
        # é¸æ“‡è¦å‰ªæçš„å±¤
        layer_name = "layer2.0.conv3"  # æœ‰æ®˜å·®é€£æ¥çš„å±¤
        
        # è¨˜éŒ„å‰ªæå‰çš„å±¤é–“é—œä¿‚
        def get_layer_channels(model, layer_name):
            layer = None
            for name, module in model.backbone.named_modules():
                if name == layer_name:
                    layer = module
                    break
            return layer.out_channels if layer else None
        
        # ç²å–å‰ªæå‰çš„é€šé“æ•¸
        pre_prune_channels = get_layer_channels(model, layer_name)
        pre_prune_downsample = get_layer_channels(model, "layer2.0.downsample.0")
        
        print(f"å‰ªæå‰ {layer_name} é€šé“æ•¸: {pre_prune_channels}")
        print(f"å‰ªæå‰ downsample é€šé“æ•¸: {pre_prune_downsample}")
        
        # å‰µå»ºæ¸¬è©¦è¼¸å…¥
        batch_size = 2
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        boxes = [torch.tensor([[10, 10, 50, 50], [20, 20, 60, 60]], dtype=torch.float32).to(device) for _ in range(batch_size)]
        labels = [torch.tensor([0, 1], dtype=torch.long).to(device) for _ in range(batch_size)]
        
        # è¨­ç½®å‰ªææ¯”ä¾‹ä¸¦åŸ·è¡Œå‰ªæ
        prune_ratio = 0.3
        success = model.prune_channel(layer_name, prune_ratio=prune_ratio, images=images, boxes=boxes, labels=labels, auxiliary_net=aux_net)
        
        if success == "SKIPPED":
            print(f"âœ… æ­£ç¢ºè·³éäº† {layer_name} çš„å‰ªæ")
            return True
            
        # é©—è­‰å‰ªæçµæœ
        post_prune_channels = get_layer_channels(model, layer_name)
        post_prune_downsample = get_layer_channels(model, "layer2.0.downsample.0")
        
        print(f"å‰ªæå¾Œ {layer_name} é€šé“æ•¸: {post_prune_channels}")
        print(f"å‰ªæå¾Œ downsample é€šé“æ•¸: {post_prune_downsample}")
        
        # é©—è­‰æ®˜å·®é€£æ¥çš„ä¸€è‡´æ€§
        assert post_prune_channels == post_prune_downsample, \
            f"å‰ªæå¾Œé€šé“æ•¸ä¸ä¸€è‡´: {layer_name}={post_prune_channels}, downsample={post_prune_downsample}"
        
        # æ¸¬è©¦å‰å‘å‚³æ’­
        class_images = [torch.randn(3, 224, 224).to(device)]
        with torch.no_grad():
            output = model(images, class_images)
            
        # æª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§
        print("\næª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§...")
        _test_all_layer_channel_consistency(model)
        
        print("âœ… æ®˜å·®é€£æ¥å‰ªæå‰å¾Œé—œä¿‚æ¸¬è©¦é€šé")
        return True
    except Exception as e:
        print(f"âŒ æ®˜å·®é€£æ¥å‰ªæå‰å¾Œé—œä¿‚æ¸¬è©¦å¤±æ•—: {e}")
        # traceback.print_exc()
        return False

def test_continuous_blocks_pruning():
    """æ¸¬è©¦é€£çºŒå¤šå€‹å¡Šçš„å‰ªæ"""
    try:
        # è¨­ç½®è¨­å‚™ 
        device = torch.device('cuda' if torch.cuda.is_available() else 'cuda')
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
        
        # åˆå§‹åŒ–è¼”åŠ©ç¶²è·¯
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
        
        # è¼‰å…¥æ¨¡å‹
        model = Os2dModelInPrune(pretrained_path=os2d_path) 
        model = model.to(device)
        
        # é¸æ“‡è¦å‰ªæçš„å¤šå€‹å¡Š
        blocks_to_prune = [
            "layer2.0.conv1",
            "layer2.0.conv2",
            "layer2.1.conv1", 
            "layer2.1.conv2"
        ]
        
        # å‰µå»ºæ¸¬è©¦è¼¸å…¥
        batch_size = 2
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        boxes = [torch.tensor([[10, 10, 50, 50], [20, 20, 60, 60]], dtype=torch.float32).to(device) for _ in range(batch_size)]
        labels = [torch.tensor([0, 1], dtype=torch.long).to(device) for _ in range(batch_size)]
        
        # è¨˜éŒ„åŸå§‹åƒæ•¸é‡
        orig_params = sum(p.numel() for p in model.parameters())
        print(f"åŸå§‹åƒæ•¸é‡: {orig_params:,}")
        
        # ä¾æ¬¡å°æ¯å€‹å¡Šé€²è¡Œå‰ªæ
        prune_ratio = 0.3
        for layer_name in blocks_to_prune:
            print(f"\nå‰ªæå±¤ {layer_name}...")
            success = model.prune_channel(layer_name, prune_ratio=prune_ratio, images=images, boxes=boxes, labels=labels, auxiliary_net=aux_net)
            if success == "SKIPPED":
                print(f"âš ï¸ è·³éå‰ªæ {layer_name}")
                continue
            assert success, f"å‰ªæ {layer_name} å¤±æ•—"
        
        # è¨ˆç®—æœ€çµ‚åƒæ•¸é‡
        final_params = sum(p.numel() for p in model.parameters())
        reduction = (orig_params - final_params) / orig_params * 100
        print(f"\nåƒæ•¸é‡æ¸›å°‘: {orig_params:,} -> {final_params:,} ({reduction:.2f}%)")
        
        # æ¸¬è©¦å‰å‘å‚³æ’­
        class_images = [torch.randn(3, 224, 224).to(device)]
        with torch.no_grad():
            output = model(images, class_images)
            
        # æª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§
        print("\næª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§...")
        _test_all_layer_channel_consistency(model)
        
        print("\nâœ… é€£çºŒå¡Šå‰ªææ¸¬è©¦é€šé")
        return True
        
    except Exception as e:
        print(f"âŒ é€£çºŒå¡Šå‰ªææ¸¬è©¦å¤±æ•—: {e}")
        # traceback.print.exc()  
        return False

def test_prune_conv1_only():
    """æ¸¬è©¦åªå‰ªæ conv1 å±¤"""
    try:
        # è¨­ç½®è¨­å‚™
        device = 'cuda' if torch.cuda.is_available() else 'cuda'
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
        # è¼‰å…¥æ¨¡å‹èˆ‡è¼”åŠ©ç¶²è·¯
        model = Os2dModelInPrune(pretrained_path=os2d_path).to(device)
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
        
        # é¸æ“‡è¦å‰ªæçš„ conv1 å±¤
        target_layers = [
            "layer1.0.conv1",
            "layer2.0.conv1", 
            "layer3.0.conv1",
            "layer4.0.conv1"
        ]
        
        # å‰µå»ºæ¸¬è©¦è¼¸å…¥
        batch_size = 1  # æ¸›å°‘æ‰¹æ¬¡å¤§å°
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        boxes = [torch.tensor([[10, 10, 50, 50]], dtype=torch.float32).to(device)]
        labels = [torch.tensor([0], dtype=torch.long).to(device)]
        
        # è¨˜éŒ„åŸå§‹åƒæ•¸é‡
        orig_params = sum(p.numel() for p in model.parameters())
        print(f"åŸå§‹åƒæ•¸é‡: {orig_params:,}")
        
        # å°æ¯å€‹ conv1 å±¤é€²è¡Œå‰ªæ
        prune_ratio = 0.3
        for layer_name in target_layers:
            print(f"\nå‰ªæå±¤ {layer_name}...")
            
            # ç²å–åŸå§‹é€šé“æ•¸
            orig_channels = None
            for name, module in model.backbone.named_modules():
                if name == layer_name:
                    orig_channels = module.out_channels
                    break
            
            if orig_channels is None:
                print(f"âš ï¸ æ‰¾ä¸åˆ°å±¤ {layer_name}")
                continue
                
            print(f"åŸå§‹é€šé“æ•¸: {orig_channels}")
            expected_channels = int(orig_channels * (1 - prune_ratio))
            print( f"é æœŸé€šé“æ•¸: {expected_channels}")
            # åŸ·è¡Œå‰ªæ
            success = model.prune_channel(
                layer_name=layer_name,
                prune_ratio=prune_ratio,
                images=images,
                boxes=boxes,
                labels=labels,
                auxiliary_net=aux_net
            )
            
            if success == "SKIPPED":
                print(f"âš ï¸ è·³éå‰ªæ {layer_name}")
                continue
                
            assert success, f"å‰ªæ {layer_name} å¤±æ•—"
            
            # é©—è­‰å‰ªæå¾Œçš„é€šé“æ•¸
            pruned_channels = None
            for name, module in model.backbone.named_modules():
                if name == layer_name:
                    pruned_channels = module.out_channels
                    break
            
            assert pruned_channels == expected_channels, \
                f"é€šé“æ•¸ä¸åŒ¹é…: é æœŸ {expected_channels}, å¯¦éš› {pruned_channels}"
                
        # è¨ˆç®—æœ€çµ‚åƒæ•¸é‡
        final_params = sum(p.numel() for p in model.parameters())
        reduction = (orig_params - final_params) / orig_params * 100
        print(f"\nåƒæ•¸é‡æ¸›å°‘: {orig_params:,} -> {final_params:,} ({reduction:.2f}%)")
        
        # model._print_model_summary()
        # æ¸¬è©¦å‰å‘å‚³æ’­
        class_images = [torch.randn(3, 224, 224).to(device)]
        with torch.no_grad():
            output = model(images, class_images)
            
        # æª¢æŸ¥channelä¸€è‡´æ€§
        print("\næª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§...")
        _test_all_layer_channel_consistency(model)
        
        print("\nâœ… Conv1 å‰ªææ¸¬è©¦é€šé")
        return True
        
    except Exception as e:
        print(f"âŒ Conv1 å‰ªææ¸¬è©¦å¤±æ•—: {e}")
        # # traceback.print.exc()
        return False

def test_prune_conv2_only():
    """æ¸¬è©¦åªå‰ªæ conv2 å±¤"""
    try:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cuda')
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
            
        # è¼‰å…¥æ¨¡å‹èˆ‡è¼”åŠ©ç¶²è·¯    
        model = Os2dModelInPrune(pretrained_path=os2d_path, is_cuda=(device.type == 'cuda')).to(device)
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
        
        # é¸æ“‡è¦å‰ªæçš„ conv2 å±¤
        target_layers = [
            "layer1.0.conv2",
            "layer2.0.conv2",
            "layer3.0.conv2"
            "layer4.0.conv2"
        ]
        
        # æ¸¬è©¦è¼¸å…¥
        batch_size = 1
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        boxes = [torch.tensor([[10, 10, 50, 50]], dtype=torch.float32).to(device)]
        labels = [torch.tensor([0], dtype=torch.long).to(device)]
        
        orig_params = sum(p.numel() for p in model.parameters())
        print(f"åŸå§‹åƒæ•¸é‡: {orig_params:,}")
        
        # å°æ¯å€‹ conv2 å±¤é€²è¡Œå‰ªæ
        prune_ratio = 0.3
        for layer_name in target_layers:
            print(f"\nå‰ªæå±¤ {layer_name}...")
            
            # ç²å–åŸå§‹é€šé“æ•¸
            orig_channels = None 
            for name, module in model.backbone.named_modules():
                if name == layer_name:
                    orig_channels = module.out_channels
                    break
                    
            if orig_channels is None:
                print(f"âš ï¸ æ‰¾ä¸åˆ°å±¤ {layer_name}")
                continue
                
            print(f"åŸå§‹é€šé“æ•¸: {orig_channels}")
            expected_channels = int(orig_channels * (1 - prune_ratio))
            
            # åŸ·è¡Œå‰ªæ
            success = model.prune_channel(
                layer_name=layer_name,
                prune_ratio=prune_ratio, 
                images=images,
                boxes=boxes,
                labels=labels,
                auxiliary_net=aux_net
            )
            
            if success == "SKIPPED":
                print(f"âš ï¸ è·³éå‰ªæ {layer_name}")
                continue
                
            assert success, f"å‰ªæ {layer_name} å¤±æ•—"
            
            # é©—è­‰å‰ªæçµæœ
            pruned_channels = None
            for name, module in model.backbone.named_modules():
                if name == layer_name:
                    pruned_channels = module.out_channels
                    break
                    
            assert pruned_channels == expected_channels, \
                f"é€šé“æ•¸ä¸åŒ¹é…: é æœŸ {expected_channels}, å¯¦éš› {pruned_channels}"
                
        # è¨ˆç®—åƒæ•¸é‡è®ŠåŒ–
        final_params = sum(p.numel() for p in model.parameters())
        reduction = (orig_params - final_params) / orig_params * 100
        print(f"\nåƒæ•¸é‡æ¸›å°‘: {orig_params:,} -> {final_params:,} ({reduction:.2f}%)")
        model._print_model_summary()
        # æ¸¬è©¦å‰å‘å‚³æ’­
        class_images = [torch.randn(3, 224, 224).to(device)]
        with torch.no_grad():
            output = model(images, class_images)
            
        # æª¢æŸ¥channelä¸€è‡´æ€§  
        print("\næª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§...")
        _test_all_layer_channel_consistency(model)
        
        print("\nâœ… Conv2 å‰ªææ¸¬è©¦é€šé")
        return True
        
    except Exception as e:
        print(f"âŒ Conv2 å‰ªææ¸¬è©¦å¤±æ•—: {e}")
        # # traceback.print.exc()
        return False

def test_prune_conv3_only():
    """æ¸¬è©¦åªå‰ªæ conv3 å±¤(åŒ…å«æ®˜å·®é€£æ¥)"""
    try:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cuda')
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
            
        # è¼‰å…¥æ¨¡å‹èˆ‡è¼”åŠ©ç¶²è·¯
        model = Os2dModelInPrune(pretrained_path=os2d_path).to(device)
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
        
        # é¸æ“‡è¦å‰ªæçš„ conv3 å±¤
        target_layers = [
            "layer1.0.conv3",
            "layer2.0.conv3",
            "layer3.0.conv3",
            "layer4.0.conv3"
        ]
        
        # æ¸¬è©¦è¼¸å…¥
        batch_size = 1
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        boxes = [torch.tensor([[10, 10, 50, 50]], dtype=torch.float32).to(device)]
        labels = [torch.tensor([0], dtype=torch.long).to(device)]
        
        orig_params = sum(p.numel() for p in model.parameters())
        print(f"åŸå§‹åƒæ•¸é‡: {orig_params:,}")
        
        # å°æ¯å€‹ conv3 å±¤é€²è¡Œå‰ªæ
        prune_ratio = 0.3
        for layer_name in target_layers:
            print(f"\nå‰ªæå±¤ {layer_name}...")
            
            # ç²å–åŸå§‹é€šé“æ•¸
            orig_channels = None
            for name, module in model.backbone.named_modules():
                if name == layer_name:
                    orig_channels = module.out_channels
                    break
                    
            if orig_channels is None:
                print(f"âš ï¸ æ‰¾ä¸åˆ°å±¤ {layer_name}")
                continue
                
            # ç²å–å°æ‡‰çš„æ®˜å·®å±¤
            block_name = ".".join(layer_name.split(".")[:2])
            downsample_name = f"{block_name}.downsample.0"
            
            print(f"åŸå§‹é€šé“æ•¸: {orig_channels}")
            expected_channels = int(orig_channels * (1 - prune_ratio))
            
            # åŸ·è¡Œå‰ªæ
            success = model.prune_channel(
                layer_name=layer_name,
                prune_ratio=prune_ratio,
                images=images, 
                boxes=boxes,
                labels=labels,
                auxiliary_net=aux_net
            )
            
            if success == "SKIPPED":
                print(f"âš ï¸ è·³éå‰ªæ {layer_name}")
                continue
                
            assert success, f"å‰ªæ {layer_name} å¤±æ•—"
            
            # é©—è­‰å‰ªæçµæœ
            pruned_channels = None
            downsample_channels = None
            for name, module in model.backbone.named_modules():
                if name == layer_name:
                    pruned_channels = module.out_channels
                elif name == downsample_name:
                    downsample_channels = module.out_channels
                    
            assert pruned_channels == expected_channels, \
                f"é€šé“æ•¸ä¸åŒ¹é…: é æœŸ {expected_channels}, å¯¦éš› {pruned_channels}"
                
            # é©—è­‰æ®˜å·®å±¤åŒæ­¥æ›´æ–°
            assert downsample_channels == pruned_channels, \
                f"æ®˜å·®å±¤é€šé“æ•¸ä¸åŒ¹é…: conv3={pruned_channels}, downsample={downsample_channels}"
                
        # è¨ˆç®—åƒæ•¸é‡è®ŠåŒ–
        final_params = sum(p.numel() for p in model.parameters())
        reduction = (orig_params - final_params) / orig_params * 100
        print(f"\nåƒæ•¸é‡æ¸›å°‘: {orig_params:,} -> {final_params:,} ({reduction:.2f}%)")
        
        # æ¸¬è©¦å‰å‘å‚³æ’­
        class_images = [torch.randn(3, 224, 224).to(device)]
        with torch.no_grad():
            output = model(images, class_images)
            
        # æª¢æŸ¥channelä¸€è‡´æ€§
        print("\næª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§...")
        _test_all_layer_channel_consistency(model)
        
        print("\nâœ… Conv3 å‰ªææ¸¬è©¦é€šé")
        return True
        
    except Exception as e:
        print(f"âŒ Conv3 å‰ªææ¸¬è©¦å¤±æ•—: {e}")
        # traceback.print.exc()
        return False

def test_continuous_block_pruning():
    """æ¸¬è©¦é€£çºŒå‰ªææ•´å€‹æ®˜å·®å¡Š"""
    try:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cuda')
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
            
        # è¼‰å…¥æ¨¡å‹èˆ‡è¼”åŠ©ç¶²è·¯
        model = Os2dModelInPrune(pretrained_path=os2d_path).to(device)
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
        
        # é¸æ“‡è¦é€£çºŒå‰ªæçš„å¡Š
        target_blocks = [
            ["layer2.0.conv1", "layer2.0.conv2", "layer2.0.conv3"],
            ["layer2.1.conv1", "layer2.1.conv2", "layer2.1.conv3"],
            ["layer3.0.conv1", "layer3.0.conv2", "layer3.0.conv3"]
        ]
        
        # æ¸¬è©¦è¼¸å…¥
        batch_size = 1
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        boxes = [torch.tensor([[10, 10, 50, 50]], dtype=torch.float32).to(device)]
        labels = [torch.tensor([0], dtype=torch.long).to(device)]
        
        orig_params = sum(p.numel() for p in model.parameters())
        print(f"åŸå§‹åƒæ•¸é‡: {orig_params:,}")
        
        # å°æ¯å€‹å¡Šé€²è¡Œé€£çºŒå‰ªæ
        prune_ratio = 0.3
        for block in target_blocks:
            print(f"\né–‹å§‹å‰ªæå¡Š {block[0].split('.')[0:2]}...")
            
            for layer_name in block:
                print(f"\nå‰ªæå±¤ {layer_name}...")
                
                # ç²å–åŸå§‹é€šé“æ•¸
                orig_channels = None
                for name, module in model.backbone.named_modules():
                    if name == layer_name:
                        orig_channels = module.out_channels
                        break
                        
                if orig_channels is None:
                    print(f"âš ï¸ æ‰¾ä¸åˆ°å±¤ {layer_name}")
                    continue
                    
                print(f"åŸå§‹é€šé“æ•¸: {orig_channels}")
                expected_channels = int(orig_channels * (1 - prune_ratio))
                
                # åŸ·è¡Œå‰ªæ
                success = model.prune_channel(
                    layer_name=layer_name,
                    prune_ratio=prune_ratio,
                    images=images,
                    boxes=boxes,
                    labels=labels,
                    auxiliary_net=aux_net
                )
                
                if success == "SKIPPED":
                    print(f"âš ï¸ è·³éå‰ªæ {layer_name}")
                    continue
                    
                assert success, f"å‰ªæ {layer_name} å¤±æ•—"
                
                # é©—è­‰å‰ªæçµæœ
                pruned_channels = None
                for name, module in model.backbone.named_modules():
                    if name == layer_name:
                        pruned_channels = module.out_channels
                        break
                        
                assert pruned_channels == expected_channels, \
                    f"é€šé“æ•¸ä¸åŒ¹é…: é æœŸ {expected_channels}, å¯¦éš› {pruned_channels}"
                    
            # æ¯å€‹å¡Šå‰ªæå®Œæˆå¾Œæ¸¬è©¦å‰å‘å‚³æ’­
            class_images = [torch.randn(3, 224, 224).to(device)]
            with torch.no_grad():
                output = model(images, class_images)
                
            # æª¢æŸ¥channelä¸€è‡´æ€§
            print("\næª¢æŸ¥æ‰€æœ‰å±¤çš„ channel ä¸€è‡´æ€§...")
            _test_all_layer_channel_consistency(model)
                
        # è¨ˆç®—æœ€çµ‚åƒæ•¸é‡
        final_params = sum(p.numel() for p in model.parameters())
        reduction = (orig_params - final_params) / orig_params * 100
        print(f"\nåƒæ•¸é‡æ¸›å°‘: {orig_params:,} -> {final_params:,} ({reduction:.2f}%)")
        
        print("\nâœ… é€£çºŒå¡Šå‰ªææ¸¬è©¦é€šé")
        return True
        
    except Exception as e:
        print(f"âŒ é€£çºŒå¡Šå‰ªææ¸¬è©¦å¤±æ•—: {e}")
        # traceback.print.exc()  
        return False

def test_prune_multiple_blocks():
    """æ¸¬è©¦é€£çºŒå‰ªå¤šå€‹ block"""
    try:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cuda')
        print(f"\n===== æ¸¬è©¦é€£çºŒå‰ªå¤šå€‹ block =====")
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
            
        model = Os2dModelInPrune(pretrained_path=os2d_path).to(device)
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
        
        # å®šç¾©è¦å‰ªæçš„å¤šå€‹ block
        blocks_to_prune = [
            ["layer2.0.conv1", "layer2.0.conv2"],  # ç¬¬ä¸€å€‹ block
            ["layer2.1.conv1", "layer2.1.conv2"],  # ç¬¬äºŒå€‹ block
            ["layer3.0.conv1", "layer3.0.conv2"]   # ç¬¬ä¸‰å€‹ block
        ]
        
        # æ¸¬è©¦è¼¸å…¥
        batch_size = 1
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        boxes = [torch.tensor([[10, 10, 50, 50]], dtype=torch.float32).to(device)]
        labels = [torch.tensor([0], dtype=torch.long).to(device)]
        
        # è¨˜éŒ„åŸå§‹åƒæ•¸é‡
        orig_params = sum(p.numel() for p in model.parameters())
        print(f"åŸå§‹åƒæ•¸é‡: {orig_params:,}")
        
        # å°æ¯å€‹ block é€²è¡Œå‰ªæ
        prune_ratio = 0.3
        for block in blocks_to_prune:
            print(f"\nå‰ªæ block: {block}")
            for layer_name in block:
                print(f"\nå‰ªæå±¤ {layer_name}...")
                success = model.prune_channel(
                    layer_name=layer_name,
                    prune_ratio=prune_ratio,
                    images=images,
                    boxes=boxes,
                    labels=labels,
                    auxiliary_net=aux_net
                )
                
                if success == "SKIPPED":
                    print(f"âš ï¸ è·³éå‰ªæ {layer_name}")
                    continue
                    
                assert success, f"å‰ªæ {layer_name} å¤±æ•—"
                
            # æ¯å€‹ block å‰ªæå¾Œæ¸¬è©¦å‰å‘å‚³æ’­
            class_images = [torch.randn(3, 224, 224).to(device)]
            with torch.no_grad():
                output = model(images, class_images)
                
            # æª¢æŸ¥ channel ä¸€è‡´æ€§
            _test_all_layer_channel_consistency(model)
            
        # è¨ˆç®—åƒæ•¸é‡æ¸›å°‘
        final_params = sum(p.numel() for p in model.parameters())
        reduction = (orig_params - final_params) / orig_params * 100
        print(f"\nåƒæ•¸é‡æ¸›å°‘: {orig_params:,} -> {final_params:,} ({reduction:.2f}%)")
        
        print("\nâœ… é€£çºŒå‰ªå¤šå€‹ block æ¸¬è©¦é€šé")
        return True
        
    except Exception as e:
        print(f"âŒ é€£çºŒå‰ªå¤šå€‹ block æ¸¬è©¦å¤±æ•—: {e}")
        # traceback.print_exc()
        return False

def test_cross_stage_prune():
    """æ¸¬è©¦è·¨ stage å‰ªæ"""
    try:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cuda')
        print(f"\n===== æ¸¬è©¦è·¨ stage å‰ªæ =====")
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
            
        model = Os2dModelInPrune(pretrained_path=os2d_path).to(device)
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
        
        # å®šç¾©è·¨ stage çš„å‰ªæå±¤
        cross_stage_layers = [
            "layer2.3.conv2",  # layer2 æœ€å¾Œä¸€å€‹ block
            "layer3.0.conv1",  # layer3 ç¬¬ä¸€å€‹ block
        ]
        
        # æ¸¬è©¦è¼¸å…¥
        batch_size = 1
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        boxes = [torch.tensor([[10, 10, 50, 50]], dtype=torch.float32).to(device)]
        labels = [torch.tensor([0], dtype=torch.long).to(device)]
        
        orig_params = sum(p.numel() for p in model.parameters())
        print(f"åŸå§‹åƒæ•¸é‡: {orig_params:,}")
        
        # åŸ·è¡Œè·¨ stage å‰ªæ
        prune_ratio = 0.3
        for layer_name in cross_stage_layers:
            print(f"\nå‰ªæå±¤ {layer_name}...")
            success = model.prune_channel(
                layer_name=layer_name,
                prune_ratio=prune_ratio,
                images=images,
                boxes=boxes,
                labels=labels,
                auxiliary_net=aux_net
            )
            
            if success == "SKIPPED":
                print(f"âš ï¸ è·³éå‰ªæ {layer_name}")
                continue
                
            assert success, f"å‰ªæ {layer_name} å¤±æ•—"
            
            # æ¸¬è©¦å‰å‘å‚³æ’­
            class_images = [torch.randn(3, 224, 224).to(device)]
            with torch.no_grad():
                output = model(images, class_images)
                
            # æª¢æŸ¥ channel ä¸€è‡´æ€§
            _test_all_layer_channel_consistency(model)
            
        final_params = sum(p.numel() for p in model.parameters())
        reduction = (orig_params - final_params) / orig_params * 100
        print(f"\nåƒæ•¸é‡æ¸›å°‘: {orig_params:,} -> {final_params:,} ({reduction:.2f}%)")
        
        print("\nâœ… è·¨ stage å‰ªææ¸¬è©¦é€šé")
        return True
        
    except Exception as e:
        print(f"âŒ è·¨ stage å‰ªææ¸¬è©¦å¤±æ•—: {e}")
        # traceback.print_exc()
        return False

def test_resnet18_basicblock_prune():
    """æ¸¬è©¦ ResNet18/34 BasicBlock å‰ªæ"""
    try:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cuda')
        print(f"\n===== æ¸¬è©¦ ResNet18 BasicBlock å‰ªæ =====")
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # è¼‰å…¥ ResNet18 æ¨¡å‹
        model = torchvision.models.resnet18(weights=None).to(device)
        
        # å®šç¾©è¦å‰ªæçš„ BasicBlock å±¤
        basic_block_layers = [
            "layer1.0.conv1",
            "layer1.0.conv2",
            "layer2.0.conv1",
            "layer2.0.conv2"
        ]
        
        # æ¸¬è©¦è¼¸å…¥
        batch_size = 1
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        
        orig_params = sum(p.numel() for p in model.parameters())
        print(f"åŸå§‹åƒæ•¸é‡: {orig_params:,}")
        
        # åŸ·è¡Œ BasicBlock å‰ªæ
        prune_ratio = 0.3
        for layer_name in basic_block_layers:
            print(f"\nå‰ªæå±¤ {layer_name}...")
            
            # ç²å–åŸå§‹é€šé“æ•¸
            layer = None
            for name, module in model.named_modules():
                if name == layer_name:
                    layer = module
                    break
                    
            if layer is None:
                print(f"âš ï¸ æ‰¾ä¸åˆ°å±¤ {layer_name}")
                continue
                
            orig_channels = layer.out_channels
            expected_channels = int(orig_channels * (1 - prune_ratio))
            
            # åŸ·è¡Œå‰ªæ
            # é€™è£¡éœ€è¦å¯¦ç¾ BasicBlock çš„å‰ªæé‚è¼¯
            
            # æ¸¬è©¦å‰å‘å‚³æ’­
            with torch.no_grad():
                output = model(images)
                
        final_params = sum(p.numel() for p in model.parameters())
        reduction = (orig_params - final_params) / orig_params * 100
        print(f"\nåƒæ•¸é‡æ¸›å°‘: {orig_params:,} -> {final_params:,} ({reduction:.2f}%)")
        
        print("\nâœ… ResNet18 BasicBlock å‰ªææ¸¬è©¦é€šé")
        return True
        
    except Exception as e:
        print(f"âŒ ResNet18 BasicBlock å‰ªææ¸¬è©¦å¤±æ•—: {e}")
        # traceback.print.exc()
        return False

def test_pruning_ratios(layer_name, model_fn=None):
    """æ¸¬è©¦ä¸åŒå‰ªæç‡å°æŒ‡å®šå±¤çš„å½±éŸ¿"""
    try:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cuda')
        print(f"\n===== æ¸¬è©¦å‰ªæç‡ sweep {layer_name} =====")
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # å®šç¾©è¦æ¸¬è©¦çš„å‰ªæç‡
        pruning_ratios = [0.1, 0.2, 0.3, 0.4, 0.5]
        
        results = []
        for ratio in pruning_ratios:
            print(f"\næ¸¬è©¦å‰ªæç‡: {ratio}")
            
            # åˆå§‹åŒ–æ–°çš„æ¨¡å‹å¯¦ä¾‹
            if model_fn:
                model = model_fn().to(device)
            else:
                os2d_path = "./os2d_v2-train.pth"
                if not os.path.exists(os2d_path):
                    pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
                model = Os2dModelInPrune(pretrained_path=os2d_path).to(device)
                
            aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
            
            # æ¸¬è©¦è¼¸å…¥
            batch_size = 1
            images = torch.randn(batch_size, 3, 224, 224).to(device)
            boxes = [torch.tensor([[10, 10, 50, 50]], dtype=torch.float32).to(device)]
            labels = [torch.tensor([0], dtype=torch.long).to(device)]
            
            # è¨˜éŒ„åŸå§‹åƒæ•¸é‡
            orig_params = sum(p.numel() for p in model.parameters())
            
            # åŸ·è¡Œå‰ªæ
            success = model.prune_channel(
                layer_name=layer_name,
                prune_ratio=ratio,
                images=images,
                boxes=boxes,
                labels=labels,
                auxiliary_net=aux_net
            )
            
            if success == "SKIPPED":
                print(f"âš ï¸ è·³éå‰ªæ ratio={ratio}")
                continue
                
            assert success, f"å‰ªæå¤±æ•— ratio={ratio}"
            
            # è¨ˆç®—åƒæ•¸é‡æ¸›å°‘
            final_params = sum(p.numel() for p in model.parameters())
            reduction = (orig_params - final_params) / orig_params * 100
            
            # æ¸¬è©¦å‰å‘å‚³æ’­
            class_images = [torch.randn(3, 224, 224).to(device)]
            with torch.no_grad():
                output = model(images, class_images)
                
            # è¨˜éŒ„çµæœ
            results.append({
                'ratio': ratio,
                'param_reduction': reduction,
                'orig_params': orig_params,
                'final_params': final_params
            })
            
        # è¼¸å‡ºçµæœæ‘˜è¦
        print("\nå‰ªæç‡ sweep çµæœ:")
        for result in results:
            print(f"å‰ªæç‡ {result['ratio']:.1f}: åƒæ•¸æ¸›å°‘ {result['param_reduction']:.2f}% ({result['orig_params']:,} -> {result['final_params']:,})")
            
        print(f"\nâœ… å‰ªæç‡ sweep æ¸¬è©¦é€šé: {layer_name}")
        return True
        
    except Exception as e:
        print(f"âŒ å‰ªæç‡ sweep æ¸¬è©¦å¤±æ•—: {e}")
        return False

def test_lcp_channel_selector():
    """æ¸¬è©¦ LCP é€šé“é¸æ“‡å™¨åŸºæœ¬åŠŸèƒ½"""
    try:
        print("\n===== LCP é€šé“é¸æ“‡å™¨æ¸¬è©¦ =====")
        
        # è¨­ç½®è¨­å‚™
        device = torch.device('cuda' if torch.cuda.is_available() else 'cuda')
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # åˆå§‹åŒ–æ¨¡å‹èˆ‡è·¯å¾‘
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
        
        # è¼‰å…¥æ¨¡å‹èˆ‡è¼”åŠ©ç¶²è·¯    
        model = Os2dModelInPrune(pretrained_path=os2d_path).to(device)
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
        
        # åˆå§‹åŒ–é¸æ“‡å™¨
        selector = OS2DChannelSelector(
            model=model,
            auxiliary_net=aux_net,
            device=device,
            alpha=0.6,
            beta=0.3,
            gamma=0.1
        )
        
        # åŸºæœ¬å±¬æ€§é©—è­‰
        assert hasattr(selector, 'compute_importance'), "é¸æ“‡å™¨æ‡‰è©²æœ‰ compute_importance æ–¹æ³•"
        assert hasattr(selector, 'select_channels'), "é¸æ“‡å™¨æ‡‰è©²æœ‰ select_channels æ–¹æ³•"
        assert selector.model is model, "æ¨¡å‹åƒè€ƒéŒ¯èª¤"
        assert selector.auxiliary_net is aux_net, "è¼”åŠ©ç¶²è·¯åƒè€ƒéŒ¯èª¤"
        assert selector.device == device, "è¨­å‚™è¨­ç½®éŒ¯èª¤"
        
        print("âœ… LCP é€šé“é¸æ“‡å™¨åˆå§‹åŒ–æ¸¬è©¦é€šé")
        return True
        
    except Exception as e:
        print(f"âŒ LCP é€šé“é¸æ“‡å™¨æ¸¬è©¦å¤±æ•—: {e}")
        # traceback.print_exc()
        return False

def test_channel_importance_computation():
    """æ¸¬è©¦é€šé“é‡è¦æ€§è¨ˆç®—åŠŸèƒ½"""
    try:
        print("\n===== é€šé“é‡è¦æ€§è¨ˆç®—æ¸¬è©¦ =====")
        
        # è¨­ç½®è¨­å‚™
        device = torch.device('cuda' if torch.cuda.is_available() else 'cuda')
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # åˆå§‹åŒ–æ¨¡å‹èˆ‡è·¯å¾‘
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
            
        # è¼‰å…¥æ¨¡å‹èˆ‡è¼”åŠ©ç¶²è·¯
        model = Os2dModelInPrune(pretrained_path=os2d_path).to(device)
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
        
        # åˆå§‹åŒ–é¸æ“‡å™¨
        selector = OS2DChannelSelector(
            model=model,
            auxiliary_net=aux_net,
            device=device
        )
        
        # æº–å‚™æ¸¬è©¦æ•¸æ“š
        batch_size = 2
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        
        # ç”Ÿæˆ class images (ä½¿ç”¨åŒä¸€æ‰¹æ¬¡ä¸­çš„ç¬¬ä¸€å¼µåœ–åƒ)
        class_images = [images[0].clone()]  # ä½¿ç”¨ç¬¬ä¸€å¼µåœ–ä½œç‚ºé¡åˆ¥åœ–åƒ
        
        # ç”Ÿæˆé‚Šç•Œæ¡†å’Œæ¨™ç±¤
        boxes = [torch.tensor([[10, 10, 50, 50]], dtype=torch.float32).to(device) for _ in range(batch_size)]
        labels = [torch.tensor([0], dtype=torch.long).to(device) for _ in range(batch_size)]
        
        # ä¿®æ”¹ forward pass
        def modified_forward():
            return model(images, class_images=class_images)
            
        # æ¸¬è©¦ä¸åŒå±¤çš„é€šé“é‡è¦æ€§è¨ˆç®—
        test_layers = [
            {"name": "layer2.0.conv1", "expected_channels": 128},
            {"name": "layer2.0.conv2", "expected_channels": 128},
            {"name": "layer3.0.conv1", "expected_channels": 256}
        ]
        
        for layer_info in test_layers:
            layer_name = layer_info["name"]
            expected_channels = layer_info["expected_channels"]
            print(f"\næ¸¬è©¦å±¤ {layer_name}...")
            
            # è¨ˆç®—é€šé“é‡è¦æ€§
            importance_scores = selector.compute_importance(
                layer_name=layer_name,
                images=images,
                boxes=boxes,
                gt_boxes=boxes,
                labels=labels
            )
            
            # é©—è­‰é‡è¦æ€§åˆ†æ•¸
            assert importance_scores is not None, f"{layer_name} importance_scores ä¸æ‡‰ç‚º None"
            assert len(importance_scores) == expected_channels, \
                f"{layer_name} importance_scores é•·åº¦ä¸ç¬¦: é æœŸ {expected_channels}, å¯¦éš› {len(importance_scores)}"
            print(f"âœ“ {layer_name} é‡è¦æ€§åˆ†æ•¸è¨ˆç®—æˆåŠŸ")
        
        print("\nâœ… é€šé“é‡è¦æ€§è¨ˆç®—æ¸¬è©¦é€šé")
        return True
        
    except Exception as e:
        print(f"âŒ é€šé“é‡è¦æ€§è¨ˆç®—æ¸¬è©¦å¤±æ•—: {e}")
        # # traceback.print_exc()
        return False
    
def test_lcp_finetune_pipeline():
    pass

def test_feature_map_extraction():
    """æ¸¬è©¦ LCP Channel Selector çš„ç‰¹å¾µåœ–æå–åŠŸèƒ½"""
    try:
        print("\n===== æ¸¬è©¦ç‰¹å¾µåœ–æå–åŠŸèƒ½ =====")
        
        # è¨­ç½®è¨­å‚™
        device = torch.device('cuda' if torch.cuda.is_available() else 'cuda')
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # åˆå§‹åŒ–æ¨¡å‹å’Œè·¯å¾‘
        os2d_path = "./os2d_v2-train.pth"
        if not os.path.exists(os2d_path):
            pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
        
        # è¼‰å…¥æ¨¡å‹èˆ‡è¼”åŠ©ç¶²è·¯
        model = Os2dModelInPrune(pretrained_path=os2d_path).to(device)
        aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
        
        # å‰µå»ºé€šé“é¸æ“‡å™¨
        selector = OS2DChannelSelector(
            model=model,
            auxiliary_net=aux_net,
            device=device
        )
        
        # æº–å‚™æ¸¬è©¦æ•¸æ“š
        batch_size = 1
        images = torch.randn(batch_size, 3, 224, 224).to(device)
        
        # æ¸¬è©¦ä¸åŒå±¤çš„ç‰¹å¾µåœ–æå–
        test_layers = [
            "layer1.0.conv1",
            "layer2.0.conv1",
            "layer3.0.conv1",
        ]
        
        # 1. é¦–å…ˆæ‰“å°æ‰€æœ‰å¯ç”¨å±¤åç¨±ä»¥ä¾›åƒè€ƒ
        print("\nç²å–æ‰€æœ‰å¯ç”¨å±¤åç¨±:")
        all_layers = {}
        for name, module in model.named_modules():
            if isinstance(module, torch.nn.Conv2d):
                all_layers[name] = module
        print(f"ç¸½å…±æ‰¾åˆ° {len(all_layers)} å€‹å·ç©å±¤")
        print("å‰10å€‹å·ç©å±¤åç¨±:")
        for idx, (name, _) in enumerate(all_layers.items()):
            if idx < 10:
                print(f"  - {name}")
        
        # 2. æ¸¬è©¦ä¸åŒæ–¹æ³•ç²å–ç‰¹å¾µåœ–
        success_count = 0
        for layer_name in test_layers:
            print(f"\næ¸¬è©¦å±¤ {layer_name} çš„ç‰¹å¾µåœ–æå–:")
            
            # æ‰‹å‹•æ·»åŠ  hook æå–ç‰¹å¾µåœ–
            feature_maps = {}
            
            def hook_fn(name):
                def inner_hook(module, input, output):
                    feature_maps[name] = output.detach()
                return inner_hook
            
            # å˜—è©¦ä¸åŒå¯èƒ½çš„å±¤è·¯å¾‘
            possible_layer_names = [
                f"net_feature_maps.{layer_name}",
                f"backbone.{layer_name}",
                layer_name
            ]
            
            hooks = []
            found_layer = False
            
            # è¨»å†Š hook
            for full_name in possible_layer_names:
                for name, module in model.named_modules():
                    if name == full_name and isinstance(module, torch.nn.Conv2d):
                        print(f"æ‰¾åˆ°å±¤: {name}")
                        hook = module.register_forward_hook(hook_fn(name))
                        hooks.append(hook)
                        found_layer = True
            
            if not found_layer:
                print(f"âŒ ç„¡æ³•æ‰¾åˆ°å±¤ {layer_name}")
                continue
                
            # å‰å‘å‚³æ’­
            with torch.no_grad():
                # å˜—è©¦ä¸åŒçš„å‰å‘å‚³æ’­æ–¹æ³•
                try:
                    # æº–å‚™ class_images
                    class_images = [images[0].clone()]
                    outputs = model(images, class_images=class_images)
                except TypeError:
                    print("æ¨¡å‹ä¸æ¥å— class_images åƒæ•¸ï¼Œä½¿ç”¨åŸºæœ¬æ¨¡å¼")
                    outputs = model(images)
            
            # æª¢æŸ¥æ˜¯å¦ç²å–åˆ°ç‰¹å¾µåœ–
            if feature_maps:
                success = True
                print(f"âœ“ é€šé hook æˆåŠŸç²å–ç‰¹å¾µåœ–:")
                for name, feature in feature_maps.items():
                    print(f"  - {name}: {feature.shape}")
                success_count += 1
            else:
                print(f"âŒ é€šé hook ç„¡æ³•ç²å–ç‰¹å¾µåœ–")
                success = False
            
            # ç§»é™¤ hooks
            for hook in hooks:
                hook.remove()
            
            # 3. æ¸¬è©¦ Channel Selector ä¸­çš„ _get_feature_maps æ–¹æ³•
            print("\nä½¿ç”¨ Channel Selector çš„ _get_feature_maps æ–¹æ³•:")
            feature_map, orig_feature_map = selector._get_feature_maps(layer_name, images)
            
            if feature_map is not None and orig_feature_map is not None:
                print(f"âœ“ æˆåŠŸç²å–ç‰¹å¾µåœ–: feature_map {feature_map.shape}, orig_feature_map {orig_feature_map.shape}")
                success_count += 1
            else:
                print("âŒ ä½¿ç”¨ _get_feature_maps æ–¹æ³•ç„¡æ³•ç²å–ç‰¹å¾µåœ–")
        
        # æ¸¬è©¦çµè«–
        if success_count > 0:
            print(f"\nâœ… ç‰¹å¾µåœ–æå–æ¸¬è©¦é€šé: {success_count} æ¬¡æˆåŠŸ")
        else:
            print("\nâŒ ç‰¹å¾µåœ–æå–æ¸¬è©¦å¤±æ•—: ç„¡æ³•ç²å–ä»»ä½•ç‰¹å¾µåœ–")
            
        # 4. æ¸¬è©¦ä¿®å¾©æ–¹æ¡ˆ - æ·»åŠ ç²å–ç‰¹å¾µåœ–çš„å‚™é¸æ–¹æ³•
        if success_count == 0:
            print("\nå˜—è©¦å¯¦ç¾ç‰¹å¾µåœ–æå–å‚™é¸æ–¹æ³•:")
            
            # æ·»åŠ  get_feature_map_backup æ–¹æ³•
            def get_feature_map_backup(model, layer_name, images):
                feature_maps = {}
                
                def hook_fn(name):
                    def inner_hook(module, input, output):
                        feature_maps[name] = output.detach()
                    return inner_hook
                
                # éæ­·æ‰€æœ‰å·ç©å±¤ä¸¦æŸ¥æ‰¾åŒ¹é…çš„
                hooks = []
                for name, module in model.named_modules():
                    if isinstance(module, torch.nn.Conv2d) and layer_name in name:
                        print(f"å˜—è©¦åŒ¹é…å±¤: {name}")
                        hook = module.register_forward_hook(hook_fn(name))
                        hooks.append(hook)
                
                try:
                    # å‰å‘å‚³æ’­
                    with torch.no_grad():
                        try:
                            # æº–å‚™ class_images
                            class_images = [images[0].clone()]
                            _ = model(images, class_images=class_images)
                        except TypeError:
                            _ = model(images)
                    
                    # æª¢æŸ¥æ˜¯å¦ç²å–åˆ°ç‰¹å¾µåœ–
                    if feature_maps:
                        key = next(iter(feature_maps.keys()))
                        return feature_maps[key]
                    return None
                
                finally:
                    # ç§»é™¤ hooks
                    for hook in hooks:
                        hook.remove()
            
            # æ¸¬è©¦å‚™é¸æ–¹æ³•
            for layer_name in test_layers:
                print(f"\næ¸¬è©¦å±¤ {layer_name} çš„å‚™é¸ç‰¹å¾µåœ–ç²å–æ–¹æ³•:")
                feature_map = get_feature_map_backup(model, layer_name, images)
                if feature_map is not None:
                    print(f"âœ“ å‚™é¸æ–¹æ³•æˆåŠŸç²å–ç‰¹å¾µåœ–: {feature_map.shape}")
                else:
                    print("âŒ å‚™é¸æ–¹æ³•ç„¡æ³•ç²å–ç‰¹å¾µåœ–")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç‰¹å¾µåœ–æå–æ¸¬è©¦ç™¼ç”ŸéŒ¯èª¤: {e}")
        # traceback.print_exc()
        return False
    
def test_train_one_epoch_basic():
    """
    Memory-friendly å–®å…ƒæ¸¬è©¦ï¼šé©—è­‰ OS2D æ¨¡å‹åœ¨ Grozi-3.2k mini set ä¸Šèƒ½æ­£ç¢º train_one_epoch
    ä¸¦æ‰“å°è©³ç´°çš„æ•¸æ“šé›†å’Œè¼¸å…¥åƒæ•¸ä¿¡æ¯
    """
    from src.os2d_model_in_prune import Os2dModelInPrune
    from src.auxiliary_network import AuxiliaryNetwork
    from os2d.data.dataset import build_grozi_dataset
    from os2d.data.dataloader import DataloaderOneShotDetection
    from os2d.modeling.box_coder import Os2dBoxCoder, BoxGridGenerator
    from os2d.structures.feature_map import FeatureMapSize
    import os
    import torch
    import pytest
    import numpy as np
    import traceback
    import logging

    # è¨­ç½®è©³ç´°çš„æ—¥èªŒ
    logging.basicConfig(level=logging.INFO, 
                      format='%(asctime)s - %(levelname)s - %(message)s')
    logger = logging.getLogger("OS2D.test")
    logger.info("===== é–‹å§‹è©³ç´°æ¸¬è©¦ OS2D è¨“ç·´ç®¡é“ =====")

    # 1. æª¢æŸ¥ Grozi dataset æ˜¯å¦å­˜åœ¨
    data_path = "./data"
    grozi_csv = os.path.join(data_path, "grozi", "classes", "grozi.csv")
    if not os.path.exists(grozi_csv):
        logger.error("âŒ Grozi-3.2k dataset not found. è«‹ä¾å®˜æ–¹èªªæ˜æ‰‹å‹•ä¸‹è¼‰ä¸¦è§£å£“è‡³ ./data/grozi/")
        pytest.skip("Grozi-3.2k dataset missing, test skipped.")
        return False

    # 2. å»ºç«‹ dataset/dataloaderï¼ˆmini subset + batch size 1ï¼‰
    logger.info("æ­£åœ¨è¼‰å…¥ Grozi-3.2k mini dataset...")
    dataset = build_grozi_dataset(
        data_path=data_path,
        name="grozi-train-mini",  # åªå–2å¼µåœ–2é¡åˆ¥
        eval_scale=224,
        cache_images=False
    )
    
    # æ‰“å°æ•¸æ“šé›†åŸºæœ¬ä¿¡æ¯
    class_ids = dataset.get_class_ids()
    logger.info(f"æ•¸æ“šé›†ä¿¡æ¯: {dataset.get_name()}")
    logger.info(f"ç¸½åœ–åƒæ•¸é‡: {len(dataset.image_ids)}")
    logger.info(f"é¡åˆ¥æ•¸é‡: {len(class_ids)}")
    logger.info(f"é¡åˆ¥ ID åˆ—è¡¨: {class_ids}")
    
    # æŸ¥çœ‹ç¬¬ä¸€å¼µåœ–çš„æ¨™è¨»ä¿¡æ¯
    if len(dataset.image_ids) > 0:
        image_id = dataset.image_ids[0]
        boxes = dataset.get_image_annotation_for_imageid(image_id)
        if hasattr(boxes, "bbox_xyxy"):
            logger.info(f"ç¬¬ä¸€å¼µåœ– ({image_id}) çš„æ¨™è¨»æ¡†: shape={boxes.bbox_xyxy.shape}, å…§å®¹={boxes.bbox_xyxy}")
            if hasattr(boxes, "get_field"):
                if "labels" in boxes.fields():
                    logger.info(f"æ¡†å°æ‡‰çš„æ¨™ç±¤: {boxes.get_field('labels')}")
    
    # å‰µå»º box_coder
    box_coder = Os2dBoxCoder(
        positive_iou_threshold=0.5,
        negative_iou_threshold=0.4,
        remap_classification_targets_iou_pos=0.5,
        remap_classification_targets_iou_neg=0.4,
        output_box_grid_generator=BoxGridGenerator(
            box_size=FeatureMapSize(w=16, h=16),
            box_stride=FeatureMapSize(w=16, h=16)
        ),
        function_get_feature_map_size=lambda img_size: FeatureMapSize(w=img_size.w // 16, h=img_size.h // 16),
        do_nms_across_classes=False
    )
    
    logger.info("å‰µå»º DataloaderOneShotDetection...")
    train_loader = DataloaderOneShotDetection(
        dataset=dataset,
        box_coder=box_coder,
        batch_size=1,  # æœ€å° batch
        img_normalization={"mean": [0.485, 0.456, 0.406], "std": [0.229, 0.224, 0.225]},
        gt_image_size=64,
        random_flip_batches=False,
        random_crop_size=None,
        random_color_distortion=False,
        pyramid_scales_eval=[1.0],
        do_augmentation=False
    )
    logger.info(f"DataLoader é•·åº¦: {len(train_loader)} batches")

    # æª¢æŸ¥ç¬¬ä¸€å€‹ batch çš„å…·é«”çµæ§‹
    logger.info("æª¢æŸ¥ç¬¬ä¸€å€‹æ‰¹æ¬¡ (batch) çš„çµæ§‹...")
    batch = train_loader.get_batch(0)
    images, class_images, loc_targets, class_targets, batch_class_ids, class_image_sizes, box_inverse_transform, batch_boxes, batch_img_size = batch
    
    # æ‰“å°è©³ç´°çš„ batch çµæ§‹ä¿¡æ¯
    logger.info(f"æ‰¹æ¬¡çµæ§‹:")
    logger.info(f"  - images: å½¢ç‹€={images.shape}, é¡å‹={images.dtype}, è¨­å‚™={images.device}")
    logger.info(f"  - class_images: æ•¸é‡={len(class_images)}, é¡å‹={type(class_images[0]) if class_images else 'N/A'}")
    if class_images and isinstance(class_images[0], torch.Tensor):
        logger.info(f"    - ç¬¬ä¸€å€‹ class_image: å½¢ç‹€={class_images[0].shape}, é¡å‹={class_images[0].dtype}")
    logger.info(f"  - loc_targets: å½¢ç‹€={loc_targets.shape}, é¡å‹={loc_targets.dtype}")
    logger.info(f"  - class_targets: å½¢ç‹€={class_targets.shape}, é¡å‹={class_targets.dtype}")
    logger.info(f"    - class_targets å€¼èŒƒåœ: min={class_targets.min().item()}, max={class_targets.max().item()}")
    logger.info(f"  - batch_class_ids: é¡å‹={type(batch_class_ids)}, æ•¸é‡={len(batch_class_ids) if isinstance(batch_class_ids, list) else 'N/A'}")
    if isinstance(batch_class_ids, list) and len(batch_class_ids) > 0:
        logger.info(f"    - ç¬¬ä¸€å€‹ batch_class_id: å½¢ç‹€={batch_class_ids[0].shape if hasattr(batch_class_ids[0], 'shape') else '()'}, å€¼={batch_class_ids[0]}")
    logger.info(f"  - class_image_sizes: {class_image_sizes}")
    logger.info(f"  - batch_boxes: é¡å‹={type(batch_boxes)}, æ•¸é‡={len(batch_boxes) if isinstance(batch_boxes, list) else 'N/A'}")
    
    # ä¿®æ­£é€™è£¡ï¼Œæ­£ç¢ºè™•ç† BoxList å°è±¡
    if isinstance(batch_boxes, list) and len(batch_boxes) > 0:
        box = batch_boxes[0]
        if hasattr(box, 'bbox_xyxy'):  # BoxList å°è±¡
            logger.info(f"    - ç¬¬ä¸€å€‹ batch_box: BoxListå°è±¡, æ¡†æ•¸é‡={box.bbox_xyxy.shape[0]}")
            logger.info(f"    - bbox_xyxy å½¢ç‹€={box.bbox_xyxy.shape}, åŒ…å« {box.bbox_xyxy.shape[0]} å€‹æ¡†")
            if hasattr(box, 'get_field') and "labels" in box.fields():
                logger.info(f"    - æ¨™ç±¤: {box.get_field('labels')}")
        elif hasattr(box, 'shape'):  # Tensor
            logger.info(f"    - ç¬¬ä¸€å€‹ batch_box: å½¢ç‹€={box.shape}, å€¼={box}")
        else:
            logger.info(f"    - ç¬¬ä¸€å€‹ batch_box: é¡å‹={type(box)}, å€¼={box}")
            
    logger.info(f"  - batch_img_size: {batch_img_size}")

    # 3. åˆå§‹åŒ–æ¨¡å‹èˆ‡å„ªåŒ–å™¨ï¼ˆç”¨ CPU ä»¥ç¯€çœè³‡æºï¼‰
    device = torch.device('cpu')
    logger.info(f"ä½¿ç”¨è¨­å‚™: {device}")
    
    os2d_path = "./os2d_v2-train.pth"
    if not os.path.exists(os2d_path):
        logger.error(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
        pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
        return False
    
    logger.info(f"è¼‰å…¥ OS2D æ¨¡å‹: {os2d_path}")
    model = Os2dModelInPrune(pretrained_path=os2d_path, is_cuda=False).to(device)
    
    # æª¢æŸ¥æ¨¡å‹çµæ§‹
    logger.info("æª¢æŸ¥æ¨¡å‹çµæ§‹:")
    param_count = sum(p.numel() for p in model.parameters())
    logger.info(f"  - ç¸½åƒæ•¸é‡: {param_count:,}")
    logger.info(f"  - backbone å‹åˆ¥: {type(model.backbone).__name__}")
    
    # åˆå§‹åŒ–è¼”åŠ©ç¶²è·¯
    logger.info("åˆå§‹åŒ–è¼”åŠ©ç¶²è·¯")
    aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
    
    # æª¢æŸ¥ä¸¦æ‰“å°æ¨¡å‹çš„ç‰¹å¾µåœ–è¼¸å‡ºå¤§å°
    logger.info("æª¢æŸ¥ç‰¹å¾µåœ–å°ºå¯¸:")
    with torch.no_grad():
        feature_maps = model.get_feature_map(images.to(device))
        if isinstance(feature_maps, torch.Tensor):
            logger.info(f"  - ç‰¹å¾µåœ–å½¢ç‹€: {feature_maps.shape}")
            logger.info(f"  - ç‰¹å¾µåœ–å€¼ç¯„åœ: [{feature_maps.min().item():.4f}, {feature_maps.max().item():.4f}]")
            # è¨ˆç®—ç‰¹å¾µåœ–å¦‚æœè¢«å®Œå…¨å±•å¹³å¾Œçš„å¤§å°
            flattened_size = feature_maps.shape[0] * feature_maps.shape[1] * feature_maps.shape[2] * feature_maps.shape[3]
            logger.info(f"  - ç‰¹å¾µåœ–å®Œå…¨å±•å¹³å¾Œå¤§å°: {flattened_size} (é€™å¯èƒ½å°è‡´é¡åˆ¥æ•¸é‡ç•°å¸¸)")
    
    # åˆå§‹åŒ–å„ªåŒ–å™¨
    optimizer = torch.optim.Adam(list(model.parameters()) + list(aux_net.parameters()), lr=1e-3)
    logger.info("åˆå§‹åŒ– Adam å„ªåŒ–å™¨ï¼Œå­¸ç¿’ç‡=1e-3")

    # 4. åŸ·è¡Œä¸€å€‹ epoch çš„è¨“ç·´ï¼ˆåªè·‘ä¸€å€‹ batchï¼‰
    logger.info("é–‹å§‹åŸ·è¡Œ train_one_epoch (åªåŸ·è¡Œä¸€å€‹ batch)...")
    try:
        logger.info(f"é¡åˆ¥æ•¸é‡: {len(train_loader.dataset.get_class_ids())}")
        loss_history = model.train_one_epoch(
            train_loader=train_loader,
            optimizer=optimizer,
            auxiliary_net=aux_net,
            device=device,
            print_freq=1,  
            max_batches=1  
        )
    except NotImplementedError:
        logger.error("âš ï¸ train_one_epoch å°šæœªå¯¦ä½œï¼Œè«‹å…ˆå®Œæˆå¯¦ä½œã€‚")
        assert False, "train_one_epoch å°šæœªå¯¦ä½œ"
        return False
    except Exception as e:
        logger.error(f"âŒ åŸ·è¡Œ train_one_epoch ç™¼ç”Ÿä¾‹å¤–: {e}")
        logger.error(traceback.format_exc())
        assert False, f"train_one_epoch åŸ·è¡Œå¤±æ•—: {e}"
        return False

    # 5. é©—è­‰ loss æ˜¯å¦åˆç†
    if isinstance(loss_history, list) and len(loss_history) > 0:
        avg_loss = np.mean(loss_history)
        logger.info(f"âœ… train_one_epoch åŸ·è¡ŒæˆåŠŸï¼Œå¹³å‡ loss={avg_loss:.4f}")
        assert np.isfinite(avg_loss), "loss æ‡‰ç‚ºæœ‰é™æ•¸å€¼"
    else:
        logger.warning("âš ï¸ train_one_epoch æœªå›å‚³ loss æ­·å²ï¼Œè«‹æª¢æŸ¥å¯¦ä½œ")
        assert False, "train_one_epoch æœªå›å‚³ loss æ­·å²"

    # 6. é©—è­‰åƒæ•¸æ˜¯å¦æœ‰æ›´æ–°
    orig_params = [p.clone().detach() for p in model.parameters()]
    model.train_one_epoch(
        train_loader=train_loader,
        optimizer=optimizer,
        auxiliary_net=aux_net,
        device=device,
        print_freq=0,
        max_batches=1
    )
    updated_params = [p.clone().detach() for p in model.parameters()]
    changed = any(not torch.equal(a, b) for a, b in zip(orig_params, updated_params))
    assert changed, "æ¨¡å‹åƒæ•¸æœªæ›´æ–°ï¼Œè«‹æª¢æŸ¥ optimizer/backward å¯¦ä½œ"
    
    logger.info("âœ… train_one_epoch åƒæ•¸æ›´æ–°æª¢æŸ¥é€šé")
    logger.info("ğŸ‰ test_train_one_epoch_basic: OS2D å–® batch å¾®èª¿è¨“ç·´æ¸¬è©¦é€šé")
    return True

def test_lcp_prune_and_train_pipeline():
    pass

def test_save_checkpoint():
    pass

def get_conv_structure(model):
    return [(name, m.in_channels, m.out_channels, m.kernel_size)
            for name, m in model.backbone.named_modules() if isinstance(m, torch.nn.Conv2d)]

def test_os2d_compatibility_with_pruned_model():
    pass

def test_compute_losses():
    """æ¸¬è©¦ compute_losses å‡½æ•¸"""
    # åˆå§‹åŒ–æ¨¡å‹å’Œè¼”åŠ©ç¶²è·¯
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = Os2dModelInPrune(pretrained_path="./os2d_v2-train.pth", is_cuda=(device.type == 'cuda')).to(device)
    aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
    
    # è¨­ç½®ç‚ºè¨“ç·´æ¨¡å¼
    model.train()
    aux_net.train()
    
    # å‰µå»ºæ¨¡æ“¬è¼¸å…¥
    batch_size = 2
    num_classes = 20
    class_images = [torch.randn(3, 64, 64).to(device) for _ in range(batch_size)]
    images = torch.randn(batch_size, 3, 224, 224, requires_grad=True).to(device)
    class_scores = torch.randn(batch_size, num_classes, requires_grad=True).to(device)
    boxes = torch.randn(batch_size, 4, requires_grad=True).to(device)
    
    # æ¨¡æ“¬ outputs
    outputs = {
        'class_scores': class_scores,
        'boxes': boxes,
        'images': images,
        'class_images': class_images
    }
    
    # åŸ·è¡Œæ•™å¸«æ¨¡å‹å‰å‘å‚³æ’­
    with torch.no_grad():
        teacher_outputs = model.teacher_model(images, class_images=class_images)
        print(f"æ•™å¸«æ¨¡å‹è¼¸å‡ºé¡å‹: {type(teacher_outputs)}")
        if isinstance(teacher_outputs, dict):
            print(f"æ•™å¸«æ¨¡å‹è¼¸å‡ºéµ: {teacher_outputs.keys()}")
        elif isinstance(teacher_outputs, tuple):
            print(f"æ•™å¸«æ¨¡å‹è¼¸å‡ºé•·åº¦: {len(teacher_outputs)}")
    
    # æ¨¡æ“¬ targets
    class_ids = [torch.tensor([1]), torch.tensor([2])]
    target_boxes = [torch.randn(1, 4).to(device), torch.randn(1, 4).to(device)]
    targets = {
        'class_ids': class_ids,
        'boxes': target_boxes,
        'images': images,
        'teacher_outputs': teacher_outputs  # æ·»åŠ æ•™å¸«æ¨¡å‹è¼¸å‡º
    }
    
    # è¨ˆç®—æå¤±
    total_loss, loss_dict = model.compute_losses(outputs, targets, auxiliary_net=aux_net)
    
    # æª¢æŸ¥æå¤±å€¼æ˜¯å¦åˆç†
    print(f"ç¸½æå¤±: {total_loss.item():.4f}")
    print(f"æå¤±å­—å…¸: {loss_dict}")
    print(f"cls loss :{loss_dict['cls_loss'].item()}")
    print(f"box loss :{loss_dict['box_loss'].item()}")
    print(f"æ•™å¸« loss :{loss_dict['teacher_loss'].item()}")
    print(f"lcp loss :{loss_dict['lcp_loss'].item()}")
    
    # åå‘å‚³æ’­
    total_loss.backward()
    
    # æª¢æŸ¥æ¢¯åº¦æ˜¯å¦å­˜åœ¨
    has_grad = any(p.grad is not None and p.grad.abs().sum().item() > 0 
                  for p in model.parameters() if p.requires_grad)
    aux_has_grad = any(p.grad is not None and p.grad.abs().sum().item() > 0 
                      for p in aux_net.parameters() if p.requires_grad)
    
    # æ¸¬è©¦é€šéæ¢ä»¶
    assert total_loss.item() > 0, "ç¸½æå¤±æ‡‰è©²å¤§æ–¼0"
    assert has_grad, "æ¨¡å‹åƒæ•¸æ‡‰è©²æœ‰æ¢¯åº¦"
    assert aux_has_grad, "è¼”åŠ©ç¶²è·¯åƒæ•¸æ‡‰è©²æœ‰æ¢¯åº¦"
    
    print("âœ… compute_losses æ¸¬è©¦é€šé")
    return True



def test_os2d_model_in_prune_eval():
    import os
    import torch
    import pytest   
    import numpy as np
    from src.os2d_model_in_prune import Os2dModelInPrune
    from src.auxiliary_network import AuxiliaryNetwork
    from os2d.data.dataset import build_grozi_dataset
    from os2d.data.dataloader import DataloaderOneShotDetection
    from os2d.modeling.box_coder import Os2dBoxCoder, BoxGridGenerator
    from os2d.structures.feature_map import FeatureMapSize

    # 1. æª¢æŸ¥ Grozi dataset æ˜¯å¦å­˜åœ¨
    data_path = "./data"
    grozi_csv = os.path.join(data_path, "grozi", "classes", "grozi.csv")
    if not os.path.exists(grozi_csv):
        print("\nâŒ Grozi-3.2k dataset not found. è«‹ä¾å®˜æ–¹èªªæ˜æ‰‹å‹•ä¸‹è¼‰ä¸¦è§£å£“è‡³ ./data/grozi/")
        pytest.skip("Grozi-3.2k dataset missing, test skipped.")
        return False

    # 2. å»ºç«‹ dataset/dataloaderï¼ˆmini subset + batch size 1ï¼‰
    dataset = build_grozi_dataset(
        data_path=data_path,
        name="grozi-train-mini",  # åªå–2å¼µåœ–2é¡åˆ¥
        eval_scale=224,
        cache_images=False
    )
    box_coder = Os2dBoxCoder(
        positive_iou_threshold=0.5,
        negative_iou_threshold=0.4,
        remap_classification_targets_iou_pos=0.5,
        remap_classification_targets_iou_neg=0.4,
        output_box_grid_generator=BoxGridGenerator(
            box_size=FeatureMapSize(w=16, h=16),
            box_stride=FeatureMapSize(w=16, h=16)
        ),
        function_get_feature_map_size=lambda img_size: FeatureMapSize(w=img_size.w // 16, h=img_size.h // 16),
        do_nms_across_classes=False
    )
    train_loader = DataloaderOneShotDetection(
        dataset=dataset,
        box_coder=box_coder,
        batch_size=1,  # æœ€å° batch
        img_normalization={"mean": [0.485, 0.456, 0.406], "std": [0.229, 0.224, 0.225]},
        gt_image_size=64,
        random_flip_batches=False,
        random_crop_size=None,
        random_color_distortion=False,
        pyramid_scales_eval=[1.0],
        do_augmentation=False
    )

    # 3. åˆå§‹åŒ–æ¨¡å‹èˆ‡å„ªåŒ–å™¨ï¼ˆå¼·åˆ¶ç”¨ cudaï¼Œæ¸›å°‘é¡¯å­˜å£“åŠ›ï¼‰
    device = torch.device('cpu')
    os2d_path = "./os2d_v2-train.pth"
    if not os.path.exists(os2d_path):
        pytest.skip(f"OS2D é è¨“ç·´æ¨¡å‹ä¸å­˜åœ¨: {os2d_path}")
    model = Os2dModelInPrune(pretrained_path=os2d_path, is_cuda=False).to(device)
    aux_net = AuxiliaryNetwork(in_channels=2048).to(device)
    optimizer = torch.optim.Adam(list(model.parameters()) + list(aux_net.parameters()), lr=1e-3)
    return True


def test_full_lcp_pipeline_with_eval_and_checkpoint():
    pass